{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN and transfer learning",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SDS-AAU/SDS-master/blob/master/M3/notebooks/CNN_and_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZGTVR17fAFp"
      },
      "source": [
        "# Using large pretrained models as your foundation\n",
        "This notebook is based on https://www.learnopencv.com/keras-tutorial-fine-tuning-using-pre-trained-models/\n",
        "\n",
        "Training large CNNs is costly (compute, time) and often we don't have enough data to bring these models to reasonable performance levels. This is where transfer-learning comes in.\n",
        "\n",
        "Assuming that the early layers of a CNN learn very basic features (edges, lines etc.) we can consider a strategy, where we take a large pretrained model, discard the last couple of layers (where we would assume the more abstract information) and train it with our new data.\n",
        "\n",
        "This is how you, for instance, could fine-tune a CNN model to some very specific medical imaging data where you simply cannot have so many examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2LsR8gScRoM"
      },
      "source": [
        "# Let's start by downloading and exploring the data\n",
        "!wget -qq https://storage.googleapis.com/sds-file-transfer/dataset.zip\n",
        "# We need to unzip the data...and as you can see there is a lot\n",
        "!unzip -qq dataset.zip"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5xW1nZukTZr"
      },
      "source": [
        "Keras has some great built-in applications - basically pretrained models with some nice functional overhead. We will start by loadeing VGG16 (a rather large model with many many many layers that has been trained on imagenet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AysqBeW7cFPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d361701a-a735-49f0-84f6-e5733e12eeb0"
      },
      "source": [
        "from keras.applications import VGG16\n",
        "#Load the VGG model\n",
        "image_size = 64\n",
        "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3bnNethklo7"
      },
      "source": [
        "The trick is, to \"freeze\" most of the initial layers and thereby preserve the majority of the information embedded in the model already. We will only train the last 2 Conv layers and also add a new dense layer as well as an output layer that fit's our purpose with the model - finding cats and dogs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Yf5KnyucGeV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2632af23-aa95-476e-dc59-1403926c2fc1"
      },
      "source": [
        "# Freeze the layers except the last 2 layers\n",
        "for layer in vgg_conv.layers[:-2]:\n",
        "    layer.trainable = False\n",
        " \n",
        "# Check the trainable status of the individual layers\n",
        "for layer in vgg_conv.layers:\n",
        "    print(layer, layer.trainable)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f54d7aeaa20> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f54d71e7470> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f54d71e7780> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f54d71e7ba8> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f54d71e8978> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f54a37084e0> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f54a3708860> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f54a2ea5400> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f54a2eae278> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f54a2eae6a0> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f54903cf198> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f54903cfa58> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f54903d98d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f54903d9978> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f54903e18d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f54903e80f0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f54903e8f28> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f54903f1320> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f54903f1c18> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9waqAE-0cmc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a292018d-445e-4ea4-8e59-f2aba04456c1"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        " \n",
        "# Create the model\n",
        "model = models.Sequential()\n",
        " \n",
        "# Add the vgg convolutional base model\n",
        "model.add(vgg_conv)\n",
        " \n",
        "# Add new layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "#model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        " \n",
        "# Show a summary of the model. Check the number of trainable parameters\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 2, 2, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 1025      \n",
            "=================================================================\n",
            "Total params: 16,813,889\n",
            "Trainable params: 4,459,009\n",
            "Non-trainable params: 12,354,880\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLy7MzjWctm_"
      },
      "source": [
        "# Importing the Keras-Image-Data-Generator <3 Keras ppl\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# Defining the generators. Note, that we for obvious reasons only apply all of the generator magic to the training set.\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Wqsv8wldGwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "205d6dfa-7d21-4aed-8e17-08583707bac1"
      },
      "source": [
        "# here, we specify the size of the images that we want (which needs to fit the input size of our network)\n",
        "# We also set the batch size and the classification method (here binary)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8q3kF86dYep"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6ZaTyUbdL-t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c15f9f5-1abb-41e8-8c1b-83aa7a1151d8"
      },
      "source": [
        "# And now we can train the network\n",
        "\n",
        "model.fit_generator(training_set,\n",
        "                         steps_per_epoch = 800,\n",
        "                         epochs = 2,\n",
        "                         validation_data = test_set,\n",
        "                         validation_steps = 100)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-ef8c8fc5cc5d>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/2\n",
            "250/800 [========>.....................] - ETA: 1:04 - loss: 0.4961 - acc: 0.7680WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1600 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 100 batches). You may need to use the repeat() function when building your dataset.\n",
            "250/800 [========>.....................] - 35s 139ms/step - loss: 0.4961 - acc: 0.7680 - val_loss: 0.4045 - val_acc: 0.8165\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f542ade3be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62rwdFrqdQW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "100f9ce1-c0c0-4f85-b3d3-e21ca361b153"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "for i in glob.glob('dataset/test_set/dogs/*')[:10]:\n",
        "  test_image = image.load_img(i, target_size = (64, 64))\n",
        "  test_image = image.img_to_array(test_image)\n",
        "\n",
        "  test_image = np.expand_dims(test_image, axis = 0)\n",
        "\n",
        "  result = model.predict_classes(test_image)\n",
        "  if result[0][0] == 1:\n",
        "    print('dog')\n",
        "  if result[0][0] == 0:\n",
        "    print('cat')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-9-74ba37e62bc9>:11: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "dog\n",
            "dog\n",
            "dog\n",
            "dog\n",
            "dog\n",
            "dog\n",
            "dog\n",
            "dog\n",
            "dog\n",
            "dog\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSxciapPfWLf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7291f21-0588-4ef5-d52a-ef3eba145202"
      },
      "source": [
        "# Evaluation returns loss and accuracy\n",
        "model.evaluate_generator(test_set, steps=500)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-10-531adde94a0a>:2: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.evaluate, which supports generators.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need to use the repeat() function when building your dataset.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4044948220252991, 0.8165000081062317]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlYgWqks7vVB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}