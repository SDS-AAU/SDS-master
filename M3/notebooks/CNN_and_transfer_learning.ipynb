{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN and transfer learning",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SDS-AAU/SDS-master/blob/master/M3/notebooks/CNN_and_transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZGTVR17fAFp"
      },
      "source": [
        "# Using large pretrained models as your foundation\n",
        "This notebook is based on https://www.learnopencv.com/keras-tutorial-fine-tuning-using-pre-trained-models/\n",
        "\n",
        "Training large CNNs is costly (compute, time) and often we don't have enough data to bring these models to reasonable performance levels. This is where transfer-learning comes in.\n",
        "\n",
        "Assuming that the early layers of a CNN learn very basic features (edges, lines etc.) we can consider a strategy, where we take a large pretrained model, discard the last couple of layers (where we would assume the more abstract information) and train it with our new data.\n",
        "\n",
        "This is how you, for instance, could fine-tune a CNN model to some very specific medical imaging data where you simply cannot have so many examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2LsR8gScRoM"
      },
      "source": [
        "# Let's start by downloading and exploring the data\n",
        "!wget -qq https://storage.googleapis.com/sds-file-transfer/dataset.zip\n",
        "# We need to unzip the data...and as you can see there is a lot\n",
        "!unzip -qq dataset.zip"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5xW1nZukTZr"
      },
      "source": [
        "Keras has some great built-in applications - basically pretrained models with some nice functional overhead. We will start by loadeing VGG16 (a rather large model with many many many layers that has been trained on imagenet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AysqBeW7cFPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "485c3b79-79e8-4446-d92c-6ffdd063976d"
      },
      "source": [
        "from keras.applications import VGG16\n",
        "#Load the VGG model\n",
        "image_size = 64\n",
        "vgg_conv = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3bnNethklo7"
      },
      "source": [
        "The trick is, to \"freeze\" most of the initial layers and thereby preserve the majority of the information embedded in the model already. We will only train the last 2 Conv layers and also add a new dense layer as well as an output layer that fit's our purpose with the model - finding cats and dogs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Yf5KnyucGeV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4956e89-2d66-45c9-d733-87d666445335"
      },
      "source": [
        "# Freeze the layers except the last 2 layers\n",
        "for layer in vgg_conv.layers[:-2]:\n",
        "    layer.trainable = False\n",
        " \n",
        "# Check the trainable status of the individual layers\n",
        "for layer in vgg_conv.layers:\n",
        "    print(layer, layer.trainable)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f4c1aa10908> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4c005acfd0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4c005ad320> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f4c005ad748> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4c005af4a8> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4bccb45e80> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f4bc01005c0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4bc0100da0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4bc010fc18> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4bc010fb70> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f4bc0111908> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4bc011c438> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4bc01262e8> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4bc01266d8> False\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f4bc00ae1d0> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4bc00aea90> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4bc00b9908> False\n",
            "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f4bc00b99b0> True\n",
            "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f4bc00c2908> True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9waqAE-0cmc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d649f429-d98b-4012-cdca-ec131ed03360"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        " \n",
        "# Create the model\n",
        "model = models.Sequential()\n",
        " \n",
        "# Add the vgg convolutional base model\n",
        "model.add(vgg_conv)\n",
        " \n",
        "# Add new layers\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "#model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        " \n",
        "# Show a summary of the model. Check the number of trainable parameters\n",
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Functional)           (None, 2, 2, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 1025      \n",
            "=================================================================\n",
            "Total params: 16,813,889\n",
            "Trainable params: 4,459,009\n",
            "Non-trainable params: 12,354,880\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLy7MzjWctm_"
      },
      "source": [
        "# Importing the Keras-Image-Data-Generator <3 Keras ppl\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# Defining the generators. Note, that we for obvious reasons only apply all of the generator magic to the training set.\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Wqsv8wldGwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "167c4922-709e-42e7-a6c7-16c52fa03705"
      },
      "source": [
        "# here, we specify the size of the images that we want (which needs to fit the input size of our network)\n",
        "# We also set the batch size and the classification method (here binary)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8q3kF86dYep"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6ZaTyUbdL-t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b639019-1d89-477c-8cf7-ad81dd993f4d"
      },
      "source": [
        "# And now we can train the network\n",
        "\n",
        "model.fit(training_set,\n",
        "                         steps_per_epoch = 245,\n",
        "                         epochs = 2,\n",
        "                         validation_data = test_set,\n",
        "                         validation_steps = 50)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "245/245 [==============================] - 32s 132ms/step - loss: 0.4090 - acc: 0.8111 - val_loss: 0.3881 - val_acc: 0.8244\n",
            "Epoch 2/2\n",
            "245/245 [==============================] - 32s 132ms/step - loss: 0.3770 - acc: 0.8277 - val_loss: 0.3853 - val_acc: 0.8119\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4b69c746a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62rwdFrqdQW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0216afa2-7645-4a64-8bc1-c0caa1c83e17"
      },
      "source": [
        "from keras.preprocessing import image\n",
        "import glob\n",
        "import numpy as np\n",
        "\n",
        "for i in glob.glob('dataset/test_set/dogs/*')[:10]:\n",
        "  test_image = image.load_img(i, target_size = (64, 64))\n",
        "  test_image = image.img_to_array(test_image)\n",
        "\n",
        "  test_image = np.expand_dims(test_image, axis = 0)\n",
        "\n",
        "  result = model.predict_classes(test_image)\n",
        "  if result[0][0] == 1:\n",
        "    print('dog')\n",
        "  if result[0][0] == 0:\n",
        "    print('cat')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-10-74ba37e62bc9>:11: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "dog\n",
            "dog\n",
            "dog\n",
            "dog\n",
            "dog\n",
            "dog\n",
            "dog\n",
            "dog\n",
            "dog\n",
            "dog\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSxciapPfWLf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4747a174-e68f-49c4-ca86-63b964d88df7"
      },
      "source": [
        "# Evaluation returns loss and accuracy\n",
        "model.evaluate(test_set, steps=500)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-11-531adde94a0a>:2: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.evaluate, which supports generators.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 500 batches). You may need to use the repeat() function when building your dataset.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3906996250152588, 0.8159999847412109]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}