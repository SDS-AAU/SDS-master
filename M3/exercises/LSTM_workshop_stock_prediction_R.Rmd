---
title:  'Sequence-2-Sequence forecasting (R)'
author: "Daniel S. Hain (dsh@business.aau.dk)"
date: "Updated `r format(Sys.time(), '%B %d, %Y')`"
output:
  html_notebook:
    code_folding: show
    df_print: paged
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
    theme: flatly
---

```{r setup, include=FALSE}
### Generic preamble
rm(list=ls())
Sys.setenv(LANG = "en") # For english language
options(scipen = 5) # To deactivate annoying scientific number notation

### Knitr options
library(knitr) # For display of the markdown
knitr::opts_chunk$set(warning=FALSE,
                     message=FALSE,
                     comment=FALSE, 
                     fig.align="center"
                     )
```


```{r}
library(tidyverse)
library(magrittr)
library(keras)
```

```{r}
# others
library(tidyquant) # My favorite package to get stock data
library(tidymodels) # Or only load the 'rsample' and recipes on its own

# Time Series
# library(feasts) # We don t really need it
```

# Workshop Stock prediction

Task:

1. Get some stock data (tip: Use tidyquant)
    * Limit yourself for now to on e stock
    * Limit yourself to one variable (preferably some price data)
2. Develop a one-step ahead prediction of prices (or their movements)

# Load some data

## Select a stock abnd load the data

```{r}
tickers = c("AAPL") # Just for fun, we get a couple of stocks
            
data_stocks <- tq_get(tickers,
               from = "2000-01-01",
               to = "2020-11-30",
               get = "stock.prices" # What we want to get.... here prices
               )
```


## Some plots for exploration...


```{r}
data_stocks %>% glimpse()
```

```{r}
data_stocks %>% head()
```

```{r}
data_stocks %>%
  ggplot(aes(x = date, y = adjusted,)) +
  geom_line() +
  labs(x = 'Date', y = "Adjusted Price") 
```

# Preprocessing

## Limit data

```{r}
data <- data_stocks %>%
  filter(symbol == 'AAPL') %>%
  rename(index = date, value = adjusted) %>%
  select(index, value) %>%
  arrange(index) %>%
  drop_na()
```

## Remodel value as percentage change

```{r}
data %<>%
  mutate(value = (value - lag(value,1)) / lag(value,1) ) %>%
  drop_na()
  
```

```{r}
data %>%
  ggplot(aes(x = index, y = value)) +
  geom_line() +
  labs(x = 'Date', y = "Price change in pct") 
```

```{r}
# Do it to get the right size  for batches
data %<>%
  slice(1:5000)
```




## Train & Test split

```{r}
# We use time_splits here to maintain the sequences
data_split <- data %>% initial_time_split(prop = 0.75)
```

```{r}
data_train <- data_split %>% training()
data_test <- data_split %>% testing()
```

```{r}
# See ehat we got
data_train %>% pull(index) %>% min()
data_train %>% pull(index) %>% max()
data_test %>% pull(index) %>% min()
data_test %>% pull(index) %>% max()
```

## Define a reciepe

We only apply min-max scaling hee

```{r}
data_recipe <- data_train %>%
  recipe(value ~ .) %>% 
  step_range(value, min = -1, max = 1)  %>%
  step_arrange(index) %>%
  prep()
```

```{r}
# Preserve the values for later (to reconstruct original values)
prep_history <- tibble(
  min = data_recipe$steps[[1]]$ranges[1],
  max = data_recipe$steps[[1]]$ranges[2]
)
```

```{r}
prep_history
```



* We now create a x and y split. Since we here always predict the next observation, that's easy. We will just set y= lead(x, 1)
* We therefore also delete the last observation in train and the first in test

## Get processedv train & test data

```{r}
# Number of lags
n_lag = 1
```


```{r}
# TRain data
x_train <- data_recipe %>% juice() 

y_train <- data_recipe %>%  juice() %>%
  mutate(value = value %>% lead(1)) 

# And the same for the test data
x_test <- data_recipe %>% bake(data_test) 

y_test <- data_recipe %>%  bake(data_test) %>%  
  mutate(value = value %>% lead(1)) %>%
  mutate(value = ifelse(is.na(value), lag(value, 1), value))
```

## Transform to a 3d tensor for keras

```{r}
x_train_arr <- x_train %>% pull(value) %>% as.numeric() %>% array_reshape(dim = c(length(.), 1, 1))
x_test_arr <- x_test %>% pull(value) %>% as.numeric() %>% array_reshape(dim = c(length(.), 1, 1))

y_train_arr <- y_train %>% pull(value) %>% as.numeric() %>% array_reshape(dim = c(length(.), 1))
y_test_arr <- y_test %>% pull(value) %>% as.numeric() %>% array_reshape(dim = c(length(.), 1))
```

# Setting up the LSTM


# LSTM

## Define model

```{r}
tsteps       <- 1
batch_size   <-50 # (nrow(x_train) / 10) %>% as.integer()
train_length <- nrow(x_train_arr)
epochs       <- 10
```


```{r}
model <- keras_model_sequential() %>%
  # # First LSTM Layer
  layer_lstm(units            = 64, 
             input_shape= c(tsteps, 1), #  timesteps, features
             #batch_size       = batch_size,
             return_sequences = TRUE, 
             #stateful         = TRUE
             ) %>% 
  #layer_dense(units = 32, activation = 'relu') %>%
  # Second LSTM Layer
  layer_lstm(units            = 64, 
             dropout	        = 0.1,
             recurrent_dropout= 0.1,
             #stateful         = TRUE,
             return_sequences = FALSE) %>% 
   #Final prediction layer
  layer_dense(units = 1, activation = 'linear')


# Compile model
model %>% 
  compile(loss = "mse", 
          metric = 'mse', 
          optimizer = "adam")
```

```{r}
model %>% summary()
```

## Fitting the model

* Next, we can fit our stateful LSTM using a for loop (we do this to manually reset states). 
* We set `shuffle = FALSE` to preserve sequences
* We manually reset the states after each epoch using `reset_states()`. Therefore we have to train the single epochs in loops. Otherwise, the states would be carried over between the epocs.


```{r}
#for (i in 1:epochs) {
  model %>% fit(x          = x_train_arr, 
                y          = y_train_arr, 
                epochs     = 1, 
                verbose    = 1, 
                batch_size = batch_size,
                shuffle    = FALSE)
  
#  model %>% reset_states()
#}
```

```{r}
model %>% evaluate(x_test_arr, y_test_arr)
```

```{r}
model_pred <- model %>% predict(x_test_arr)
```


# Multi-episode LSTM

## Transform to a 3d tensor for keras

```{r}
tsteps_x = 5
tsteps_y = 5
```


```{r}
train_arr <- x_train %>% pull(value) %>% as.numeric() %>% matrix(ncol = (tsteps_x + tsteps_y))
```

```{r}
x_train_arr <- train_arr[,1:tsteps_x] %>% array_reshape(dim = c(length(.), 1, 1))
```




```{r}
x_train %<>% pull(value) %>% as.numeric() %>% array_reshape(dim = c(length(.), 1, 1))
x_test %<>% pull(value) %>% as.numeric() %>% array_reshape(dim = c(length(.), 1, 1))

y_train %<>% pull(value) %>% as.numeric() %>% array_reshape(dim = c(length(.), 1))
y_test %<>% pull(value) %>% as.numeric() %>% array_reshape(dim = c(length(.), 1))
```

