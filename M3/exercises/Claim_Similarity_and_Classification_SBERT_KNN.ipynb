{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Claim Similarity and Classification SBERT_KNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SDS-AAU/SDS-master/blob/master/M3/exercises/Claim_Similarity_and_Classification_SBERT_KNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2jVU19sB6Tm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31438e17-ca57-4f5d-a79d-c335b55fc5c8"
      },
      "source": [
        "!pip install sentence_transformers"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.6/dist-packages (0.3.9)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from sentence_transformers) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sentence_transformers) (1.18.5)\n",
            "Requirement already satisfied: transformers<3.6.0,>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from sentence_transformers) (3.5.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sentence_transformers) (0.22.2.post1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from sentence_transformers) (1.7.0+cu101)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sentence_transformers) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from sentence_transformers) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->sentence_transformers) (1.15.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence_transformers) (3.12.4)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence_transformers) (0.1.91)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence_transformers) (0.9.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence_transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence_transformers) (0.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence_transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence_transformers) (2.23.0)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence_transformers) (0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<3.6.0,>=3.1.0->sentence_transformers) (20.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sentence_transformers) (0.17.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence_transformers) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->sentence_transformers) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers<3.6.0,>=3.1.0->sentence_transformers) (50.3.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<3.6.0,>=3.1.0->sentence_transformers) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence_transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence_transformers) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence_transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers<3.6.0,>=3.1.0->sentence_transformers) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<3.6.0,>=3.1.0->sentence_transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl6vMeHxKTSw"
      },
      "source": [
        "import scipy.spatial\n",
        "import numpy as np\n",
        "import os, json\n",
        "import glob\n",
        "import re\n",
        "import torch\n",
        "import pandas as pd"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SKcdUBUFL4X"
      },
      "source": [
        "df_row = pd.read_csv('https://github.com/SDS-AAU/SDS-master/raw/master/00_data/patent_claim5000.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkQ_L8kXQRJm",
        "outputId": "5aa62aac-75f2-4a2c-d7b2-3b584fab2268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_row.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patent_id</th>\n",
              "      <th>claim_number</th>\n",
              "      <th>text</th>\n",
              "      <th>sequence</th>\n",
              "      <th>dependent</th>\n",
              "      <th>exemplary</th>\n",
              "      <th>subclass</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10606734</td>\n",
              "      <td>6</td>\n",
              "      <td>6. A computer-program product for intelligent ...</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10606734</td>\n",
              "      <td>7</td>\n",
              "      <td>7. The computer program product of claim 6 , w...</td>\n",
              "      <td>6</td>\n",
              "      <td>claim 6</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10606734</td>\n",
              "      <td>8</td>\n",
              "      <td>8. The computer program product of claim 6 , f...</td>\n",
              "      <td>7</td>\n",
              "      <td>claim 6</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10606734</td>\n",
              "      <td>9</td>\n",
              "      <td>9. The computer program product of claim 8 , w...</td>\n",
              "      <td>8</td>\n",
              "      <td>claim 8</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10606734</td>\n",
              "      <td>10</td>\n",
              "      <td>10. The computer program product of claim 6 , ...</td>\n",
              "      <td>9</td>\n",
              "      <td>claim 6</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   patent_id  claim_number  ... exemplary  subclass\n",
              "0   10606734             6  ...         0         A\n",
              "1   10606734             7  ...         0         A\n",
              "2   10606734             8  ...         0         A\n",
              "3   10606734             9  ...         0         A\n",
              "4   10606734            10  ...         0         A\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD8WxypujijC",
        "outputId": "02abd538-8685-498d-9b62-4a37637f3edd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        }
      },
      "source": [
        "df_row.iloc[0]['text']"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'6. A computer-program product for intelligent mobile device selection for mobile application testing, the computer-program product comprising: a computer-readable storage medium readable by a processing circuit and storing instructions for execution by the processing circuit for performing a method comprising: determining features of a new mobile application to be tested; comparing, by a processor, the features of the new mobile application to be tested with features of multiple known mobile applications to identify one or more known mobile applications with similar features; based at least in part on automated analysis of user reviews of the one or more known mobile applications operating in one or more types of mobile devices, providing one or more risk scores for operation of the new mobile application in the one or more types of mobile devices, wherein providing the one or more risk scores comprises generating a respective risk score for operating the new mobile application in each type of mobile device of the one or more types of mobile devices, the respective risk scores being determined based, at least in part, on automated analysis of user reviews of the one or more known mobile applications with similar features operating on that type of mobile device; using, by the processor, at least in part, the one or more risk scores in deciding in which types of mobile devices to test the operation of the new mobile application.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8lSU_dYj025"
      },
      "source": [
        "df_newmergetext = df_row.groupby('patent_id')['text'].apply(lambda x: \"{%s}\" % ', '.join(x))\n",
        "# type(df_newmergetext)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5boN95U_-Lio",
        "outputId": "13e86c83-75f6-4767-d9f0-fe3f643cb5aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_newmergetext.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "patent_id\n",
              "10606734    {6. A computer-program product for intelligent...\n",
              "10606736    {1. A computer-implemented method for creation...\n",
              "10606737    {1. A method for testing a resource constraine...\n",
              "10606738    {1. A method, comprising: receiving results fr...\n",
              "10606739    {1. A device, comprising: a memory; and one or...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SK0ILaVtkAsn"
      },
      "source": [
        "df_newmergetext = df_newmergetext.to_frame()\n",
        "# df_newmergetext.head()\n",
        "# df_newmergetext.iloc[0]['text']"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7MwdYKNkJI4"
      },
      "source": [
        "df = pd.merge(df_row.drop_duplicates(subset='patent_id'), df_newmergetext, on='patent_id', how='inner')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAQPbYb_-Vdy",
        "outputId": "0f041d55-7034-4933-eee0-e9541dd14b73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patent_id</th>\n",
              "      <th>claim_number</th>\n",
              "      <th>text_x</th>\n",
              "      <th>sequence</th>\n",
              "      <th>dependent</th>\n",
              "      <th>exemplary</th>\n",
              "      <th>subclass</th>\n",
              "      <th>text_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10606734</td>\n",
              "      <td>6</td>\n",
              "      <td>6. A computer-program product for intelligent ...</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>{6. A computer-program product for intelligent...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10606736</td>\n",
              "      <td>1</td>\n",
              "      <td>1. A computer-implemented method for creation ...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>{1. A computer-implemented method for creation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10606737</td>\n",
              "      <td>1</td>\n",
              "      <td>1. A method for testing a resource constrained...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>{1. A method for testing a resource constraine...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10606738</td>\n",
              "      <td>1</td>\n",
              "      <td>1. A method, comprising: receiving results fro...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>{1. A method, comprising: receiving results fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10606739</td>\n",
              "      <td>1</td>\n",
              "      <td>1. A device, comprising: a memory; and one or ...</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>{1. A device, comprising: a memory; and one or...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   patent_id  ...                                             text_y\n",
              "0   10606734  ...  {6. A computer-program product for intelligent...\n",
              "1   10606736  ...  {1. A computer-implemented method for creation...\n",
              "2   10606737  ...  {1. A method for testing a resource constraine...\n",
              "3   10606738  ...  {1. A method, comprising: receiving results fr...\n",
              "4   10606739  ...  {1. A device, comprising: a memory; and one or...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inAwgaDFkRmE"
      },
      "source": [
        "df['text_y'] = df['text_y'].str.strip('{}')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ8ohjZUkgRH"
      },
      "source": [
        "df = df.drop('text_x', axis=1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-cGeNaDkkaK",
        "outputId": "d3739d25-511f-4ed7-aae1-94c71e72a26b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>patent_id</th>\n",
              "      <th>claim_number</th>\n",
              "      <th>sequence</th>\n",
              "      <th>dependent</th>\n",
              "      <th>exemplary</th>\n",
              "      <th>subclass</th>\n",
              "      <th>text_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10606734</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>6. A computer-program product for intelligent ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10606736</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1. A computer-implemented method for creation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10606737</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1. A method for testing a resource constrained...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10606738</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1. A method, comprising: receiving results fro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10606739</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1. A device, comprising: a memory; and one or ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   patent_id  ...                                             text_y\n",
              "0   10606734  ...  6. A computer-program product for intelligent ...\n",
              "1   10606736  ...  1. A computer-implemented method for creation ...\n",
              "2   10606737  ...  1. A method for testing a resource constrained...\n",
              "3   10606738  ...  1. A method, comprising: receiving results fro...\n",
              "4   10606739  ...  1. A device, comprising: a memory; and one or ...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiBKqGailUZr"
      },
      "source": [
        "df = df.rename(columns={\"text_y\": \"text\"}, errors=\"raise\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dqn9Pd6EkmZR",
        "outputId": "331c769a-7be5-4e5c-86ba-997190c68685",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "total_patents = df.count()\n",
        "total_patents"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "patent_id       282\n",
              "claim_number    282\n",
              "sequence        282\n",
              "dependent         0\n",
              "exemplary       282\n",
              "subclass        282\n",
              "text            282\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgW99gz3Qo4c"
      },
      "source": [
        "## Torch tryout\n",
        "# df_test_tensor = df.drop(['text', 'dependent'], axis=1)\n",
        "# df_test_tensor\n",
        "# sorted, indices = torch.sort(df_tensor, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WVrtjzXFWu1"
      },
      "source": [
        "claims = list(df.text)\n",
        "patent_id = list(df.patent_id)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3oCcr88Fsb1"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY9JTYCo_WSV",
        "outputId": "fbdd317f-e842-4636-d0e5-7551a321eedc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#embedder = SentenceTransformer('roberta-base-nli-stsb-mean-tokens')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 461M/461M [00:19<00:00, 24.2MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xBxdJVg6d_J"
      },
      "source": [
        "#Test_claim_embeddings = embedder.encode(claims)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LsjbPYRFxV0"
      },
      "source": [
        "def get_top_n_similar_patents_df(new_claim, claims):\n",
        "    # embedder = SentenceTransformer('bert-base-nli-stsb-mean-tokens')\n",
        "    embedder = SentenceTransformer('roberta-base-nli-stsb-mean-tokens')\n",
        "    query_embeddings = embedder.encode([new_claim])\n",
        "\n",
        "    # list of patent claims\n",
        "    claim_embeddings = embedder.encode(claims)\n",
        "\n",
        "    # get top 100 patent claims based on cosine similarity\n",
        "    closest_n = 100\n",
        "    distances = scipy.spatial.distance.cdist(query_embeddings, claim_embeddings, \"cosine\")[0]\n",
        "\n",
        "    results = zip(range(len(distances)), distances)\n",
        "    results = sorted(results, key=lambda x: x[1])\n",
        "\n",
        "    # save similar patents info\n",
        "    top_claim_ids = []\n",
        "    top_claims = []\n",
        "    top_similarity_scores = []\n",
        "\n",
        "\n",
        "    print('New_claim: ' + new_claim + '\\n')\n",
        "\n",
        "    # Find the closest 100 patent claims for each query new_claim based on cosine similarity\n",
        "    for idx, distance in results[0:closest_n]:\n",
        "        top_claim_ids.append(patent_id[idx])\n",
        "        top_claims.append(claims[idx])\n",
        "        top_similarity_scores.append(round((1-distance), 4))\n",
        "        print('Patent ID: ' + str(patent_id[idx]))\n",
        "        print('PubMed Claim: ' + claims[idx])\n",
        "        print('Similarity Score: ' + \"%.4f\" % (1-distance))\n",
        "        print('\\n')\n",
        "        \n",
        "    top_100_similar_patents_df = pd.DataFrame({\n",
        "        'top_claim_ids': top_claim_ids,\n",
        "        'cosine_similarity': top_similarity_scores,\n",
        "        'claims': top_claims,\n",
        "    })\n",
        "    \n",
        "    return top_100_similar_patents_df"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPomUyRuRHAE"
      },
      "source": [
        "new_claim = ['The computer-implemented method of claim 4 wherein the filtering criteria comprises a number of page groups in the page group list is greater than 1, and the representative rank is less than or equal to the exit-entry max paths. The computer-implemented method of claim 2 wherein the selecting of the top n unconverted session paths further comprises only selecting unconverted sessions that meet a filtering criteria. The computer-implemented method of claim 1 further comprising creating a master table that lists the set of load test scenarios and the think times that represents a distribution of paths taken by real users during the peak hour.']"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8ORKVQyJFYX",
        "outputId": "1b0f7e3d-5e95-4b50-9fd5-750178729fa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# search for similar patent claim\n",
        "\n",
        "if os.path.exists('top_100_similar_patents_df.csv'):\n",
        "    get_top_n_similar_patents_df = pd.read_csv('top_100_similar_patents_df.csv')\n",
        "\n",
        "else:\n",
        "    get_top_n_similar_patents_df = get_top_n_similar_patents_df(new_claim[0], claims)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New_claim: The computer-implemented method of claim 4 wherein the filtering criteria comprises a number of page groups in the page group list is greater than 1, and the representative rank is less than or equal to the exit-entry max paths. The computer-implemented method of claim 2 wherein the selecting of the top n unconverted session paths further comprises only selecting unconverted sessions that meet a filtering criteria. The computer-implemented method of claim 1 further comprising creating a master table that lists the set of load test scenarios and the think times that represents a distribution of paths taken by real users during the peak hour.\n",
            "\n",
            "Patent ID: 10606917\n",
            "PubMed Claim: 1. An alternating least square recommendation system, comprising a processor; and a memory, the memory storing instructions to cause the processor to perform: partially updating a user's feature by evaluating an update ratio and a predefined threshold ratio, the pre-defined threshold ratio being configurable based on a preference of an existing sparse matrix factorization, wherein the pre-defined threshold ratio is pre-defined by setting the pre-defined threshold ratio to a variable value according to a past acceptable update., 2. The system of claim 1 , further comprising comparing a result of an update with each value to a result with a full-update, wherein the value of the pre-defined threshold ratio having a highest accuracy is set as the pre-defined threshold ratio., 3. A computer program product, the computer program product comprising a non-transitory computer-readable storage medium having program instructions embodied therewith, the program instructions executable by a computer to cause the computer to perform: partially updating a user's feature by evaluating an update ratio and a pre-defined threshold ratio, the pre-defined threshold ratio being configurable based on a preference of an existing sparse matrix factorization, wherein the pre-defined threshold ratio is predefined by setting the pre-defined threshold ratio to a variable value according to a past acceptable update., 4. The computer program product of claim 3 , further comprising comparing a result of an update with each value to a result with a full-update, wherein the value of the pre-defined threshold ratio having a highest accuracy is set as the pre-defined threshold ratio., 5. An alternating least square recommendation method, comprising: partially updating a user's feature by evaluating an update ratio and a pre-defined threshold ratio, the pre-defined threshold ratio being configurable based on a preference of an existing sparse matrix factorization, wherein the pre-defined threshold ratio is pre-defined by setting the pre-defined threshold ratio to a variable value according to a past acceptable update., 6. The method of claim 5 , further comprising comparing a result of an update with each value to a result with a full-update, wherein the value of the pre-defined threshold ratio having a highest accuracy is set as the pre-defined threshold ratio.\n",
            "Similarity Score: 0.6802\n",
            "\n",
            "\n",
            "Patent ID: 10606970\n",
            "PubMed Claim: 1. A computer-implemented method for statistical static timing analysis of an integrated circuit, the method comprising: specifying, by a user, a criteria for paths and tests for the integrated circuit; performing, by a processor, a statistical static timing analysis for each of the paths of the integrated circuit to create slack canonicals; projecting, by the processor, the slack canonicals for each of the paths of the integrated circuit to a worst value; applying a filter to the slack canonicals; determining, by the processor, worst timing corners based at least in part on applying the filter to the slack canonicals and based at least in part on the worst value; performing a selection based on the worst timing corners, wherein the selection is at least one of selecting a number of timing corners or selecting a margin; and delivering a timing setup to an optimization tool, the timing setup being based at least in part on the selection., 2. The computer-implemented method of claim 1 , wherein the number of timing corners is determined by an efficiency of the optimization tool., 3. The computer-implemented method of claim 1 , wherein the margin is selected to provide a desired coverage for a number of selected timing corners., 4. The computer-implemented method of claim 1 , wherein applying the filter enables a user to define the worst value based on a desired test., 5. The computer-implemented method of claim 1 , wherein applying the filter enables a user to define the worst value based on a desired outcome., 6. The computer-implemented method of claim 1 , wherein applying the filter enables a user to define the worst value based on which of a plurality of parameters are of particular importance., 7. The computer-implemented method of claim 1 , wherein applying the filter enables a user to exclude at least one path., 8. The computer-implemented method of claim 1 , wherein the worst timing corners are determined using pre-determined test metrics., 9. The computer-implemented method of claim 1 , further comprising performing, by the processor, a subsequent statistical static timing analysis of the integrated circuit using the selection., 10. A system comprising: a memory comprising computer readable instructions; and a processing device for executing the computer readable instructions for performing a method for statistical static timing analysis of an integrated circuit, the method comprising: specifying, by a user, a criteria for paths and tests for the integrated circuit; performing, by a processor, a statistical static timing analysis for each of the paths of the integrated circuit to create slack canonicals; projecting, by the processor, the slack canonicals for each of the paths of the integrated circuit to a worst value; applying a filter to the slack canonicals; determining, by the processor, worst timing corners based at least in part on applying the filter to the slack canonicals and based at least in part on the worst value; performing a selection based on the worst timing corners, wherein the selection is at least one of selecting a number of timing corners or selecting a margin; and delivering a timing setup to an optimization tool, the timing setup being based at least in part on the selection., 11. The system of claim 10 , wherein the number of timing corners is determined by an efficiency of the optimization tool., 12. The system of claim 10 , wherein the margin is selected to provide a desired coverage for a number of selected timing corners., 13. The system of claim 10 , wherein applying the filter enables a user to define the worst value based on a desired test., 14. The system of claim 10 , wherein applying the filter enables a user to define the worst value based on a desired outcome., 15. The system of claim 10 , wherein applying the filter enables a user to define the worst value based on which of a plurality of parameters are of particular importance., 16. The system of claim 10 , wherein applying the filter enables a user to exclude at least one path., 17. The system of claim 10 , wherein the worst timing corners are determined using pre-determined test metrics., 18. The system of claim 10 , wherein the method further comprises performing, by the processor, a subsequent statistical static timing analysis of the integrated circuit using the selection., 19. A computer program product comprising: a computer readable storage medium having program instructions embodied therewith, the program instructions executable by a processing device to cause the processing device to perform a method for statistical static timing analysis of an integrated circuit, the method comprising: specifying, by a user, a criteria for paths and tests for the integrated circuit; performing, by a processor, a statistical static timing analysis for each of the paths of the integrated circuit to create slack canonicals; projecting, by the processor, the slack canonicals for each of the paths of the integrated circuit to a worst value; applying a filter to the slack canonicals; determining, by the processor, worst timing corners based at least in part on applying the filter to the slack canonicals and based at least in part on the worst value; performing a selection based on the worst timing corners, wherein the selection is at least one of selecting a number of timing corners or selecting a margin; and delivering a timing setup to an optimization tool, the timing setup being based at least in part on the selection., 20. The computer program product of claim 19 , wherein the method further comprises performing, by the processor, a subsequent statistical static timing analysis of the integrated circuit using the selection.\n",
            "Similarity Score: 0.6652\n",
            "\n",
            "\n",
            "Patent ID: 10606918\n",
            "PubMed Claim: 1. A convolution engine, comprising: an input buffer circuit configured to receive and store data values of a plurality of channels of input data in an interleaved manner; a datapath switch circuit coupled to the input buffer circuit and configured to retrieve a group of the data values stored in the input buffer circuit including a center data value and one or more neighboring data values separated from the center data value by one or more step values as defined by configuration information, a portion of the data values between the center data value and the one or more neighboring values being skipped when the group of the data values is retrieved; and a computation core circuit coupled to the datapath switch circuit and configured to: receive the group of the data values from the datapath switch circuit and filter elements of a kernel for performing a convolution operation, and multiply each data value of the group of the data values with a corresponding filter element to obtain multiplied values., 2. The convolution engine of claim 1 , further comprising an output buffer coupled to the computation core circuit, the output buffer configured to store output values from the computation core circuit., 3. The convolution engine of claim 2 , wherein the output values stored in the output buffer are of a plurality of output channels in an interleaved manner., 4. The convolution engine of claim 1 , further comprising: a filter storage configured to store the filter elements; and a filter switch circuit coupled to the filter storage and the computation core circuit, the filter switch circuit configured to retrieve the filter elements from the filter storage and provide the filter elements to the computation core circuit., 5. The convolution engine of claim 1 , wherein the input buffer circuit stores (i) in a predetermined row and a column of memory location, first data values for a first subset of bits of a data unit in the input data, and (ii) in the row and another column adjacent to the column storing the first subset of bits, a second data value for a second subset of bits of the data unit., 6. The convolution engine of claim 5 , wherein the first subset of the bits is most significant bits of the data, and the second subset of the bits is least significant bits of the data., 7. The convolution engine of claim 1 , wherein the computation core circuit is further configured to process subsets of the multiplied values by one of (i) accumulating of the subsets of the multiplied values to obtain an output value or (ii) selecting one of the multiplied values as an output value., 8. The convolution engine of claim 7 , further comprising a post-processing circuit coupled to the computation core circuit, the post-processing circuit configured to perform normalized cross correlation on the output value., 9. The convolution engine of claim 1 , wherein the group of the data values multiplied by the computation core circuit in a cycle define a portion of an image., 10. A method of performing convolution, comprising: storing, by an input buffer circuit of a convolution engine, data values of a plurality of channels of input data in an interleaved manner; retrieving, by a datapath switch circuit of the convolution engine and from the input buffer circuit, a group of the data values stored in the input buffer circuit including a center data value and one or more neighboring data values separated from the center data value by one or more step values as defined by configuration information, a portion of the data values between the center data value and the one or more neighboring values skipped when the group of the data values is retrieved; receiving, by a computation core circuit of the convolution engine, the group of the data values from the datapath switch circuit and filter elements of a kernel for performing a convolution operation; and multiplying, by the computation core circuit, each data value of the group of the data values with a corresponding filter element to obtain multiplied values., 11. The method of claim 10 , further comprising, by an output buffer of the convolution engine, storing output values of the computation core circuit, and wherein the output values stored in the output buffer are of a plurality of output channels in an interleaved manner., 12. The method of claim 10 , further comprising: storing, by a filter storage of the convolution engine, the filter elements of the kernel; retrieving, by a filter switch circuit of the convolution engine, the filter elements from the filter storage; and providing, by the filter switch circuit, the filter elements to the computation core circuit., 13. The method of claim 10 , wherein the input buffer circuit stores (i) in a predetermined row and a column of memory location, first data values for a first subset of bits of a data unit in the input data, and (ii) in the row and another column adjacent to the column storing the first subset of bits, a second data value for a second subset of bits of the data unit., 14. The method of claim 13 , wherein the first subset of the bits is most significant bits of the data, and the second subset of the bits is least significant bits of the data., 15. The method of claim 10 , further comprising, by the computation core circuit, processing subsets of the multiplied values by the computation core circuit includes one of (i) accumulating of the subsets of the multiplied values to obtain an output value or (ii) selecting one of the multiplied values as an output value., 16. The method of claim 15 , further comprising, by a post-processing circuit of the convolution engine, performing a normalized cross correlation on the output value., 17. The method of claim 10 , wherein the group of the data values multiplied by the computation core circuit in a cycle define a portion of an image., 18. An image signal processor, comprising: an input buffer circuit configured to receive and store data values of a plurality of channels of input data in an interleaved manner; a datapath switch circuit coupled to the input buffer circuit and configured to retrieve a group of the data values stored in the input buffer circuit including a center data value and one or more neighboring data values separated from the center data value by one or more step values as defined by configuration information, a portion of the data values between the center data value and the one or more neighboring values skipped when the group of the data values is retrieved; and a computation core circuit coupled to the datapath switch circuit and configured to: receive the group of the data values from the datapath switch circuit and filter elements of a kernel for performing a convolution operation, and multiply each data value of the group of data values with a corresponding filter element to obtain multiplied values., 19. The image signal processor of claim 18 , further comprising an output buffer coupled to the computation core circuit, the output buffer configured to store output values from the computation core circuit., 20. The image signal processor of claim 19 , wherein the output values stored in the output buffer are of a plurality of output channels in an interleaved manner.\n",
            "Similarity Score: 0.6614\n",
            "\n",
            "\n",
            "Patent ID: 10606971\n",
            "PubMed Claim: 1. A system, comprising a processor to: receive a netlist comprising a complex coverage event that depends on at least one singular independent signal; detect that the complex coverage event can be separated into the singular independent signal and a logic state based on a structural logic analysis; and test the netlist based on the singular independent signal., 2. The system of claim 1 , wherein the processor is to separate the singular independent signal from the logic state in the complex coverage event to generate a partial coverage event comprising the logic state., 3. The system of claim 2 , wherein the processor is to determine an operation window in which the singular independent signal effects the complex coverage event based on the partial coverage event., 4. The system of claim 3 , wherein the processor is to drive the singular independent signal at the operation window to simulate the complex coverage event., 5. The system of claim 1 , wherein the processor is to: detect that the complex coverage event can be separated into a plurality of singular independent signals including the singular independent signal and the logic state based on the structural logic analysis; separate the plurality of singular independent signals from the logic state in the complex coverage event to generate a partial coverage event comprising the logic state; determine one or more operation windows in which the plurality of singular independent signals effect the complex coverage event based on the partial coverage event; and drive the plurality of singular independent signals at the one or more operation windows to simulate the complex coverage event., 6. The system of claim 1 , wherein the singular independent signal comprises an asynchronous interface signal., 7. The system of claim 1 , wherein the singular independent signal comprises an interrupt., 8. A computer-implemented method, comprising: receiving, via a processor, a netlist comprising a complex coverage event that depends on a singular independent signal; detecting, via the processor, that complex coverage event can be separated into the singular independent signal and a logic state based on a structural logic analysis; and testing, via the processor, the netlist based on the singular independent signal., 9. The computer-implemented method of claim 8 , comprising separating, via the processor, the singular independent signal from the complex coverage event to generate a partial coverage event comprising the logic state., 10. The computer-implemented method of claim 9 , comprising determining, via the processor, an operation window in which the singular independent signal effects the complex coverage event based on the partial coverage event., 11. The computer-implemented method of claim 10 , comprising driving, via the processor, the singular independent signal at the operation window to simulate the complex coverage event., 12. The computer-implemented method of claim 9 , comprising: detecting, via the processor, that the complex coverage event can be separated into a plurality of singular independent signals including the singular independent signal and the logic state based on the structural logic analysis; extracting, via the processor, the plurality of singular independent signals to generate the partial coverage event comprising the logic state; determining, via the processor, one or more operation windows in which the plurality of singular independent signals effect the complex coverage event based on the partial coverage event; and driving, via the processor, the plurality of singular independent signals at the one or more operation windows to simulate the complex coverage event., 13. The computer-implemented method of claim 8 , comprising analyzing coverage holes in the netlist to identify complex coverage events that depend on asynchronous interface signals., 14. The computer-implemented method of claim 8 , wherein the structural logic analysis comprises determining a number of paths for each signal received at a counter and identifying signals with more than one path as part of the logic state., 15. A computer program product comprising a computer-readable storage medium having program code embodied therewith, wherein the computer readable storage medium is not a transitory signal per se, the program code executable by a processor to cause the processor to: receive a netlist comprising a complex coverage event that depends on a singular independent signal; detect that complex coverage event can be separated into the singular independent signal and a logic state based on a structural logic analysis; and test the netlist based on the singular independent signal., 16. The computer program product of claim 15 , comprising program code executable by the processor to separate the singular independent signal from the complex coverage event to generate a partial coverage event comprising the logic state., 17. The computer program product of claim 16 , comprising program code executable by the processor to determine an operation window in which the singular independent signal effects a hard-to-hit coverage event based on the partial coverage event., 18. The computer program product of claim 17 , comprising program code executable by the processor to drive the singular independent signal at the operation window to simulate the hard-to-hit coverage event., 19. The computer program product of claim 16 , comprising program code executable by the processor to: detect that the complex coverage event can be separated into a plurality of singular independent signals including the singular independent signal and the logic state based on the structural logic analysis; separate the plurality of singular independent signals from the logic state to generate the partial coverage event comprising the logic state; determine one or more operation windows in which the plurality of singular independent signals effect the complex coverage event based on the partial coverage event; and drive the plurality of singular independent signals at the one or more operation windows to simulate the complex coverage event., 20. The computer program product of claim 15 , comprising program code executable by the processor to determine a number of paths for each signal received at a counter and identifying signals with more than one path as part of the logic state.\n",
            "Similarity Score: 0.6549\n",
            "\n",
            "\n",
            "Patent ID: 10606931\n",
            "PubMed Claim: 1. A system, comprising: one or more storage devices; one or more processors; and a memory comprising program instructions executable by the one or more processors to: store compressed entity information for a plurality of entities in a hierarchical conditional random field model on the one or more storage devices, wherein each entity is represented as an entity node that forms a subtree in the model, wherein mentions associated with each entity are stored as leaf nodes of the respective entity node; wherein each mention is represented in the model as a low-dimensional fixed-width feature vector comprising n features, wherein the feature vectors are compressed according to a locality sensitive hash (LSH) function H that, for a feature vector a, stores a dot product a��h i as the hash of a such that H(a) is an array of dot products of lengt, 2. The system as recited in claim 1 , wherein the program instructions are further executable by the one or more processors to compute cosine similarity between entity nodes in the model based on the compressed feature vectors., 3. The system as recited in claim 1 , wherein the program instructions are further executable by the one or more processors to add compressed feature vectors to the compressed entity information without requiring the feature vectors to be added to original uncompressed entity information and recompressing the entity information., 4. The system as recited in claim 1 , wherein the program instructions are further executable by the one or more processors to subtract compressed feature vectors from the compressed entity information without requiring the feature vectors to be subtracted from original uncompressed entity information and recompressing the entity information., 5. The system as recited in claim 1 , wherein the program instructions are further executable by at least one of the one or more processors to: determine, based on the compressed entity information, that two entity nodes in the model refer to a same entity; and merge the two entity nodes in the model without requiring the compressed entity information to be decompressed., 6. The system as recited in claim 5 , wherein, to merge the two entity nodes, the program instructions are further executable by the one or more processors to add the compressed feature vectors of the two entity nodes without requiring the compressed entity information to be decompressed., 7. The system as recited in claim 1 , wherein a subtree formed by an entity node has one or more intermediate nodes that organize subsets of the entity's mentions as leaf nodes, wherein the program instructions are further executable by at least one of the one or more processors to: determine, based on the compressed entity information, that an intermediate node of an entity node refers to a different entity; and split the intermediate node from the entity node's subtree in the model to form a new subtree in the model with the intermediate node as the entity node without requiring the compressed entity information to be decompressed., 8. The system as recited in claim 7 , wherein, to split the intermediate node from the entity node's subtree in the model, the program instructions are further executable by the one or more processors to subtract the compressed feature vectors of the intermediate node from the entity node without requiring the compressed entity information to be decompressed., 9. A method, comprising: performing, by a computer system comprising one or more processors: compressing feature vectors representing mentions associated with entities according to a locality sensitive hash (LSH) function H that, for a feature vector a, stores a dot product a��h i as the hash of a such that H(a) is an array of dot products of length n; and storing the compressed feature vectors as compressed entity information for a plurality of entities in a hierarchical conditional random field model on one or more storage devices, wherein each entity is represented as an entity node that forms a subtree in the model, wherein compressed feature vectors representing mentions associated with each entity are stored as leaf nodes of the respective entity n, 10. The method as recited in claim 9 , further comprising computing cosine similarity between entity nodes in the model based on the compressed feature vectors without decompressing the entity information., 11. The method as recited in claim 9 , further comprising adding a compressed feature vector to the compressed entity information without decompressing the entity information., 12. The method as recited in claim 9 , further comprising subtracting a compressed feature vector from the compressed entity information without decompressing the entity information., 13. The method as recited in claim 9 , further comprising: determining, based on the compressed entity information, that two entity nodes in the model refer to a same entity; and merging the two entity nodes in the model without requiring the compressed entity information to be decompressed., 14. The method as recited in claim 13 , wherein merging the two entity nodes comprises adding the compressed feature vectors of the two entity nodes without requiring the compressed entity information to be decompressed., 15. The method as recited in claim 9 , wherein a subtree formed by an entity node has one or more intermediate nodes that organize subsets of the entity's mentions as leaf nodes, the method further comprising: determining, based on the compressed entity information, that an intermediate node of an entity node refers to a different entity; and splitting the intermediate node from the entity node's subtree in the model to form a new subtree in the model with the intermediate node as the entity node without requiring the compressed entity information to be decompressed., 16. The method as recited in claim 15 , wherein splitting the intermediate node from the entity node's subtree in the model comprises subtracting the compressed feature vectors of the intermediate node from the entity node without requiring the compressed entity information to be decompressed., 17. A non-transitory, computer-readable storage medium storing program instructions that when executed on one or more computers cause the one or more computers to: compress feature vectors representing mentions associated with entities according to a locality sensitive hash (LSH) function H that, for a feature vector a, stores a dot product a��h i as the hash of a such that H(a) is an array of dot products of length n; and store the compressed feature vectors as compressed entity information for a plurality of entities in a hierarchical conditional random field model on one or more storage devices, wherein each entity is represented as an entity node that forms a subtree in the model, wherein compressed feature vectors representing mentions associated with each entity are stored as leaf nodes of the respective entity n, 18. The non-transitory, computer-readable storage medium of claim 17 , wherein the program instructions when executed further cause the one or more computers to compute cosine similarity between entity nodes in the model based on the compressed feature vectors., 19. The non-transitory, computer-readable storage medium of claim 17 , wherein the program instructions when executed further cause the one or more computers to add a compressed feature vector to the compressed entity information without requiring the feature vector to be added to original uncompressed entity information and recompressing the entity information., 20. The non-transitory, computer-readable storage medium of claim 17 , wherein the program instructions when executed further cause the one or more computers to subtract a compressed feature vector from the compressed entity information without requiring the feature vector to be subtracted from original uncompressed entity information and recompressing the entity information.\n",
            "Similarity Score: 0.6529\n",
            "\n",
            "\n",
            "Patent ID: 10606981\n",
            "PubMed Claim: 1. A computer-implemented method for space frame design, comprising: constructing a load stress map in a geometrical boundary representation of a design space; defining a plurality of attachment points and load application points in the design space; creating a starting network of interconnecting lines between each two of the plurality of attachment points and load application points in the design space; assigning load application factors to each line of the starting network of interconnecting lines based on values of the load stress map; generating a plurality of potential space frame designs by selectively culling different subsets of lines of the starting network of interconnecting lines for each potential space frame design according to variable culling parameters; evaluating a performance score of each of the plurality of potential space frame designs with respect to a number of predefined optimization parameters; combining the culling parameters for the potential space frame designs the performance score of which is above a predefined performance threshold; and iterating the steps of generating the plurality of potential space frame designs and evaluating the performance score of each of the plurality of potential space frame designs on the basis of the combined culling parameters., 2. The computer-implemented method according to claim 1 , wherein the culling parameters are selected from the group of global line density, local line density and line length., 3. The computer-implemented method according to claim 1 , further comprising enriching the starting network of interconnecting lines with reinforcement lines between a node on one of the interconnecting lines and one of the plurality of attachment points and load application points in the design space or between two nodes on neighboring ones of the interconnecting lines., 4. The computer-implemented method according to claim 3 , wherein the culling parameters are selected from the group of node position on the interconnecting lines and length of the reinforcement lines., 5. The computer-implemented method according to claim 1 , wherein evaluating the performance score of each of the plurality of potential space frame designs is performed using a finite element analysis., 6. The computer-implemented method according to claim 1 , wherein the potential space frame designs are clustered in a multi-variate optimization parameter diagram to find space frame designs near a Pareto frontier., 7. The computer-implemented method according to claim 1 , wherein the iteration of the steps of generating the plurality of potential space frame designs and evaluating the performance score of each of the plurality of potential space frame designs is terminated when an increment in performance score for subsequently generated potential space frame designs falls below a termination threshold., 8. The computer-implemented method according to claim 1 , further comprising generating a truss model with a microstructural framework for each line in the starting network of interconnecting lines of selected ones of the potential space frame designs on the basis of corresponding values of the load stress map., 9. The computer-implemented method according to claim 8 , wherein the truss models are employed as input geometry for an additive manufacturing, AM, process for manufacturing a plurality of space frame rods., 10. The computer-implemented method according to claim 8 , further comprising sub-dividing a plurality of space frame rods into a number of partial space frame rods having a predefined maximum length., 11. A non-transitory computer-readable medium including instructions that, when executed by a processor, cause the processor to perform the steps of: constructing a load stress map in a geometrical boundary representation of a design space; defining a plurality of attachment points and load application points in the design space; creating a starting network of interconnecting lines between each two of the plurality of attachment points and load application points in the design space; assigning load application factors to each line of the starting network of interconnecting lines based on values of the load stress map; generating a plurality of potential space frame designs by selectively culling different subsets of lines of the starting network of interconnecting lines for each potential space frame design according to variable culling parameters; evaluating a performance score of each of the plurality of potential space frame designs with respect to a number of predefined optimization parameters; combining the culling parameters for the potential space frame designs the performance score of which is above a predefined performance threshold; and iterating the steps of generating the plurality of potential space frame designs and evaluating the performance score of each of the plurality of potential space frame designs on the basis of the combined culling parameters., 12. The non-transitory computer-readable medium according to claim 11 , wherein the culling parameters are selected from the group of global line density, local line density and line length., 13. The non-transitory computer-readable medium according to claim 11 , further comprising enriching the starting network of interconnecting lines with reinforcement lines between a node on one of the interconnecting lines and one of the plurality of attachment points and load application points in the design space or between two nodes on neighboring ones of the interconnecting lines., 14. The non-transitory computer-readable medium according to claim 13 , wherein the culling parameters are selected from the group of node position on the interconnecting lines and length of the reinforcement lines., 15. The non-transitory computer-readable medium according to claim 11 , wherein evaluating the performance score of each of the plurality of potential space frame designs is performed using a finite element analysis., 16. The non-transitory computer-readable medium according to claim 11 , wherein the potential space frame designs are clustered in a multi-variate optimization parameter diagram to find space frame designs near a Pareto frontier., 17. The non-transitory computer-readable medium according to claim 11 , wherein the iteration of the steps of generating the plurality of potential space frame designs and evaluating the performance score of each of the plurality of potential space frame designs is terminated when an increment in performance score for subsequently generated potential space frame designs falls below a termination threshold., 18. The non-transitory computer-readable medium according to claim 11 , further comprising generating a truss model with a microstructural framework for each line in the starting network of interconnecting lines of selected ones of the potential space frame designs on the basis of corresponding values of the load stress map., 19. The non-transitory computer-readable medium according to claim 18 , wherein the truss models are employed as input geometry for an additive manufacturing, AM, process for manufacturing a plurality of space frame rods., 20. The non-transitory computer-readable medium according to claim 18 , further comprising sub-dividing a plurality of space frame rods into a number of partial space frame rods having a predefined maximum length., 21. A system, comprising: a memory that includes instructions; and a processor that is coupled to the memory and, when executing the instructions, is configured to perform the steps of: constructing a load stress map in a geometrical boundary representation of a design space; defining a plurality of attachment points and load application points in the design space; creating a starting network of interconnecting lines between each two of the plurality of attachment points and load application points in the design space; assigning load application factors to each line of the starting network of interconnecting lines based on values of the load stress map; generating a plurality of potential space frame designs by selectively culling different subsets of lines of the starting network of interconnecting lines for each potential space frame design according to variable culling parameters; evaluating a performance score of each of the plurality of potential space frame designs with respect to a number of predefined optimization parameters; combining the culling parameters for the potential space frame designs the performance score of which is above a predefined performance threshold; and iterating the steps of generating the plurality of potential space frame designs and evaluating the performance score of each of the plurality of potential space frame designs on the basis of the combined culling parameters.\n",
            "Similarity Score: 0.6499\n",
            "\n",
            "\n",
            "Patent ID: 10606909\n",
            "PubMed Claim: 1. A computer-implemented method for optimizing searches, the method comprising: receiving a boolean search query comprising a plurality of operands and corresponding operators and usage information corresponding to a user, wherein the usage information is stored in a cookie and comprises user browsing information, user language preferences, and user file type preferences; determining a search load of a search engine located on a search server, wherein the search load includes an amount of resources of the search server that are being utilized; in response to determining that the search load is greater than a pre-defined threshold, determining modifications to be made to the boolean search query according to the usage information; modifying the boolean search query according to the modifications; and performing a search using the modified boolean search query., 2. The method of claim 1 , wherein: an operand of the boolean search query is an OR operand; and modifying the boolean search query comprises removing the OR operand and a corresponding OR operator., 3. The method of claim 2 , wherein the OR operand comprises a resource that the user has not accessed after a selected time threshold., 4. The method of claim 2 , wherein the OR operand comprises a resource that has not been updated after a selected time threshold., 5. The method of claim 1 , wherein: the user browsing information stored in the cookie includes a list of resources that the user accesses, corresponding access times for the list of resources, and corresponding access frequencies for the list of resources, the user language preferences stored in the cookie include a first language and a second language, and the user file type preferences include one or more preferred file types and codecs., 6. The method of claim 5 , wherein determining modifications to be made to the boolean search query according to the usage information comprises: in response to determining the search load exceeds a first utilization threshold, removing, from the boolean search query, an operand determined to be the third least-popular operand based on the list of resources that the user accesses., 7. The method of claim 6 , wherein determining modifications to be made to the boolean search query according to the usage information further comprises: in response to determining the search load exceeds a second utilization threshold, removing, from the boolean search query: (i) an operand determined to be the second least-popular operand based on the list of resources that the user accesses, and (ii) a second language preference., 8. The method of claim 7 , wherein determining modifications to be made to the boolean search query according to the usage information further comprises: in response to determining the search load exceeds a third utilization threshold, removing, from the boolean search query: (i) an operand determined to be the next least-popular operand based on the list of resources that the user accesses, and (ii) a preferred file type., 9. The method of claim 1 , wherein: an operand of the boolean search query is an AND operand; and modifying the boolean search query comprises adding an additional AND operand and a corresponding AND operator., 10. The method of claim 9 , wherein the additional AND operand comprises a language., 11. The method of claim 9 , wherein the additional AND operand comprises a file type.\n",
            "Similarity Score: 0.6270\n",
            "\n",
            "\n",
            "Patent ID: 10606856\n",
            "PubMed Claim: 1. A method, comprising: ingesting, by a data intake and query system, collected data including metrics data, the metrics data including a plurality of key values and a plurality of numerical values, each numerical value being indicative of a measured characteristic of a computing resource; populating, by the data intake and query system, a first portion of a metric-series index (msidx) file with the plurality of key values and a second portion of the msidx file with the plurality of numerical values, the first portion being distinct from the second portion; generating, by the data intake and query system, a plurality of metrics from the metrics data, each metric having a plurality of dimensions populated with at least some of the plurality of key values and having one of the plurality of numerical values; and indexing, by the data intake and query system, the plurality of metrics by at least one of the plurality of dimensions, wherein data of an indexed metric is searchable based on the first portion of the msidx file., 2. The method of claim 1 , further comprising: receiving, by the data intake and query system, a query including a criterion; and evaluating, by the data intake and query system, the query by applying the criterion to only the first portion of the msidx file to obtain query results indicative of metrics that satisfy the criterion., 3. The method of claim 1 , wherein each numerical value of the plurality of numerical values is a floating point value., 4. The method of claim 1 , wherein the metrics data is semi-structured data or structured data., 5. The method of claim 1 , wherein the measured characteristic of a computing resource is a utilization of a processor, a temperature of an electronic component, or a voltage reading of an electronic component., 6. The method of claim 1 , wherein the metrics data is received by the data intake and query system over a computer network from a plurality of remote computer systems., 7. The method of claim 1 , wherein each of the plurality of dimensions is either a required dimension or an optional dimension, wherein each of the plurality of metrics includes a value for each required dimension, and wherein only some of the plurality of metrics include values for some optional dimensions., 8. The method of claim 1 , wherein the plurality of dimensions includes a plurality of required dimensions, and wherein each metric includes a value for each required dimension., 9. The method of claim 1 , wherein the plurality of dimensions includes a time dimension, the time dimension including a value indicative of when the measured characteristic of the metric was measured, and a name dimension indicative of (a) the measured characteristic and (b) the computing resource of the numerical value., 10. The method of claim 1 , wherein the plurality of dimensions includes optional dimensions, and wherein only some of the plurality of metrics include values for some optional dimensions., 11. The method of claim 1 , wherein: the plurality of dimensions includes a host dimension, a manufacturer dimension, and a model dimension; and only some of the plurality of metrics include values for the host dimension, the manufacturer dimension, or the model dimension., 12. The method of claim 1 , wherein the plurality of dimensions includes a user specified dimension selected by a user prior to ingesting the metrics data., 13. The method of claim 1 , wherein at least some of the plurality of numerical values are indicative of a time series of measured characteristics of a single computing resource., 14. The method of claim 1 , wherein the collected data includes raw machine data, the method further comprising: generating, by the data intake and query system, a plurality of events indexed by timestamps, each of the plurality of events including a respective segment of the raw machine data., 15. The method of claim 1 , wherein the collected data includes raw machine data, the method further comprising: generating, by the data intake and query system, a plurality of events indexed by timestamps, each of the plurality of events including a respective segment of the raw machine data; and correlating, by the data intake and query system, the plurality of events and the plurality of metrics., 16. The method of claim 1 , further comprising, prior to ingesting the collected data: causing, by the data intake and query system, a forwarder to collect the collected data, the collected data being selected from a group consisting of: only raw data; raw data and structured metrics data; and only structured metrics data; and receiving, by the data intake and query system, the collected data over a computer network., 17. The method of claim 1 , further comprising, prior to ingesting the collected data: causing, by the data intake and query system, a forwarder to collect and locally index the collected data, the collected data being selected from a group consisting of: only raw data; raw data and structured metrics data; and only structured metrics data; and receiving, by the data intake and query system, the collected data over a computer network., 18. The method of claim 1 , further comprising, prior to ingesting the collected data: causing, by the data intake and query system, a script running on a remote computer system to collect the metrics data from an application running on the remote computer system, the application including the script; and receiving, by the data intake and query system, the metrics data over an HTTP-based connection of a computer network., 19. The method of claim 1 , further comprising, prior to ingesting the collected data: causing, by the data intake and query system, a background process of a remote computer system to collect the metrics data from an application running on the remote computer system, the background process being functionally independent of the application; and receiving, by the data intake and query system, the metrics data over a computer network., 20. The method of claim 1 , further comprising, prior to ingesting the collected data: causing, by the data intake and query system, a collector running on a remote computer system to collect metrics data from the remote computing system; and receiving, by the data intake and query system, the metrics data over a computer network., 21. The method of claim 1 , further comprising, prior to ingesting the collected data: causing, by the data intake and query system, a collector running on a remote computer system to collect and aggregate metrics data from the remote computing system to produce the collected data; and receiving, by the data intake and query system, the collected data over a computer network., 22. The method of claim 1 , further comprising, prior to ingesting the collected data: receiving, by the data intake and query system, a command causing the data intake and query system to obtain the metrics data using an add-on reusable software component., 23. The method of claim 1 , further comprising, prior to ingesting the collected data: calling, by the data intake and query system, an application programming interface, API, of a remote computer system to send the metrics data to the data intake and query system; and receiving, by the data intake and query system, the metrics data over a computer network., 24. The method of claim 1 , further comprising, prior to ingesting the collected data: receiving, by the data intake and query system, a command from a user to modify an add-on reusable software component; causing, by the data intake and query system, the modified add-on reusable software component to obtain the structured metrics data from a remote computer system; and receiving, by the data intake and query system, the structured metrics data over a computer network., 25. The method of claim 1 , further comprising, prior to ingesting the collected data: scheduling, by the data intake and query system, transfer of the metrics data collected by a plurality of collectors from a plurality of remote computer system; and receiving, by the data intake and query system, the structured metrics data over a computer network., 26. A method, comprising: ingesting, by a data intake and query system, raw data and metrics data, the metrics data including a plurality of key values and a plurality of numerical values, each numerical value being indicative of a measured characteristic of a computing resource; populating, by the data intake and query system, a first portion of a metric-series index (msidx) file with the plurality of key values and a second portion of the msidx file with the plurality of numerical values, the first portion being distinct from the second portion; generating, by the data intake and query system, a plurality of metrics from the metrics data, each metric having a plurality of dimensions populated with at least some of the plurality of key values and having one of the plurality of numerical values; generating, by the data intake and query system, a plurality of events including a timestamp and a segment of the raw data; and indexing, by the data intake and query system, the plurality of metrics by at least one of the plurality of dimensions, wherein data of an indexed metric is searchable based on the first portion of the msidx file; and indexing, by the data intake and query system, the plurality of events by the timestamps., 27. The method of claim 26 , further comprising: receiving, by the data intake and query system, a query having a scope that includes at least one of the plurality of metrics or the plurality of events, the query being input by a user and expressed in a pipelined search language; obtaining, by the data intake and query system, results satisfying the received query; and displaying, on a display device, the results or data indicative of the results., 28. The method of claim 26 , wherein each numerical value of the plurality of numerical values is a floating point value., 29. The method of claim 26 , wherein the metrics data is semi-structured data or structured data., 30. A data intake and query system comprising: a processor; and memory containing instructions that, when executed by the processor, cause the data intake and query system to: ingest collected data including metrics data, the metrics data including a plurality of key values and a plurality of numerical values, each numerical value being indicative of a measured characteristic of a computing resource; populate a first portion of a metric-series index (msidx) file with the plurality of key values and a second portion of the msidx file with the plurality of numerical values, the first portion being distinct from the second portion; generate a plurality of metrics from the metrics data, each metric having a plurality of dimensions populated with at least some of the plurality of key values and having one of the plurality of numerical values; and index the plurality of metrics by at least one of the plurality of dimensions, wherein data of an indexed metric is searchable based on the first portion of the msidx file.\n",
            "Similarity Score: 0.6263\n",
            "\n",
            "\n",
            "Patent ID: 10606749\n",
            "PubMed Claim: 1. A non-transitory computer-readable storage device storing instructions that, in response to execution, control a processor to perform operations, the operations comprising: receiving, from a member of a set of recommendation providers, a recommendation concerning whether or when to perform a storage management action on data stored in a collection of data storage devices that provide a multi-tier data store; selectively acting on the recommendation based on a credibility of the provider of the recommendation, where the credibility is based, at least in part, on a measure of a utility of a previous recommendation received from the provider; selectively updating the credibility of the member of the set of recommendation providers based, at least in part, on how the recommendation affects an optimization parameter of the multi-tier data store; selectively updating the credibility of members of the set of recommendation providers based, at least in part, on a rebalancing parameter; and selectively adapting the operation of the member of the set of recommendation providers by changing a likelihood that the member will make a recommendation about a portion of a file system stored by the multi-tier data store, changing the likelihood that the member will make a recommendation concerning a tier in the multi-tier data store, changing the likelihood that the member will make a recommendation concerning a type of device in the multi-tier data store, or changing the likelihood that the member will make a recommendation about flushing data, evicting data, recalling data, or deleting data from the multi-tier data store., 2. The non-transitory computer-readable storage device of claim 1 , where the storage management action is a flush operation, an evict operation, a recall operation, or a delete operation., 3. The non-transitory computer-readable storage device of claim 1 , where the credibility is further based, at least in part, on a measure of a consistency, a value, a worth, or an efficacy of a previous recommendation received from the provider., 4. A non-transitory computer-readable storage device storing computer executable instructions that when executed by a computer control the computer to perform a method, the method comprising: accessing a data storage transaction to be serviced by a device in a plurality of storage devices arranged in a multi-tier electronic data storage system, where the data storage transaction is a predicted transaction; selectively providing information about the data storage transaction to one or more members of a plurality of data movement recommenders; receiving, from a member of the plurality of data movement recommenders, a data movement recommendation, where the data movement recommendation is generated by a member of the plurality of data movement recommenders based on least recently used (LRU) reasoning, least frequently used (LFU) reasoning, large item eviction reasoning, small item eviction reasoning, space continuity reasoning, or weighted benefit analysis reasoning; performing a data movement action for a member of the plurality of storage devices based, at least in part, on the data movement recommendation and a credibility of the member of the plurality of data movement recommenders associated with the data movement recommendation, where the credibility is based, at least in part, on a utility of a previous recommendation received from the recommender; determining an impact of the data movement action on the multi-tier electronic data storage system; storing data relating the data movement action, the impact of the data movement action, and the data movement recommendation; selectively manipulating the credibility of the member of the plurality of data movement recommenders associated with the data movement recommendation based, at least in part, on the impact of the data movement action; and selectively collectively manipulating the credibility of members of the plurality of data movement recommenders based, at least in part, on determining a number of data movement actions performed for the member of the plurality of storage devices based on a data movement recommendation received from a member of the plurality of data movement recommenders, an amount of data moved for the member of the plurality of storage devices based on a data movement recommendation received from a member of the plurality of data movement recommenders, a time period, a cache hit rate for the multi-tier electronic data storage system falling below a threshold, or a response time for the multi-tier electronic data storage system exceeding a threshold, and further based on the cache hit rate for the multi-tier electronic data storage system and at least one of an actual size of the cache, or a derived size of the cache., 5. The non-transitory computer-readable storage device of claim 4 , where the data movement action is an evict action, a flush action, a recall action, or a delete action., 6. The non-transitory computer-readable storage device of claim 4 , where the credibility is further based, at least in part, on a measure of a consistency, a value, a worth, or an efficacy of a previous recommendation received from the recommender., 7. The non-transitory computer-readable storage device of claim 4 , where the impact of the data movement action is a projected impact., 8. The non-transitory computer-readable storage device of claim 4 , the method further comprising: changing a criterion upon which the credibility of members of the plurality of data movement recommenders is selectively collectively manipulated based, at least in part, on a change in a cache hit rate for the multi-tier electronic data storage system, on a change in a response time for the multi-tier electronic data storage system, on a change in a dollar cost for operating the multi-tier electronic data storage system, or on a change in an energy cost for operating the multi-tier electronic data storage system., 9. The non-transitory computer-readable storage device of claim 4 , where selectively manipulating the credibility of the member of the plurality of data movement recommenders is performed on a recommendation-by-recommendation basis, after a threshold number of data movement recommendations have been provided by the member of the plurality of data movement recommenders, or after a threshold period of time after the data movement action is performed., 10. An apparatus, comprising: a processor; a memory; a set of circuits; and a hardware interface that connects the processor, the memory, and the set of circuits; the set of circuits comprising: a first circuit configured to: receive a data storage request to be handled by a multi-tier data storage system; provide information about the data storage request to an advisor in a plurality of advisors; receive a recommendation from the advisor concerning whether, when, or how to move data in the multi-tier data storage system in response to the data storage request; selectively perform a data movement in the multi-tier data storage system based, at least in part, on the data storage request, the recommendation, and a weighting factor associated with the advisor; log information about the data storage request, the recommendation from the advisor, and the data movement; perform a retrospective analysis of a previous recommendation received from the advisor; update a credibility of the advisor based, at least in part, on a utility of the previous recommendation received from the advisor; a second circuit configured to: selectively determine an effect of the data movement on an optimization measure of the multi-tier data storage system during an interval of interest; a third circuit configured to: selectively adapt the weighting factor for the advisor upon determining that an update threshold has been met; and a fourth circuit configured to: selectively adapt an operation of a selected advisor in the plurality of advisors upon determining that an adaptation threshold has been met., 11. The apparatus of claim 10 , where the recommendation from the advisor is a flush recommendation, an evict recommendation, a recall recommendation, or a delete recommendation., 12. The apparatus of claim 10 , where the credibility is further based at least in part on a measure of a consistency, a value, a worth, or an efficacy of the previous recommendation received from the advisor., 13. The apparatus of claim 10 , where the second circuit is configured to selectively determine the effect of the data movement for less than each recommendation received from the plurality of advisors, and where the second circuit is configured to determine the interval of interest based on a time period, a point in time, a number of data movements performed, or an amount of data moved in the multi-tier data storage system., 14. The apparatus of claim 10 , where the third circuit is configured to selectively adapt the weighting factor for the advisor as part of a collective action that manipulates the weighting factor for two or more advisors in the plurality of advisors; and where the third circuit is configured to selectively adapt the weighting factor for the advisor based, at least in part, on the effect of the recommendation made by the advisor., 15. The apparatus of claim 10 , where the fourth circuit is configured to adapt the operation of the selected advisor by changing the likelihood that the selected advisor will: make a recommendation about a portion of a file system stored by the multi-tier data storage system, make a recommendation concerning a tier in the multi-tier data storage system, make a recommendation concerning a type of device in the multi-tier data storage system, or make a recommendation about flushing data, evicting data, recalling data, or deleting data.\n",
            "Similarity Score: 0.6246\n",
            "\n",
            "\n",
            "Patent ID: 10606819\n",
            "PubMed Claim: 1. A method of reducing a number of event records to be communicated between one or more user devices and a device configured to obtain event data relating to a plurality of users, said event records corresponding to one or more changes or updates relating to a user profile or goal, said method comprising: accessing a list of pending event records corresponding to one or more changes or updates relating to a user profile or goal at a server entity; determining whether a first one of said pending event records comprises a most recent event of an event record type associated to a single one of said plurality of users; when it is determined that said first one of said pending event records comprises said most recent event of said event record type associated to said single user, transmitting said first one of said pending event records to said device configured to obtain said event data; when it is determined that said first one of said pending event records does not comprise said most recent event of said event record type associated to said single user, omitting to transmit said first one of said pending event records to said device configured to obtain said event data such that the number of event records to be communicated is reduced; performing said acts of determining and transmitting or omitting for each additional event record listed in said list of pending event records; determining whether said first one of said pending event records comprises a record indicating a first user profile deletion associated to a first user profile; when it is determined that said first one of said pending event records comprises a record indicating said profile deletion associated to said first user profile, omitting to transmit other ones of said pending event records associated to said first user profile to said device configured to obtain said event data; and ending a transmission session when it is determined that no further event records are listed in said list of pending event records., 2. The method of claim 1 , further comprising determining whether said first one of said pending event records comprises a recognized event type., 3. The method of claim 2 , wherein when said first one of said pending event records does not comprise a recognized event type, said method further comprises transmitting said first one of said pending event records to said device configured to obtain said event data., 4. The method of claim 3 , wherein when said first one of said pending event records does not comprise a recognized event type, said method further comprises marking said first one of said pending event records as having been evaluated., 5. The method of claim 1 , wherein when it is determined that said first one of said pending event records comprises said most recent event of said event record type associated to said first user profile, or when it is determined that said first one of said pending event records does not comprise said most recent event of said event record type associated to said first user profile, said method further comprising marking said first one of said pending event records as having been evaluated., 6. A server apparatus for reducing transmission of a plurality of records relating to a respective plurality of events entered at one or more user devices to at least one health-monitoring device, said events corresponding to one or more changes or updates relating to a user profile or goal, said server apparatus comprising: at least one interface configured to enable communication with said at least one health-monitoring device; a storage entity; and a processor configured to communicate to said storage entity, and said at least one interface, said processor configured to execute a plurality of health-monitoring computer programs and at least one event management computer program thereon, said event management computer program comprising a plurality of instructions which are configured to, when executed by said processor, cause said server apparatus to: access a plurality of previously unevaluated event records corresponding to one or more changes or updates relating to a user profile or goal; determine whether a first one of said plurality of previously unevaluated event records comprises a most temporally recent event of an event record type associated to a first user profile within said plurality of said previously unevaluated event records; transmit said first one of said plurality of previously unevaluated event records to said at least one health-monitoring device when it is determined that said first one of said plurality of previously unevaluated event records comprises said most temporally recent event of said event record type associated to said first user profile within said plurality of said previously unevaluated event records; and not transmit said first one of said plurality of previously unevaluated event records to said at least one health-monitoring device when it is determined that said first one of said plurality of previously unevaluated event records does not comprise said most temporally recent event of said event record type associated to said first user profile, and thereby reduce a number of the plurality of event records transmitted by the server apparatus; place a marker on said first one of said plurality of previously unevaluated event records as having been evaluated; and determine based on a presence of said marker on each of said plurality of previously unevaluated event records that no further event records are pending, and end a transmission session., 7. The server apparatus of claim 6 , wherein said determination, transmission and non-transmission occur for each of said plurality of previously unevaluated event records., 8. The server apparatus of claim 6 , wherein said plurality of instructions are further configured to, when executed by said processor, cause said server apparatus to: determine whether said first one of said plurality of previously unevaluated event records comprises a recognized event type; and when said first one of said plurality of previously unevaluated event records does not comprise said recognized event type, transmit said first one of said plurality of previously unevaluated event records to said at least one health-monitoring device., 9. The server apparatus of claim 8 , wherein said recognized event type comprises at least one of: a profile-related update, a profile deletion, a goal-related update, and/or a goal deletion., 10. The server apparatus of claim 8 , wherein said plurality of instructions are further configured to, when executed by said processor, cause said server apparatus to: when said first one of said plurality of previously unevaluated event records does not comprise said recognized event type, place a marker on said first one of said plurality of previously unevaluated event records as having been evaluated., 11. The server apparatus of claim 6 , wherein said plurality of instructions are further configured to, when executed by said processor, cause said server apparatus to: when it is determined that said first one of said plurality of previously unevaluated event records comprises a record indicating a profile deletion associated to said first user profile, not transmit any other ones of said plurality of previously unevaluated event records associated to said first profile to said at least one health-monitoring device., 12. A non-transitory, computer readable medium comprising a plurality of instructions which are configured to, when executed: collect at a server entity a plurality of pending event records representative of a respective plurality of events entered at one or more user devices and communicated to said server entity via a network, wherein said pending event records correspond to one or more changes or updates initiated by said users relating to a user profile or goal thereof; receive a notification that a second device is able to accept one or more of said plurality of pending event records; apply one or more rules configured to identify for suppression first ones of said plurality of pending event records which are not required to be transmitted to said health monitoring device, and identify for transmission second ones of said plurality of pending event records which are required to be transmitted to said health monitoring device; cause said first ones of said plurality of pending event records to be marked as having been evaluated, wherein said first ones of said plurality of event records do not include most recent event records of event record types; cause said second ones of said plurality of pending event records to be marked as having been evaluated, said second ones of said plurality of event records including most recent event records of the event record types; cause said second ones of said plurality of pending event records to be transmitted to said health monitoring device without causing said first ones of said plurality of event records to be transmitted to said health monitoring device such that a number of event records transmitted to said health monitoring device is reduced; and end a transmission session when it is determined that all event records are marked as having been evaluated., 13. The non-transitory, computer readable medium of claim 12 , wherein said notification that said second device is able to accept said one or more of said plurality of event records comprises a notification generated when said second device is powered on., 14. The non-transitory, computer readable medium of claim 12 , wherein one or more rules configured to identify for suppression first ones of said plurality of event records which are not required to be transmitted to said health monitoring device comprise rules configured to identify redundant and/or irrelevant event records from among said plurality of event records., 15. The non-transitory, computer readable medium of claim 12 , wherein one or more rules configured to identify for transmission second ones of said plurality of event records which are required to be transmitted to said health monitoring device comprise rules configured to identify non-redundant and/or most relevant event records from among said plurality of event records., 16. A method of reducing a number of records to be communicated between a first plurality of devices and a second device, said method comprising: accessing a list at a server entity, said list comprising a plurality of pending event records corresponding to one or more changes or updates relating to a user profile or first goal, each of said plurality of pending event records being categorized by an event type thereof; for each event type, identifying a most recent one of said plurality of pending event records thereof; transmitting said identified most recent pending event record of said each event type; omitting to transmit those ones of said plurality of pending event records of said each event type which are not identified as being said most recent one thereof such that the number of event records to be communicated is reduced; ending a transmission session when it is determined that all of the pending event records have been transmitted or omitted to transmit., 17. The method of claim 16 further comprising: determining whether an identified most recent one of said plurality of pending event records is a profile deletion for a first user profile, and omitting to transmit subsequent pending event records associated to said first user profile when it is determined that said identified most recent one of said plurality of pending event records is a profile deletion for the first user profile.\n",
            "Similarity Score: 0.6236\n",
            "\n",
            "\n",
            "Patent ID: 10606842\n",
            "PubMed Claim: 1. A method of constructing data from different data providers in a correlated fashion, the method being performed by one or more processors of a computer system, the method comprising: performing a first query on a first data set controlled by a first entity to capture a first set of data results; performing a second query on a second data set controlled by a second entity to capture a second set of data results, wherein the second query is generated independently from the first query such that the second query is distinct from, and not dependent on, the first query; receiving a selection of one or more results from the first set of data results; subsequent to performing both the first query and the second query, using the selection of the one or more results from the first set of data results to: consult a relationship ontology that correlates data stored in different data stores controlled by different entities, the correlated data including correlations between the first data set controlled by the first entity and the second data set controlled by the second entity, and identify, from the relationship ontology, at least one relationship between data in the selection of the one or more results from the first set of data results and the second set of data results; and performing a new query over only the second data set to generate a new set of data results, the new query being constructed based on the identified at least one relationship such that the new set of data results are correlated with the selection of the one or more results from the first set of data results., 2. The method of claim 1 , wherein the at least one relationship stored in the relationship ontology is manually defined., 3. The method of claim 1 further comprising: performing an additional operation on the second set of data results based on the identified at least one relationship between the data in the selection from the first set of data results and the second set of data results., 4. The method of claim 3 , wherein the additional operation comprises highlighting an element in the second set of data results., 5. The method of claim 3 , wherein the additional operation comprises categorizing the second set of data results., 6. The method of claim 3 , the additional operation comprises sorting the second set of data results., 7. The method of claim 3 , wherein the additional operation comprises filtering the second set of data results., 8. The method of claim 1 , further comprising: displaying a correlation between the first set of data results and the second set of data results., 9. A system for constructing data from different data providers in a correlated fashion, the system comprising: one or more processors; and one or more computer readable hardware storage devices having stored thereon computer executable instructions that are executable by at least one of the one or more processors to cause the system to: perform a first query on a first data set controlled by a first entity to capture a first set of data results; perform a second query on a second data set controlled by a second entity to capture a second set of data results, wherein the second query is generated independently from the first query such that the second query is distinct from, and not dependent on, the first query; receive a selection of one or more results from the first set of data results; subsequent to performing both the first query and the second query, use the selection of the one or more results from the first set of data results to: consult a relationship ontology that correlates data stored in different data stores controlled by different entities, the correlated data including correlations between the first data set controlled by the first entity and the second data set controlled by the second entity, and identify, from the relationship ontology, at least one relationship between data in the selection of the one or more results from the first set of data results and the second set of data results; and perform a new query over only the second data set to generate a new set of data results, the new query being constructed based on the identified at least one relationship such that the new set of data results are correlated with the selection of the one or more results from the first set of data results., 10. The system of claim 9 , wherein the at least one relationship stored in the relationship ontology is manually defined., 11. The system of claim 9 , wherein execution of the computer-executable instructions further causes the system to: perform an additional operation on the second set of data results based on the identified at least one relationship between the data in the selection from the first set of data results and the second set of data results., 12. The system of claim 11 , wherein the additional operation comprises highlighting an element in the second set of data results., 13. The system of claim 11 , wherein the additional operation comprises filtering the second set of data results., 14. The system of claim 9 , wherein the first data set is stored in a first table that includes column labeling and the second data set is stored in a second table that also includes column labeling, and wherein the computer executable instructions further cause the system to: identify a first column of information in the first table, the first column including substantially similar information as a second column of information in the second table; identify a first column label corresponding to the first column, the first column label being named differently than a second column label corresponding to the second column; and in the relationship ontology, correlate the first column of information in the first table with the second column of information in the second table even though the first column label is named differently than the second column label., 15. The system of claim 14 , wherein the first column label is expressed using a first language while the second column label is expressed using a second language., 16. The system of claim 14 , wherein the second set of data results is displayed in a bar chart., 17. A physical computer readable hardware storage device comprising computer executable instructions that are executable by one or more processors to cause the one or more processors to: perform a first query on a first data set controlled by a first entity to capture a first set of data results; perform a second query on a second data set controlled by a second entity to capture a second set of data results, wherein the second query is generated independently from the first query such that the second query is distinct from, and not dependent on, the first query; receive a selection of one or more results from the first set of data results; subsequent to both the first query and the second query, use the selection of the one or more results from the first set of data results to: consult a relationship ontology that correlates data stored in different data stores controlled by different entities, the correlated data including correlations between the first data set controlled by the first entity and the second data set controlled by the second entity, and identify, from the relationship ontology, at least one relationship between data in the selection of the one or more results from the first set of data results and the second set of data results; and perform a new query over only the second data set to generate a new set of data results, the new query being constructed based on the identified at least one relationship such that the new set of data results are correlated with the selection of the one or more results from the first set of data results.\n",
            "Similarity Score: 0.6068\n",
            "\n",
            "\n",
            "Patent ID: 10606892\n",
            "PubMed Claim: 1. A system for partitioning a graph database, comprising: a processor; and a memory coupled with the processor, wherein the memory is configured to provide the processor with instructions which when executed cause the processor to: assign to a plurality of nodes a plurality of vertices of the graph database, wherein the vertices of the graph database are connected by edges that indicate relationships between the vertices; and designate a vertex of the graph database as a super-vertex that is split into a truncated vertex and at least one vertex representative, comprising to: identify abstract paths in the graph database, comprising to: identify traversal patterns based on database query samples for the graph database, a traversal pattern including a traversal between more than one vertex: identify common patterns in the traversal patterns, a common pattern including a commonality in a portion of or entire traversal patterns; identify abstract path patterns based on the common patterns; and identify the abstract paths based on the abstract path patterns and weights associated with the abstract path patterns; and assign one or more vertices to nodes based on the abstract paths between the vertices., 2. The system of claim 1 , wherein the truncated vertex is assigned to a main node and the at least one vertex representative is assigned to a different node., 3. The system of claim 2 , wherein a database query associated with the super-vertex received at the different node is handled by the different node using its assigned vertex representative without processing by the main node., 4. The system of claim 1 , wherein the truncated vertex is stored at a storage of a main node and the at least one vertex representative is stored at a storage of a different node., 5. The system of claim 1 , wherein the super-vertex was split in response to a determination that the super-vertex is connected to at least a threshold number of other vertices., 6. The system of claim 1 , wherein each vertex representative identifies one or more edges of the super-vertex that are not identified by the truncated vertex., 7. The system of claim 1 , wherein the vertex was designated as the super-vertex based on an indication from an administrator., 8. The system of claim 1 , wherein designating the vertex of the graph database as the super-vertex includes automatically detecting that the vertex meets a criteria to be designated as the super-vertex., 9. The system of claim 1 , wherein only edges of the super-vertex that match a criteria are eligible to be split to the at least one vertex representative from the truncated vertex., 10. The system of claim 9 , wherein the criteria specifies an edge directionality or edge label., 11. The system of claim 1 , wherein the truncated vertex retains edges directed away from the super-vertex., 12. The system of claim 1 , wherein the at least one vertex representative specifies a vertex-centric index including identifiers, labels, properties, or directionality of edges of the super-vertex., 13. The system of claim 1 , wherein the at least one vertex representative assigned to an assigned node includes an index listing any other vertices assigned to the assigned node that are also connected to the super-vertex., 14. The system of claim 1 , wherein in the event a connected vertex connected to the super-vertex and assigned to an assigned node that has also been assigned at least one vertex representative is removed from the assigned node, the at least one vertex representative is automatically modified to reflect the removal of the connected vertex., 15. The system of claim 1 , wherein the super-vertex is split into the truncated vertex and a plurality of vertex representatives., 16. The system of claim 15 , wherein each of the plurality of vertex representatives identifies a set of edges that are different from other vertex representatives., 17. The system of claim 15 , wherein the processor is configured to process a database query of the graph database associated with the super-vertex, each of a plurality of nodes assigned to each of the plurality of vertex representatives is instructed to perform processing with respect to its assigned vertex representative and results from the plurality of nodes are combined to determine a response to the database query., 18. The system of claim 1 , wherein the super-vertex is one of a plurality of super-vertices of the graph database., 19. A method for partitioning a graph database, comprising: assigning to a plurality of nodes a plurality of vertices of the graph database, wherein the vertices of the graph database are connected by edges that indicate relationships between the vertices; and using a processor to designate a vertex of the graph database as a super-vertex that is split into a truncated vertex and at least one vertex representative, comprising: identifying abstract paths in the graph database, comprising: identifying traversal patterns based on database query samples for the graph database, a traversal pattern including a traversal between more than one vertex, identifying common patterns in the traversal patterns, a common pattern including a commonality in a portion of or entire traversal patterns; identifying abstract path patterns based on the common patterns; and identifying the abstract paths based on the abstract path patterns and weights associated with the abstract path patterns; and assigning one or more vertices to nodes based on the abstract paths between the vertices., 20. A computer program product for partitioning a graph database, the computer program product being embodied in a non-transitory computer readable storage medium and comprising computer instructions for: assigning to a plurality of nodes a plurality of vertices of the graph database, wherein the vertices of the graph database are connected by edges that indicate relationships between the vertices; and designating a vertex of the graph database as a super-vertex that is split into a truncated vertex and at least one vertex representative, comprising: identifying abstract paths in the graph database, comprising: identifying traversal patterns based on database query samples for the graph database, a traversal pattern including a traversal between more than one vertex; identifying common patterns in the traversal patterns, a common pattern including a commonality in a portion of or entire traversal patterns; identifying abstract path patterns based on the common patterns; and identifying the abstract paths based on the abstract path patterns and weights associated with the abstract path patterns; and assigning one or more vertices to nodes based on the abstract paths between the vertices.\n",
            "Similarity Score: 0.6063\n",
            "\n",
            "\n",
            "Patent ID: 10606885\n",
            "PubMed Claim: 1. A computer-implemented system, running on numerous parallel processors, for providing expanded data object correlations for user-generated web customizations, comprising: an insertion module that creates an initial plurality of candidate data object image representations by procreation in dependence upon a data object image having a plurality of dimensions, with at least some dimensions of the data object image modified by user-generated web customizations; a memory storing a candidate population having the plurality of candidate data object image representations; an evaluation module that scores each of the candidate data object image representations for conformity with a predefined goal using a trained neural network system and/or a rule rule-based percept filter; a competition module that discards candidate data object image representations from the candidate population which are scored as being less in conformity with the predefined goal than other candidate data object image representations in the candidate population; a procreation module that adds new data object image representations to the candidate population by procreation in dependence upon the candidate data object image representations not discarded by the competition module; a control module that iterates the evaluation module, the competition module, and the procreation module until the competition module yields a candidate pool of candidate data object image representations not yet discarded but which satisfy a convergence condition; and a harvesting module providing as recommendation for display to a user at least one of the data object images represented in the candidate pool of candidate data object image representations not selected for discarding but which satisfy the convergence condition., 2. The system of claim 1 , wherein procreating the data object image having the plurality of dimensions further comprises mutating one or more dimension values of the dimensions., 3. The system of claim 1 , wherein the data object image is selected from a recommended collection of data object images that was presented toward to the user., 4. The system of claim 1 , wherein the user-generated web customizations are manual modifications of one or more image features of a prior data object image., 5. The system of claim 4 , wherein the prior data object image is one previously recommended toward the user., 6. The system of claim 4 , wherein the prior data object image is one previously customized and/or selected by the user., 7. The system of claim 1 , wherein the procreation further comprises crossing-over two or more parent candidate data object image representations not discarded by the competition module., 8. The system of claim 1 , wherein the procreation further comprises crossing-over two or more parent candidate data object image representations not discarded by the competition module and mutating a resulting child data object image representation procreated by the crossing-over., 9. The system of claim 1 , wherein the predefined goal is visual similarity of image features of the image representations with image features of a set of target image representations., 10. The system of claim 1 , wherein the predefined goal is visual conformance of image features of the image representations with a set of perception metrics., 11. The system of claim 1 , wherein the rule-based percept filter enforces visual conformance of image features of the image representations with a set of perception metrics., 12. The system of claim 1 , wherein the trained neural network system further comprises a plurality of neural networks trained to achieve conformity with different predefined goals in dependence upon respective thresholds., 13. A computer-implemented method of providing expanded data object correlations for user-generated web customizations, including: creating an initial plurality of candidate data object image representations by procreation in dependence upon a data object image having a plurality of dimensions, with at least some dimensions of the data object image modified by user-generated web customizations; storing a candidate population having the plurality of candidate data object image representations; scoring each of the candidate data object image representations for conformity with a predefined goal using a trained neural network system and/or a rule rule-based percept filter; discarding candidate data object image representations from the candidate population which are scored as being less in conformity with the predefined goal than other candidate data object image representations in the candidate population; adding new data object image representations to the candidate population by procreation in dependence upon the candidate data object image representations not discarded; iterating the scoring, the discarding, and the adding until the discarding yields a candidate pool of candidate data object image representations not yet discarded but which satisfy a convergence condition; and providing as recommendation for display to a user at least one of the data object images represented in the candidate pool of candidate data object image representations not selected for discarding but which satisfy the convergence condition., 14. A non-transitory, computer-readable medium having computer executable instructions that implement the method of claim 13 .\n",
            "Similarity Score: 0.6059\n",
            "\n",
            "\n",
            "Patent ID: 10606899\n",
            "PubMed Claim: 1. A computer-implemented method, comprising: receiving a search query; determining a first set of categories associated with the search query, where each category of the first set of categories includes one or more words that describe one or more aspects of the search query, and each of the first set of categories associated with the search query includes a slash tag unique to a predetermined subject, the slash tag including a grouping of identifiers of locations of a plurality of documents; determining a second set of categories associated with preliminary results of the search query; and filtering the preliminary results of the search query, including removing a subset of the preliminary results of the search query based on a comparison of the first set of categories to the second set of categories., 2. The computer-implemented method of claim 1 , wherein a reverse lookup is performed for the search query using a dynamic inference map in order to determine the first set of categories, and determining the second set of categories associated with preliminary results of the search query includes: identifying the preliminary results of the search query by performing a search utilizing the search query and a search index, extracting textual data from each of the preliminary results of the search query by crawling the preliminary results of the search query, identifying one or more key words within the extracted textual data, utilizing latent dirichlet allocation (LDA) analysis, and mapping the one or more key words onto a predetermined set of categories to determine the second set of categories., 3. The computer-implemented method of claim 1 , wherein determining the first set of categories includes: categorizing one or more words within the search query, and performing a reverse lookup for the search query using a dynamic inference map to determine the first set of categories, wherein each category of the first set of categories has an associated confidence score indicating a strength of a match between the category and the search query., 4. The computer-implemented method of claim 1 , wherein filtering the preliminary results of the search query includes: ranking each of the preliminary results of the search query according to matching categories and associated confidence levels determined between the first set of categories and the second set of categories, and returning a predetermined number of the ranked preliminary results., 5. The computer-implemented method of claim 1 , wherein filtering the preliminary results includes: comparing the first set of categories to the second set of categories to determine matching categories, where each of the matching categories includes an associated confidence score, determining an overall match score for each the preliminary results of the search query, utilizing to the matching categories and the associated confidence score for each of the matching categories, and for each of the preliminary results of the search query, returning the preliminary result in response to determining that the overall match score for the preliminary result exceeds a threshold., 6. The computer-implemented method of claim 1 , wherein filtering the preliminary results includes returning each of the preliminary results of the search query only if its overall match score exceeds a predetermined threshold., 7. The computer-implemented method of claim 1 , wherein determining the second set of categories associated with preliminary results of the search query includes extracting textual data from each of the preliminary results of the search query, where: the preliminary results of the search query include a plurality of URLs, and the textual data extracted includes data extracted from a plurality of web pages pointed to by the plurality of URLs., 8. The computer-implemented method of claim 7 , wherein determining the second set of categories associated with preliminary results of the search query includes determining a plurality of key words from the textual data, utilizing latent dirichlet allocation (LDA) analysis., 9. The computer-implemented method of claim 8 , wherein determining the second set of categories associated with preliminary results of the search query includes mapping the plurality of key words to a predetermined set of categories, where each of the plurality of key words maps to one or more categories of the predetermined set of categories., 10. A computer program product for categorically filtering search results, the computer program product comprising a computer readable storage medium having program instructions embodied therewith, wherein the computer readable storage medium is not a transitory signal per se, the program instructions executable by a processor to cause the processor to perform a method comprising: receiving a search query, utilizing the processor; determining, utilizing the processor, a first set of categories associated with the search query, where each category of the first set of categories includes one or more words that describe one or more aspects of the search query, and each of the first set of categories associated with the search query includes a slash tag unique to a predetermined subject, the slash tag including a grouping of identifiers of locations of a plurality of documents; determining, utilizing the processor, a second set of categories associated with preliminary results of the search query; and filtering, utilizing the processor, the preliminary results of the search query, including removing a subset of the preliminary results of the search query based on a comparison of the first set of categories to the second set of categories., 11. The computer program product of claim 10 , wherein a reverse lookup is performed for the search query using a dynamic inference map in order to determine the first set of categories., 12. The computer program product of claim 10 , wherein a confidence level is associated with each category within the first set of categories., 13. The computer program product of claim 10 , wherein determining the second set of categories associated with preliminary results of the search query includes identifying the preliminary results of the search query by performing a search utilizing the search query., 14. The computer program product of claim 10 , wherein filtering the preliminary results includes removing a subset of the preliminary results of the search query according to a comparison of the first set of categories to the second set of categories., 15. The computer program product of claim 10 , wherein filtering the preliminary results includes determining an overall match score for each of the preliminary results of the search query., 16. The computer program product of claim 15 , wherein filtering the preliminary results includes returning each of the preliminary results of the search query only if its overall match score exceeds a predetermined threshold., 17. The computer program product of claim 10 , wherein determining the second set of categories associated with preliminary results of the search query includes extracting textual data from each of the preliminary results of the search query., 18. The computer program product of claim 17 , wherein determining the second set of categories associated with preliminary results of the search query includes determining a plurality of key words from the textual data, utilizing latent dirichlet allocation (LDA) analysis., 19. A system, comprising: a processor; and logic integrated with the processor, executable by the processor, or integrated with and executable by the processor, the logic being configured to: receive a search query; determine a first set of categories associated with the search query, where each category of the first set of categories includes one or more words that describe one or more aspects of the search query, and each of the first set of categories associated with the search query includes a slash tag unique to a predetermined subject, the slash tag including a grouping of identifiers of locations of a plurality of documents; determine a second set of categories associated with preliminary results of the search query; and filter the preliminary results of the search query, including removing a subset of the preliminary results of the search query based on a comparison of the first set of categories to the second set of categories.\n",
            "Similarity Score: 0.6050\n",
            "\n",
            "\n",
            "Patent ID: 10606987\n",
            "PubMed Claim: 1. A computer-implemented method, comprising: obtaining, at an interface of a computing system, information that includes job codes of users of the computing system and access permissions assigned to the users; generating, based at least in part on the information, an initial value corresponding to a probability of a role being associated with a user; perturbing a candidate value corresponding to the probability to produce a perturbed value corresponding to the probability, the candidate value being associated with a first score and based at least in part on the initial value; calculating a second score based at least in part on passing the perturbed value as input to an objective function that minimizes at least one ambiguous assignment penalty function for measuring correctness of the role being associated with the user; setting, as a result of an evaluation of the second score against the first score, the perturbed value to be the candidate value; storing the candidate value as an entry in a candidate solution matrix, wherein the candidate solution matrix is configured to store a plurality of perturbed values associated with information for assigning roles to users; and assigning, as a result of a comparison of the candidate value in the candidate solution matrix to a threshold, the role to the user such that the user accesses one or more computing resources associated with the role., 2. The computer-implemented method of claim 1 , wherein calculating the second score further includes weighting the objective function based at least in part on an importance value associated with the role., 3. The computer-implemented method of claim 1 , further comprising: identifying an anomalous user role assignment; and providing a report of the anomalous user role assignment., 4. The computer-implemented method of claim 3 , wherein identifying the anomalous user role assignment includes determining that: the candidate value is within a range that indicates uncertainty that the user is associated with the role; at least one of the users has no assigned role; or at least one role, determined based at least in part on the information, is unassigned., 5. The computer-implemented method of claim 1 , wherein the objective function further minimizes redundant roles., 6. A system, comprising: one or more processors; and memory to store computer-executable instructions that, as a result of being executed by the one or more processors, cause the system to: obtain information that indicates permissions of users associated with the system; generate, based at least in part on the information, an initial probability value of a role being associated with a user; perturb a candidate probability value to produce a perturbed probability value, the candidate probability value based at least in part on the initial probability value; calculate a first score based at least in part on the candidate probability value and a second score based at least in part on passing the perturbed probability value as input to an objective function that minimizes at least one ambiguous assignment penalty function for measuring the correctness of the perturbed value; set, as a result of an evaluation of the second score against the first score, the perturbed probability value to be the candidate probability value; generate a matrix to store the candidate probability value as an entry in the matrix, the entry representing a probability of whether the role is associated with the user; assign, as a result of a comparison of the candidate probability value of the matrix to a threshold, the role to the user; and enforce access to one or more computing resources by the user in accordance with the role as a result of the comparison., 7. The system of claim 6 , wherein the information includes: data from an access control list; cryptographic key information; or data from a security policy., 8. The system of claim 6 , wherein the information includes: a job description of the user; a job code of the user; or a reporting structure associated with the user., 9. The system of claim 6 , wherein the computer-executable instructions that cause the system to perturb the candidate probability value includes computer-executable instructions that further cause the system to: perturb a probability value based at least in part on the initial probability value to produce a second perturbed probability value with a third score; and determine, based at least in part on an evaluation of the third score against the second score, that the candidate probability value is more optimal than the second perturbed probability value., 10. The system of claim 6 , wherein the computer-executable instructions that cause the system to calculate the first score and the second score includes computer-executable instructions that further cause the system to penalize a probability value that lies within a particular range by applying a penalty weight to the probability value., 11. The system of claim 6 , wherein the computer-executable instructions that cause the system to perturb the candidate probability value further cause the system to normalize the perturbed probability value to ensure that the perturbed probability value remains below a threshold., 12. The system of claim 6 , wherein the second score is further computed by weighting the objective function based at least in part on an importance value associated with the role., 13. The system of claim 12 , wherein the penalty function involves one or more of: counting a number of roles that comprise a non-zero probability of being assigned to a user; counting a number of different roles that are assignable to a particular user; or counting a number of different users that are assignable to a particular role., 14. A non-transitory computer-readable storage medium that stores executable instructions that, as a result of being executed by one or more processors of a computer system, cause the computer system to: determine a first probability that indicates a probability value that a user of the computing system is associated with a role, the first probability comprising a first score; perturb, by an objective function that minimizes at least one ambiguous assignment penalty function, the first probability to determine a second probability comprising a second score; evaluate the second score against the first score using a penalty function to determine that the second probability indicates a more optimal probability of the user being associated with the role than the first probability; set, based on the evaluation, the second probability as an entry in a matrix configured to store a plurality of probabilities indicating whether to assign the role to the user; and assign, based at least in part on the entry in matrix, the role to the user such that the user accesses one or more computing resources provided by the computer system., 15. The non-transitory computer-readable storage medium of claim 14 , wherein the executable instructions that cause the computer system to perturb the first probability cause the computer system to: perturb the first probability to produce a third probability comprising a third score; evaluate the third probability against the first score to determine that the third probability indicates a more optimal probability of the user being associated with the role than the first probability; and perturb the third probability to produce the second probability., 16. The non-transitory computer-readable storage medium of claim 14 , wherein the executable instructions that cause the computer system to perturb the first probability further cause the computer system to normalize the second probability to ensure that the second probability remains below a threshold., 17. The non-transitory computer-readable storage medium of claim 14 , wherein the executable instructions that cause the computer system to perturb the first probability cause the computer system to increase or decrease the first probability by a random amount., 18. The non-transitory computer-readable storage medium of claim 14 , wherein the executable instructions that cause the computer system to determine the second probability include executable instructions that cause the computer system to determine the second probability based at least in part on a metaheuristic algorithm., 19. The non-transitory computer-readable storage medium of claim 18 , wherein the metaheuristic algorithm is a genetic algorithm or a probabilistic algorithm., 20. The non-transitory computer-readable storage medium of claim 14 , wherein the executable instructions that cause the computer system to determine the second probability include executable instructions that cause the computer system to determine the second probability based at least in part on a numerical optimization algorithm., 21. The non-transitory computer-readable storage medium of claim 20 , wherein: the numerical optimization algorithm is a gradient descent optimization function; and the executable instructions that cause the computer system to determine that that the second probability indicates the more optimal probability include executable instructions that cause the computer system to: compute the first score and the second score by including the first probability and the second probability as inputs to the gradient descent optimization function; and determine that the second score is closer to a local minimum than the first score.\n",
            "Similarity Score: 0.6050\n",
            "\n",
            "\n",
            "Patent ID: 10606836\n",
            "PubMed Claim: 1. A system comprising: a local monitoring data management apparatus; a communication network; and one or more monitoring apparatuses that use the communication network to transmit and receive monitoring data with respect to electric power generation information of a photovoltaic power generation cloud system, wherein the local monitoring data management apparatus: identifies the monitoring data as one of structured monitoring data and unstructured monitoring data using flag information of the monitoring data, wherein the unstructured monitoring data is selected from the group consisting of a graph, an image, and audio information, wherein the structured monitoring data has a table structure or a tree structure in which a field is structured; stores the monitoring data in a relational database on the basis of an identification result of the monitoring data, wherein the photovoltaic power generation cloud system communicates with the one or more local monitoring apparatuses to receive the monitoring data; converts the structured monitoring data into unstructured monitoring data using a data conversion condition comprising a preset field value among the field value of the structured monitoring data or searches the structured monitoring data corresponding to a preset data format among the structured monitoring data and converts the structured monitoring data, which is combined with apparatus identification information of the one or more monitoring apparatuses the same as the apparatus identification information among the searched structured monitoring data, into the unstructured monitoring data, wherein the local monitoring data management apparatus uses the data conversion condition if the field value of the structured monitoring data is the same as the preset field value, wherein the field value includes regional information, monitoring time information, and monitoring date information, and wherein the local monitoring data management apparatus verifies the apparatus identification information that is combined with the structured monitoring data corresponding to the preset data format; and performs a big data analysis from the unstructured monitoring data to produce estimated electric power generation information of the photovoltaic power generation cloud system located at different geographic regions on the basis of the graph and calculate an estimated price using the analyzed data., 2. The system of claim 1 , wherein the local monitoring data management apparatus collects the monitoring data from the one or more monitoring apparatuses., 3. The system of claim 2 , wherein the local monitoring data management apparatus collects the monitoring data by combining the apparatus identification information of the one or more monitoring apparatuses with the monitoring data.\n",
            "Similarity Score: 0.6049\n",
            "\n",
            "\n",
            "Patent ID: 10606847\n",
            "PubMed Claim: 1. A computer implemented method, comprising: obtaining one or more sample ideal candidate member profiles in a social networking service; obtaining one or more sample search result member profiles in the social networking service, the one or more sample search result member profiles being results returned in response to searches performed using the one or more sample ideal candidate member profiles as input; identifying one or more pairs of sample ideal candidate member profiles and sample search result member profile, wherein each pair includes a sample ideal candidate member profile and a sample search result member profile returned in response to a search performed using the corresponding sample ideal candidate member profile in the pair as input; generating, for each unique pair of sample ideal candidate member profile and sample search result member profile, a label using a score generated from log information of the social networking service, the log information including records of communications between a searcher and members of the social networking service, the score being different if the searcher communicated with both the member corresponding to the sample ideal candidate member profile and the member corresponding to the sample search result member profile in a same search session than if the searcher did not communicate with both the member corresponding to the sample ideal candidate member profile and the member corresponding to the sample search result member profile in the same search session, the label being indicative of the likelihood that the searcher would interact with the sample search result member profile in the pair in response to the search being performed using the corresponding sample ideal candidate member profile as input; and feeding the generated labels into a machine learning algorithm to train a combined ranking model used to output ranking scores for search result member profiles., 2. The method of claim 1 , wherein the score is a medium score between the score if the searcher did communicate with both the member corresponding to the sample ideal candidate member profile and the member corresponding to the sample search result member profile in the same session and the score if the searcher did not communicate with both the member corresponding to the sample ideal candidate member profile and the member corresponding to the sample search result member profile in the same session if the log information further includes records of user input by the searcher, the user input causing interaction with member profiles in the social networking service but not resulting in communications between the searcher and the member of the social networking service corresponding to both the sample ideal candidate member profile and the sample search result member profile in the same search session., 3. The method of claim 1 , wherein a search session is a browsing session., 4. The method of claim 1 , wherein a search session includes a period of time between a searcher initiating a search and the searcher submitting an unrelated search or logging off the social networking service., 5. The method of claim 2 , wherein the score if the searcher communicated with both the member corresponding to the sample ideal candidate member profile and the member corresponding to the sample search result member profile in a same search session is higher than the score if the searcher did not communicate with both the member corresponding to the sample ideal candidate member profile and the member corresponding to the sample search result member profile in the same search session., 6. The method of claim 1 , further comprising aggregating label scores from multiple search sessions., 7. The method of claim 1 , further comprising ranking one or more search result member profiles using the combined ranking model., 8. A system comprising: a hardware processor; and a computer-readable medium having instructions stored thereon, which, when executed by the processor, cause the system to: obtain one or more sample ideal candidate member profiles in a social networking service; obtain one or more sample search result member profiles in the social networking service, the one or more sample search result member profiles being results returned in response to searches performed using the one or more sample ideal candidate member profiles as input; identify one or more pairs of sample ideal candidate member profiles and sample search result member profile, wherein each pair includes a sample ideal candidate member profile and a sample search result member profile returned in response to a search performed using the corresponding sample ideal candidate member profile in the pair as input; generate, for each unique pair of sample ideal candidate member profile and sample search result member profile, a label using a score generated from log information of the social networking service, the log information including records of communications between a searcher and members of the social networking service, the score being different if the searcher communicated with both the member corresponding to the sample ideal candidate member profile and the member corresponding to the sample search result member profile in a same search session than if the searcher did not communicate with both the member corresponding to the sample ideal candidate member profile and the member corresponding to the sample search result member profile in the same search session, the label being indicative of the likelihood that the searcher would interact with the sample search result member profile in the pair in response to the search being performed using the corresponding sample ideal candidate member profile as input; and feed the generated labels into a machine learning algorithm to train a combined ranking model used to output ranking scores for search result member profiles., 9. The system of claim 8 , wherein the score is a medium score between the score if the searcher did communicate with both the member corresponding to the sample ideal candidate member profile and the member corresponding to the sample search result member profile in the same session and the score if the searcher did not communicate with both the member corresponding to the sample ideal candidate member profile and the member corresponding to the sample search result member profile in the same session if the log information further includes records of user input by the searcher, the user input causing interaction with member profiles in the social networking service but not resulting in communications between the searcher and the member of the social networking service corresponding to both the sample ideal candidate member profile and the sample search result member profile in the same search session., 10. The system of claim 8 , wherein a search session is a browsing session., 11. The system of claim 8 , wherein a search session includes a period of time between a searcher initiating a search and the searcher submitting an unrelated search or logging off the social networking service., 12. The system of claim 9 , wherein the score if the searcher communicated with both the member corresponding to the sample ideal candidate member profile and the member corresponding to the sample search result member profile in a same search session is higher than the score if the searcher did not communicate with both the member corresponding to the sample ideal candidate member profile and the member corresponding to the sample search result member profile in the same search session., 13. The system of claim 8 , wherein the instructions further cause the system to aggregate label scores from multiple search sessions., 14. The system of claim 8 , wherein the instructions further cause the system to rank one or more search result member profiles using the combined ranking model., 15. A non-transitory machine-readable storage medium comprising instructions, which when implemented by one or more machines, cause the one or more machines to perform operations comprising: obtaining one or more sample ideal candidate member profiles in a social networking service; obtaining one or more sample search result member profiles in the social networking service, the one or more sample search result member profiles being results returned in response to searches performed using the one or more sample ideal candidate member profiles as input; identifying one or more pairs of sample ideal candidate member profiles and sample search result member profile, wherein each pair includes a sample ideal candidate member profile and a sample search result member profile returned in response to a search performed using the corresponding sample ideal candidate member profile in the pair as input; generating, for each unique pair of sample ideal candidate member profile and sample search result member profile, a label using a score generated from log information of the social networking service, the log information including records of communications between a searcher and members of the social networking service, the score being different if the searcher communicated with both the member corresponding to the sample ideal candidate member profile and the member corresponding to the sample search result member profile in a same search session than if the searcher did not communicate with both the member corresponding to the sample ideal candidate member profile and the member corresponding to the sample search result member profile in the same search session, the label being indicative of the likelihood that the searcher would interact with the sample search result member profile in the pair in response to the search being performed using the corresponding sample ideal candidate member profile as input; and feeding the generated labels into a machine learning algorithm to train a combined ranking model used to output ranking scores for search result member profiles., 16. The non-transitory machine-readable storage medium of claim 15 , wherein the score is a medium score between the score if the searcher did communicate with both the member corresponding to the sample ideal candidate member profile and the member corresponding to the sample search result member profile in the same session and the score if the searcher did not communicate with both the member corresponding to the sample ideal candidate member profile and the member corresponding to the sample search result member profile in the same session if the log information further includes records of user input by the searcher, the user input causing interaction with member profiles in the social networking service but not resulting in communications between the searcher and the member of the social networking service corresponding to both the sample ideal candidate member profile and the sample search result member profile in the same search session., 17. The non-transitory machine-readable storage medium of claim 15 , wherein a search session is a browsing session., 18. The non-transitory machine-readable storage medium of claim 15 , wherein a search session includes a period of time between a searcher initiating a search and the searcher submitting an unrelated search or logging off the social networking service., 19. The non-transitory machine-readable storage medium of claim 16 , wherein the score if the searcher communicated with both the member corresponding to the sample ideal candidate member profile and the member corresponding to the sample search result member profile in a same search session is higher than the score if the searcher did not communicate with both the member corresponding to the sample ideal candidate member profile and the member corresponding to the sample search result member profile in the same search session., 20. The non-transitory machine-readable storage medium of claim 15 , wherein the instructions further comprise aggregating label scores from multiple search sessions.\n",
            "Similarity Score: 0.6033\n",
            "\n",
            "\n",
            "Patent ID: 10606863\n",
            "PubMed Claim: 1. A method for monotonic transactions in a multi-master database with a plurality of nodes that are loosely coupled, the method comprising: electing, by a processor, a special node from the plurality of nodes based on a consensus protocol; and performing, by the processor, a write transaction protocol including: a client device issuing a write transaction at any one particular node of the plurality of nodes; recording the write transaction locally at the one particular node of the plurality of nodes and asynchronously replicating the write transaction to at least one other node of the plurality of nodes; and waiting for reception of an acknowledgment from at least a write quorum of the plurality of nodes before returning a response to the client device, wherein the write quorum is any set of the plurality of nodes that includes the special node and at least one other node, and after a commit transaction for storing data from the write transaction to the multi-master database, an initiator node of the plurality of nodes waits to receive an acknowledgement for the commit transaction without ever timing out, and waits for replication of a transaction log to the set of nodes of the write quorum before returning a success result notification for the commit transaction for providing data consistency and visibility of the write transaction for the plurality of nodes., 2. The method of claim 1 , wherein the write quorum and the read quorum each further includes a number of other nodes of the plurality of that are selected based on a durability requirement., 3. The method of claim 1 , wherein upon determining the client device timed out during waiting for receiving an acknowledgment from the multi-master database, the client device obtains status of the write transaction by issuing at least one read transaction., 4. The method of claim 3 , further comprising: upon determining timeout by the client device of the at least one read transaction, repeating, by the client device, the at least one read transaction., 5. The method of claim 1 , further comprising: performing, by the processor, a read transaction protocol including: issuing read transactions at any one of the plurality of nodes; attempting to return rows that are known to be replicated by at least a read quorum of the plurality of nodes; and for timing-out of the attempting to return rows known to be replicated by at least the read quorum of the plurality of nodes based on the special-node being non-responsive: selecting a new special-node from the plurality of nodes; and repeating attempting to return rows that are known to be replicated by at least the read quorum of the plurality of nodes., 6. The method of claim 5 , further comprising: assigning weights to the plurality of nodes including the special node, wherein a weight assigned to the special-node exceeds weights assigned to remaining nodes of the plurality of nodes, write quorum voting is based on a first sum of voting nodes weights being equal to or greater than a write quorum threshold, and read quorum voting is based on a second sum of voting nodes weights being equal to or greater than a read quorum threshold., 7. The method of claim 5 , wherein the selecting of the new special-node is performed by the processor upon a transaction failure or non-responsiveness of the special node., 8. A computer program product for monotonic transactions in a multi-master database with a plurality of nodes that are loosely coupled, the computer program product comprising a computer readable storage medium having program instructions embodied therewith, the program instructions executable by a processor to cause the processor to: elect, by the processor, a special node from the plurality of nodes based on a consensus protocol; and perform, by the processor, a write transaction protocol including: a client device issuing a write transaction at any one particular node of the plurality of nodes; recording the write transaction locally at the one particular node of the plurality of nodes and asynchronously replicating the write transaction to at least one other node of the plurality of nodes; and waiting for reception of an acknowledgment from at least a write quorum of the plurality of nodes before returning a response to the client device, wherein the write quorum is any set of the plurality of nodes that includes the special node and at least one other node, and after a commit transaction for storing data from the write transaction to the multi-master database, an initiator node of the plurality of nodes waits to receive an acknowledgement for the commit transaction without ever timing out and waits for replication of a transaction log to the set of nodes of the write quorum before returning a success result notification for the commit transaction for providing data consistency and visibility of the write transaction for the plurality of nodes., 9. The computer program product of claim 8 , wherein upon determining the client device timed out during waiting for receiving an acknowledgment from the multi-master database, the client device obtains status of the write transaction by issuing at least one read transaction., 10. The computer program product of claim 8 , wherein the write quorum and the read quorum each further includes a number of other nodes of the plurality of nodes that are selected based on a durability requirement., 11. The computer program product of claim 8 , further comprising program instructions executable by the processor to cause the processor to: perform, by the processor, a read transaction protocol including further program instructions executable by the processor to cause the processor to: issue read transactions at any one of the plurality of nodes; attempt to return rows that are known to be replicated by at least a read quorum of the plurality of nodes; and for timing out of the attempting to return rows known to be replicated by at least the read quorum of the plurality of nodes based on the special-node being non-responsive: select a new special-node from the plurality of nodes; and repeat attempting to return rows that are known to be replicated by at least the read quorum of the plurality of nodes., 12. The computer program product of claim 11 , wherein the selecting of the new special-node is performed by the processor upon a transaction failure or non-responsiveness of the special node., 13. The computer program product of claim 11 , further comprising: upon determining timeout of the at least one read transaction, repeating, by the client device, the at least one read transaction., 14. The computer program product of claim 11 , wherein selecting of the new special-node is performed by the processor upon a transaction failure or non-responsiveness of the special node., 15. The computer program product of claim 11 , further comprising program instructions executable by the processor to cause the processor to: assign, by the processor, weights to the plurality of nodes including the special node, wherein a weight assigned to the special-node exceeds weights assigned to remaining nodes of the plurality of nodes, and write quorum voting is based on a first sum of voting nodes weights being equal to or greater than a write quorum threshold, and read quorum voting is based on a second sum of voting nodes weights being equal to or greater than a read quorum threshold., 16. An apparatus comprising: a memory configured to store instructions; and a processor configured to execute the instructions to: elect a special node from a plurality of nodes that are loosely coupled in a multi-master database based on a consensus protocol; and perform a write transaction protocol including: a client device issuing a write transaction at any one particular node of the plurality of nodes; recording the write transaction locally at the one particular node of the plurality of nodes and asynchronously replicating the write transaction to at least one other node of the plurality of nodes; waiting for reception of an acknowledgment from at least a write quorum of the plurality of nodes before returning a response to the client device, wherein the write quorum is any set of the plurality of nodes that includes the special node and at least one other node; and after a commit transaction for storing data from the write transaction to the multi-master database, waiting by an initiator node of the plurality of nodes to receive an acknowledgement for the commit transaction, without ever timing out, and waiting for replication of a transaction log to the set of nodes of the write quorum before returning a success result notification for the commit transaction for providing data consistency and visibility of the write transaction for the plurality of nodes., 17. The apparatus of claim 16 , wherein: upon determining the client device timed out during waiting for receiving an acknowledgment from the multi-master database, the client device obtains status of the write transaction by issuing at least one read transaction., 18. The apparatus of claim 17 , wherein: upon determining timeout of the at least one read transaction, repeating, by the client device, the at least one read transaction., 19. The apparatus of claim 16 , wherein the processor is further configured to: perform a read transaction protocol including: issue read transactions at any one of the nodes of the plurality of nodes; attempt to return rows that are known to be replicated by at least a read quorum of the plurality of nodes; and for timing out of the attempting to return rows known to be replicated by at least the read quorum of the plurality of nodes based on the special-node being non-responsive: select a new special-node; and repeat attempting to return rows that are known to be replicated by at least the read quorum of the plurality of nodes., 20. The apparatus of claim 19 , wherein: selection of the new special-node is performed by the processor upon a transaction failure or non-responsiveness of the special node; and the write quorum and the read quorum each further includes a number of other nodes of the plurality of nodes that are selected based on a durability requirement., 21. The apparatus of claim 19 , wherein the processor is further configured to: assign weights to the plurality of nodes including the special node, wherein a weight assigned to the special-node exceeds weights assigned to remaining nodes of the plurality of nodes, and write quorum voting is based on a first sum of voting nodes weights being equal to or greater than a write quorum threshold, and read quorum voting is based on a second sum of voting nodes weights being equal to or greater than a read quorum threshold.\n",
            "Similarity Score: 0.6030\n",
            "\n",
            "\n",
            "Patent ID: 10606875\n",
            "PubMed Claim: 1. A search support apparatus for widening a range of a user's interest, the apparatus comprising: a hardware processor configured to: analyze a clipped document to obtain location information indicating a location of an original document which is an origination from which the clipped document is obtained; acquire an updated document by referring to the location information if the original document has been updated, the updated document being the updated original document; measure a first update frequency of the original document; extract one or more first keywords from the clipped document; weight each keyword extraction algorithm from a plurality of keyword extraction algorithms based at least in part on an update pattern corresponding to a time span of the first update frequency among a high-frequency update pattern, a periodic update pattern, and a no-update pattern; select a keyword extraction algorithm from the plurality of keyword extractions algorithms based on the weight of each keyword extraction algorithm, wherein the keyword extraction algorithm extracts at least one different keyword from the updated document than at least one other keyword extraction algorithm from the plurality of keyword extraction algorithms; extract one or more second keywords from the updated document using a first keyword extraction scheme which is set in accordance with the first update frequency, the first keyword extraction scheme including the keyword extraction algorithm; and a storage which stores the one or more first keywords, the one or more second keywords and the update document each associated with the clipped document., 2. The apparatus according to claim 1 , wherein the hardware processor is further configured to: extract a word feature amount of a query document which serves as a search query; and search the storage for a relevant document which is a clipped document having a level of similarity with the word feature amount no less than a threshold; and wherein the apparatus further comprises a display configured to display the query document, the relevant document, and at least one of an updated document associated with the relevant document and the one or more second keywords associated with the relevant document., 3. The apparatus according to claim 1 , wherein the hardware processor is further configured to: analyze the clipped document and the updated document to obtain link information indicating a link to other documents; acquire a link destination document by referring to the link information, the link destination document being a linked-to document; measure a second update frequency of the link destination document; and extract one or more third keywords from the link destination document, using a second keyword extraction scheme in accordance with the second update frequency, the second keyword extraction scheme including a keyword extraction algorithm selected from the plurality of keyword extraction algorithms based on an update pattern corresponding to a time span of the second update frequency among the high-frequency update pattern, the periodic update pattern, and the no-update pattern; and wherein the storage further stores the link destination document and the one or more third keywords each associated with the clipped document., 4. The apparatus according to claim 3 , wherein the hardware processor extracts the one or more third keywords from domains of logical elements and fields related to a layout of the updated document set in accordance with the second update frequency., 5. The apparatus according to claim 1 , wherein the hardware processor is further configured to: extract a word feature amount of a query document which serves as a search query; and search the storage for a relevant document which is a clipped document having a level of similarity with the word feature amount no less than a threshold; and wherein the apparatus further comprises a display configured to display the query document, the relevant document, and at least one of an updated document associated with the relevant document, a link destination document associated with the relevant document, the one or more second keywords associated with the relevant document and the one or more third keywords associated with the relevant document., 6. The apparatus according to claim 1 , wherein the hardware processor extracts the one or more second keywords from domains of logical elements and fields related to a layout of the updated document set in accordance with the first update frequency., 7. A search support method for widening a range of a user's interest, the method comprising: analyzing a clipped document to obtain location information indicating a location of an original document which is an origination from which the clipped document is obtained; acquiring an updated document by referring to the location information if the original document has been updated, the updated document being the updated original document; measuring a first update frequency of the original document; extracting one or more first keywords from the clipped document; weighting each keyword extraction algorithm from a plurality of keyword extraction algorithms based at least in part on an update pattern corresponding to a time span of the first update frequency among a high-frequency update pattern, a periodic update pattern, and a no-update pattern; selecting a keyword extraction algorithm from the plurality of keyword extractions algorithms based on the weight of each keyword extraction algorithm, wherein the keyword extraction algorithm extracts at least one different keyword from the updated document than at least one other keyword extraction algorithm from the plurality of keyword extraction algorithms; extracting one or more second keywords from the updated document using a first keyword extraction scheme which is set in accordance with the first update frequency, the first keyword extraction scheme including the keyword extraction algorithm; and storing, in a storage, the one or more first keywords, the one or more second keywords and the update document each associated with the clipped document., 8. The method according to claim 7 , further comprising: extracting a word feature amount of a query document which serves as a search query; searching the storage for a relevant document which is a clipped document having a level of similarity with the word feature amount no less than a threshold; and presenting the query document, the relevant document, and at least one of an updated document associated with the relevant document and the one or more second keywords associated with the relevant document., 9. The method according to claim 7 , further comprising: analyzing the clipped document and the updated document to obtain link information indicating a link to other documents; acquiring a link destination document by referring to the link information, the link destination document being a linked-to document; measuring a second update frequency of the link destination document; extracting one or more third keywords from the link destination document, using a second keyword extraction scheme in accordance with the second update frequency, the second keyword extraction scheme including a keyword extraction algorithm selected from the plurality of keyword extraction algorithms based on an update pattern corresponding to a time span of the second update frequency among the high-frequency update pattern, the periodic update pattern, and the no-update pattern; and storing, in the storage, the link destination document and the one or more third keywords each associated with the clipped document., 10. The method according to claim 9 , wherein the extracting extracts the one or more third keywords from domains of logical elements and fields related to a layout of the updated document set in accordance with the second update frequency., 11. The method according to claim 7 , further comprising: extracting a word feature amount of a query document which serves as a search query; searching the storage for a relevant document which is a clipped document having a level of similarity with the word feature amount no less than a threshold; and presenting the query document, the relevant document, and at least one of an updated document associated with the relevant document, a link destination document associated with the relevant document, the one or more second keywords associated with the relevant document and the one or more third keywords associated with the relevant document., 12. The method according to claim 7 , wherein the extracting extracts the one or more second keywords from domains of logical elements and fields related to a layout of the updated document set in accordance with the first update frequency., 13. A non-transitory computer readable medium including computer executable instructions, wherein the instructions, when executed by a processor, cause the processor to perform a method for widening a range of a user's interest, the method comprising: analyzing a clipped document to obtain location information indicating a location of an original document which is an origination from which the clipped document is obtained; acquiring an updated document by referring to the location information if the original document has been updated, the updated document being the updated original document; measuring a first update frequency of the original document; extracting one or more first keywords from the clipped document; weighting each keyword extraction algorithm from a plurality of keyword extraction algorithms based at least in part on an update pattern corresponding to a time span of the first update frequency among a high-frequency update pattern, a periodic update pattern, and a no-update pattern; selecting a keyword extraction algorithm from the plurality of keyword extractions algorithms based on the weight of each keyword extraction algorithm, wherein the keyword extraction algorithm extracts at least one different keyword from the updated document than at least one other keyword extraction algorithm from the plurality of keyword extraction algorithms; extracting one or more second keywords from the updated document using a first keyword extraction scheme which is set in accordance with the first update frequency, the first keyword extraction scheme including the keyword extraction algorithm; and storing, in a storage, the one or more first keywords, the one or more second keywords and the update document each associated with the clipped document., 14. The medium according to claim 13 , further comprising: extracting a word feature amount of a query document which serves as a search query; searching the storage for a relevant document which is a clipped document having a level of similarity with the word feature amount no less than a threshold; and presenting the query document, the relevant document, and at least one of an updated document associated with the relevant document and the one or more second keywords associated with the relevant document., 15. The medium according to claim 13 , further comprising: analyzing the clipped document and the updated document to obtain link information indicating a link to other documents; acquiring a link destination document by referring to the link information, the link destination document being a linked-to document; measuring a second update frequency of the link destination document; extracting one or more third keywords from the link destination document, using a second keyword extraction scheme in accordance with the second update frequency, the second keyword extraction scheme including a keyword extraction algorithm selected from the plurality of keyword extraction algorithms based on an update pattern corresponding to a time span of the second update frequency among the high-frequency update pattern, the periodic update pattern, and the no-update pattern; and storing, in the storage, the link destination document and the one or more third keywords each associated with the clipped document., 16. The medium according to claim 15 , wherein the extracting extracts the one or more third keywords from domains of logical elements and fields related to a layout of the updated document set in accordance with the second update frequency., 17. The medium according to claim 13 , further comprising: extracting a word feature amount of a query document which serves as a search query; searching the storage for a relevant document which is a clipped document having a level of similarity with the word feature amount no less than a threshold; and presenting the query document, the relevant document, and at least one of an updated document associated with the relevant document, a link destination document associated with the relevant document, the one or more second keywords associated with the relevant document and the one or more third keywords associated with the relevant document., 18. The medium according to claim 13 , wherein the extracting extracts the one or more second keywords from domains of logical elements and fields related to a layout of the updated document set in accordance with the first update frequency.\n",
            "Similarity Score: 0.6011\n",
            "\n",
            "\n",
            "Patent ID: 10606834\n",
            "PubMed Claim: 1. A method for optimizing query execution, the method comprising: identifying, in a query execution plan compiled for a query, a plurality of target operators that includes an expression that computes a common value; for at least one target operator of the plurality of target operators, modifying a row input of the at least one target operator to add a column to receive an evaluation result comprising the common value from a storage device; performing, by a database server connected to the storage device, the query execution plan by: sending, to the storage device, the expression that computes the common value, and receiving, within the column, the common value from the storage device; wherein the method is performed by one or more computing devices., 2. The method of claim 1 , further comprising: determining whether a number of target operators identified satisfies a threshold; wherein said modifying is performed in response to determining that the number of target operators identified satisfies the threshold., 3. The method of claim 1 , wherein the storage device returns a set of rows that includes the evaluation result., 4. The method of claim 1 , wherein the expression is a hash computation on a common hash key., 5. The method of claim 1 , wherein modifying a row input of the at least one target operator comprises: traversing operators of a query execution tree to identify a first target operator that is a hash-user; wherein the first target operator includes an expression for computing a hash value from a particular hash key; traversing a subtree of the query execution tree using the first target operator as a root to identify one or more operators in the subtree that are also hash-users; for each hash-user identified in the subtree, determining whether a hash key is identical to the particular hash key; in response to determining that the hash-user includes a hash key that is identical to the particular hash key, marking the hash-user as a target operator., 6. The method of claim 1 , wherein modifying a row input of the at least one target operator comprises: for one or more target operators of the at least one target operator, replacing the expression with a reference to a shared expression; wherein replacing the expression with a reference to a shared expression causes a respective target operator to access the evaluation result without computing the evaluation result., 7. The method of claim 1 , wherein modifying a row input of the at least one target operator comprises assigning responsibility for evaluating the expression to a single target operator of the at least one target operator; wherein the responsibility is assigned to a first target operator in a dataflow of a query execution tree., 8. The method of claim 1 , wherein the plurality of target operators include different target operators; wherein a first target operator of the at least one target operator uses the evaluation result to perform a first type of operation; wherein a second target operation of the at least one target operator uses the evaluation result to perform a second type of operation; wherein the first type of operation is different than the second type of operation., 9. The method of claim 1 , wherein the plurality of target operators includes two or more of: a hash join, a hash group by, a bloom filter, or an output table queue., 10. One or more non-transitory computer-readable storage media storing instructions, which, when executed by one or more processors, cause: identifying, in a query execution plan compiled for a query, a plurality of target operators that includes an expression that computes a common value; for at least one target operator of the plurality of target operators, modifying a row input of the at least one target operator to add a column to receive an evaluation result comprising the common value from a layer device; performing, by a database server connected to the storage device, the query execution plan by: sending, to the storage device, the expression that computes the common value, and receiving, within the column, the common value from the storage device., 11. The one or more non-transitory computer-readable storage media of claim 10 , wherein the instructions further cause: determining whether a number of target operators identified satisfies a threshold; wherein said modifying is performed in response to determining that the number of target operators identified satisfies the threshold., 12. The one or more non-transitory computer-readable storage media of claim 10 , wherein the storage device returns a set of rows that includes the evaluation result., 13. The one or more non-transitory computer-readable storage media of claim 10 , wherein the expression is a hash computation on a common hash key., 14. The one or more non-transitory computer-readable storage media of claim 10 , wherein modifying a row input of the at least one target operator comprises: traversing operators of a query execution tree to identify a first target operator that is a hash-user; wherein the first target operator includes an expression for computing a hash value from a particular hash key; traversing a subtree of the query execution tree using the first target operator as a root to identify one or more operators in the subtree that are also hash-users; for each hash-user identified in the subtree, determining whether a hash key is identical to the particular hash key; in response to determining that the hash-user includes a hash key that is identical to the particular hash key, marking the hash-user as a target operator., 15. The one or more non-transitory computer-readable storage media of claim 10 , wherein modifying a row input of the at least one target operator comprises: for one or more target operators of the at least one target operator, replacing the expression with a reference to a shared expression; wherein replacing the expression with a reference to a shared expression causes a respective target operator to access the evaluation result without computing the evaluation result., 16. The one or more non-transitory computer-readable storage media of claim 10 , wherein modifying a row input of the at least one target operator comprises assigning responsibility for evaluating the expression to a single target operator of the at least one target operator; wherein the responsibility is assigned to a first target operator in a dataflow of a query execution tree., 17. The one or more non-transitory computer-readable storage media of claim 10 , wherein the plurality of target operators include different target operators; wherein a first target operator of the at least one target operator uses the evaluation result to perform a first type of operation; wherein a second target operation of the at least one target operator uses the evaluation result to perform a second type of operation; wherein the first type of operation is different than the second type of operation., 18. The one or more non-transitory computer-readable storage media of claim 10 , wherein the plurality of target operators includes two or more of: a hash join, a hash group by, a bloom filter, or an output table queue., 19. A system comprising: a storage computer configured to store database content and execute one or more target operators upon the database content; a database server configured to: identify, in a query execution plan compiled for a query, a plurality of target operators that includes an expression that computes a common value; for at least one target operator of the plurality of target operators, modify a row input of the at least one target operator to add a column to receive an evaluation result comprising the common value from the storage computer; and perform the query execution plan, including: send, to the storage computer, the expression that computes the common value, and receive, within the column, the common value from the storage computer; wherein the database server is connected to the storage computer by a communication network., 20. The system of claim 19 , wherein the storage computer returns a set of rows that includes the evaluation result.\n",
            "Similarity Score: 0.6006\n",
            "\n",
            "\n",
            "Patent ID: 10606954\n",
            "PubMed Claim: 1. A method for text segmentation for topic modelling by a processor, comprising: analyzing real-time conversation data, wherein time intervals between messages being received into the conversation data are recorded; defining the messages as burst segments or reflection segments according to the analyzing; wherein the burst segments comprise successive messages received into the conversation data within a first time interval and the reflection segments comprise multiple messages each received into the conversation data having an inter-arrival time outside the first time interval; enhancing, using a machine learning mechanism, one or more topic modelling operations for text segmentation using the burst segments or reflection segments; and presenting, via a display, a summary of the one or more topic modelling operations to a user according to an output of a text mining analysis implementing the one or more topic modelling operations enhanced by the machine learning mechanism., 2. The method of claim 1 , further including using the burst segments or reflection segments to determine optimal topic model sizes., 3. The method of claim 1 , further including selecting a topic cluster size using the one or more enhanced topic modelling operations., 4. The method of claim 1 , further including selecting a topic term size using the one or more enhanced topic modelling operations., 5. The method of claim 1 , further including determining a percentage of unique stop words., 6. The method of claim 1 , further including altering a topic cluster size and a topic term size until a percentage of unique stop words are maximized., 7. A system for text segmentation for topic modelling in a computing environment, comprising: one or more computers with executable instructions that when executed cause the system to: analyze real-time conversation data, wherein time intervals between messages being received into the conversation data are recorded; define the messages as burst segments or reflection segments according to the analyzing; wherein the burst segments comprise successive messages received into the conversation data within a first time interval and the reflection segments comprise multiple messages each received into the conversation data having an inter-arrival time outside the first time interval; enhance, using a machine learning mechanism, one or more topic modelling operations for text segmentation using the burst segments or reflection segments; and present, via a display, a summary of the one or more topic modelling operations to a user according to an output of a text mining analysis implementing the one or more topic modelling operations enhanced by the machine learning mechanism., 8. The system of claim 7 , wherein the executable instructions when executed cause the system to use the burst segments or reflection segments to determine optimal topic model sizes., 9. The system of claim 7 , wherein the executable instructions when executed cause the system to select a topic cluster size using the one or more enhanced topic modelling operations., 10. The system of claim 7 , wherein the executable instructions when executed cause the system to select a topic term size using the one or more enhanced topic modelling operations., 11. The system of claim 7 , wherein the executable instructions when executed cause the system to determine a percentage of unique stop words., 12. The system of claim 7 , wherein the executable instructions when executed cause the system to alter a topic cluster size and a topic term size until a percentage of unique stop words are maximized., 13. A computer program product for, by a processor, text segmentation for topic modelling, the computer program product comprising a non-transitory computer-readable storage medium having computer-readable program code portions stored therein, the computer-readable program code portions comprising: an executable portion that analyzes real-time conversation data, wherein time intervals between messages being received into the conversation data are recorded; an executable portion that defines the messages as burst segments or reflection segments according to the analyzing; wherein the burst segments comprise successive messages received into the conversation data within a first time interval and the reflection segments comprise multiple messages each received into the conversation data having an inter-arrival time outside the first time interval; an executable portion that enhances, using a machine learning mechanism, one or more topic modelling operations for text segmentation using the burst segments or reflection segments; and an executable portion that presents, via a display, a summary of the one or more topic modelling operations to a user according to an output of a text mining analysis implementing the one or more topic modelling operations enhanced by the machine learning mechanism., 14. The computer program product of claim 13 , further including an executable portion that uses the burst segments or reflection segments to determine optimal topic model sizes., 15. The computer program product of claim 13 , further including an executable portion that selects a topic cluster size using the one or more enhanced topic modelling operations., 16. The computer program product of claim 13 , further including an executable portion that: selects a topic term size; and determine a percentage of unique stop words., 17. The computer program product of claim 13 , further including an executable portion that alters a topic cluster size and a topic term size until a percentage of unique stop words are maximized.\n",
            "Similarity Score: 0.5985\n",
            "\n",
            "\n",
            "Patent ID: 10606869\n",
            "PubMed Claim: 1. A computer-implemented method for event matching, the computer-implemented method comprising: acquiring a plurality of documents, wherein each document of the plurality of documents comprises respective metadata that is indicative of an event attribute; identifying a document subset comprising multiple documents of the plurality of documents using the respective metadata for each document of the multiple documents; extracting a first salient text feature from a first document of the multiple documents and a second salient text feature from a second document of the multiple documents; determining, based on a comparison between the first salient text feature and the second salient text feature, an event similarity score for the first document and the second document; and upon determining that the event similarity score satisfies a threshold condition, including the first document and the second document as a pair of documents in a common event document list, wherein the common event document list identifies pairs of documents whose respective event similarity scores satisfy the threshold condition; providing, for display by a presentation module, a representation of the pair of documents for review, wherein the representation of the pair of documents identifies the first salient text feature and the second salient text feature in a manner that highlights a match between the first salient text feature and the second salient text feature; receiving data indicative of feedback about the pair of documents, the feedback comprising a confirmation of the including of the first document and the second document together in the common event document list; and adjusting the threshold condition based on the feedback., 2. The computer-implemented method of claim 1 , wherein the event attribute comprises an event time., 3. The computer-implemented method of claim 1 , wherein the event attribute comprises an event location., 4. The computer-implemented method of claim 1 , wherein the event attribute comprises an entity type of an entity associated with the event., 5. The computer-implemented method of claim 1 , wherein identifying the document subset comprises excluding a third document from inclusion in the document subset based on respective metadata for the third document., 6. The computer-implemented method of claim 1 , wherein the first salient text feature comprise a first multi-word term, and wherein the second salient text feature comprise a second multi-word term, and wherein the event similarity score is determined based on the first multi-word term and the second multi-word term., 7. The computer-implemented method of claim 6 , wherein extracting the first salient text feature comprises extracting the first salient text feature using natural language processing., 8. The computer-implemented method of claim 7 , wherein extracting the first salient text feature using natural language processing comprises identifying the first salient text feature as an n-gram., 9. The computer-implemented method of claim 6 , wherein determining the event similarity score comprises: computing a first weight corresponding to the first multi-word term using a rarity measure; computing a second weight corresponding to the second multi-word term using a rarity measure; and determining the event similarity score based on the first weight, the first multi-word term, the second weight, and the second multi-word term., 10. The computer-implemented method of claim 9 , wherein the rarity measure comprises an inverse document frequency., 11. The computer-implemented method of claim 6 , wherein extracting the first multi-word term comprises expanding an acronym using an acronym list., 12. The computer-implemented method of claim 6 , wherein the first salient text feature comprises a first aircraft event, and wherein the second salient text feature comprises a second aircraft event., 13. The computer-implemented method of claim 1 , wherein extracting the first salient text feature comprises extracting a first alphanumerical expression or a first multiword term, wherein extracting the second salient text feature comprises extracting a second alphanumerical expression or a second multiword term., 14. The computer-implemented method of claim 1 , wherein extracting the first salient text feature comprises extracting a first numerical expression using a regular expression, wherein extracting the second salient text feature comprises extracting a second numerical expression using a regular expression, and wherein the event similarity score is determined based on the first numerical expression and the second numerical expression., 15. The computer-implemented method of claim 1 , wherein extracting the first salient text feature comprises extracting a first alphanumerical expression using a regular expression, wherein extracting the second salient text feature comprises extracting a second alphanumerical expression using a regular expression, and wherein the event similarity score is determined based on the first alphanumerical expression and the second alphanumerical expression., 16. The computer-implemented method of claim 15 , wherein the regular expression comprises a number and unit pattern., 17. The computer-implemented method of claim 1 , further comprising extracting a third salient text feature from the first document and a fourth salient text feature from the second document, wherein the event similarity score is further based on a comparison between the third salient text feature and the fourth salient text feature., 18. The computer-implemented method of claim 1 , wherein the respective metadata for the documents of the plurality of documents comprises a structured content field storing information that enables grouping of the documents of the plurality of documents, and wherein identifying the document subset comprises grouping the multiple documents into the document subset based on the information of the structured content field for the multiple documents., 19. The computer-implemented method of claim 16 , further comprising: extracting a third salient text feature from the first document; and determining that the third salient text feature does not match any salient text features extracted from the second document, wherein the representation identifies the third salient text feature as unmatched., 20. A system for event matching, the system comprising: at least one processor; and a memory storing instructions that, when executed by the at least one processor, cause the at least one processor to perform functions comprising: acquiring a plurality of documents, wherein each document of the plurality of documents comprises respective metadata that is indicative of an event attribute, identifying a document subset comprising multiple documents of the plurality of documents using the respective metadata for each document of the multiple documents, extracting a first salient text feature from a first document of the multiple documents and a second salient text feature from a second document of the multiple documents, determining, based on a comparison between the first salient text feature and the second salient text feature, an event similarity score for the first document and the second document; and upon determining that the event similarity score satisfies a threshold condition, including the first document and the second document as a pair of documents in a common event document list, wherein the common event document list identifies pairs of documents whose respective event similarity scores satisfy the threshold condition, providing, for display, a representation of the pair of documents for review, wherein the representation of the pair of documents identifies the first salient text feature and the second salient text feature in a manner that highlights a match between the first salient text feature and the second salient text feature, receiving data indicative of feedback about the pair of documents, the feedback comprising a confirmation of the including of the first document and the second document together in the common event document list, and adjusting the threshold condition based on the feedback., 21. A non-transitory computer-readable medium having stored therein instructions that, when executed by at least one processor, cause the at least one processor to perform functions comprising: acquiring a plurality of documents, wherein each document of the plurality of documents comprises respective metadata that is indicative of an event attribute, identifying a document subset comprising multiple documents of the plurality of documents using the respective metadata for each document of the multiple documents, extracting a first salient text feature from a first document of the multiple documents and a second salient text feature from a second document of the multiple documents, determining, based on a comparison between the first salient text feature and the second salient text feature, an event similarity score for the first document and the second document; and upon determining that the event similarity score satisfies a threshold condition, including the first document and the second document as a pair of documents in a common event document list, wherein the common event document list identifies pairs of documents whose respective event similarity scores satisfy the threshold condition, providing, for display, a representation of the pair of documents for review, wherein the representation of the pair of documents identifies the first salient text feature and the second salient text feature in a manner that highlights a match between the first salient text feature and the second salient text feature, receiving data indicative of feedback about the pair of documents, the feedback comprising a confirmation of the including of the first document and the second document together in the common event document list, and adjusting the threshold condition based on the feedback.\n",
            "Similarity Score: 0.5982\n",
            "\n",
            "\n",
            "Patent ID: 10606871\n",
            "PubMed Claim: 1. A non-transitory computer readable medium comprising computer executable instructions stored thereon to cause one or more processing units to: obtain a first plurality of messages for a first user, wherein the first plurality of messages comprises: one or more messages in each of a first one or more formats; and one or more messages sent or received via each of a first one or more protocols; and create one or more associations between one or more of the first plurality of messages, wherein creating the one or more associations comprises: performing a predictive semantic analysis on the first plurality of messages, wherein performing the predictive semantic analysis comprises: generating a predictive tag cloud based on at least one word in a first one of the first plurality of messages, wherein the predictive tag cloud comprises a plurality of words predicted to be related to the at least one word; and creating one or more clusters of messages from the first plurality of messages, wherein creating the one or more clusters of messages comprises: associating the first one of the first plurality of messages with at least a second one of the first plurality of messages based, at least in part, on the second one of the first plurality of messages containing at least one word from the generated predictive tag cloud., 2. The non-transitory computer readable medium of claim 1 , wherein the instructions further comprise instructions to cause the one or more processing units to receive a query requesting at least one message from the first plurality of messages., 3. The non-transitory computer readable medium of claim 2 , wherein the instructions further comprise instructions to cause the one or more processing units to generate a result set to the query., 4. The non-transitory computer readable medium of claim 3 , wherein the result set comprises the at least one requested message and one or more messages from the first plurality of messages for which associations have been created to the requested message., 5. The non-transitory computer readable medium of claim 1 , wherein the instructions to create one or more associations between one or more of the first plurality of messages further comprise instructions to: perform a semantic analysis on the first plurality of messages; and create one or more additional clusters of messages from the first plurality of messages, based, at least in part, on the semantic analysis performed on the first plurality of messages., 6. The non-transitory computer readable medium of claim 5 , wherein the instructions to perform a semantic analysis on a first plurality of messages further comprise instructions to identify one or more keywords in one or more of the first plurality of messages., 7. The non-transitory computer readable medium of claim 1 , wherein at least one of the one or more associations is between messages sent or received via two or more different protocols from among the first one or more protocols, and wherein at least one of the one or more associations is between messages in two or more different formats from among the first one or more formats., 8. The non-transitory computer readable medium of claim 1 , wherein the instructions to create one or more associations between one or more of the first plurality of messages further comprise instructions to: perform element matching on the first plurality of messages., 9. The non-transitory computer readable medium of claim 8 , wherein the instructions to perform element matching on the first plurality of messages further comprise instructions to: perform element matching on at least one of the following: sender, recipient list, subject, quoted text, and timestamp., 10. The non-transitory computer readable medium of claim 1 , wherein the instructions to create one or more associations between one or more of the first plurality of messages further comprise instructions to: perform state matching on the first plurality of messages., 11. A system, comprising: a memory; and one or more processing units, communicatively coupled to the memory, wherein the memory stores instructions to configure the one or more processing units to: obtain a first plurality of messages for a first user, wherein the first plurality of messages comprises: one or more messages in each of a first one or more formats; and one or more messages sent or received via each of a first one or more protocols; and create one or more associations between one or more of the first plurality of messages, wherein creating the one or more associations comprises: performing a predictive semantic analysis on the first plurality of messages, wherein performing the predictive semantic analysis comprises: generating a predictive tag cloud based on at least one word in a first one of the first plurality of messages, wherein the predictive tag cloud comprises a plurality of words predicted to be related to the at least one word; and creating one or more clusters of messages from the first plurality of messages, wherein creating the one or more clusters of messages comprises: associating the first one of the first plurality of messages with at least a second one of the first plurality of messages based, at least in part, on the second one of the first plurality of messages containing at least one word from the generated predictive tag cloud., 12. The system of claim 11 , wherein the instructions further comprise instructions to cause the one or more processing units to receive a query requesting at least one message from the first plurality of messages., 13. The system of claim 12 , wherein the instructions further comprise instructions to cause the one or more processing units to generate a result set to the query., 14. The system of claim 13 , wherein the result set comprises the at least one requested message and one or more messages from the first plurality of messages for which associations have been created to the requested message., 15. The system of claim 11 , wherein the instructions to create one or more associations between one or more of the first plurality of messages further comprise instructions to: perform a semantic analysis on the first plurality of messages; and create one or more additional clusters of messages from the first plurality of messages, based, at least in part, on the semantic analysis performed on the first plurality of messages., 16. The system of claim 15 , wherein the instructions to perform a semantic analysis on a first plurality of messages further comprise instructions to identify one or more keywords in one or more of the first plurality of messages., 17. The system of claim 11 , wherein at least one of the one or more associations is between messages sent or received via two or more different protocols from among the first one or more protocols, and wherein at least one of the one or more associations is between messages in two or more different formats from among the first one or more formats., 18. The system of claim 11 , wherein the instructions to create one or more associations between one or more of the first plurality of messages further comprise instructions to: perform element matching on the first plurality of messages., 19. The system of claim 18 , wherein the instructions to perform element matching on the first plurality of messages further comprise instructions to: perform element matching on at least one of the following: sender, recipient list, subject, quoted text, and timestamp., 20. The system of claim 11 , wherein the instructions to create one or more associations between one or more of the first plurality of messages further comprise instructions to: perform state matching on the first plurality of messages., 21. A computer-implemented method, comprising: obtaining a first plurality of messages for a first user, wherein the first plurality of messages comprises: one or more messages in each of a first one or more formats; and one or more messages sent or received via each of a first one or more protocols; and creating one or more associations between one or more of the first plurality of messages, wherein creating the one or more associations comprises: performing a predictive semantic analysis on the first plurality of messages, wherein performing the predictive semantic analysis comprises: generating a predictive tag cloud based on at least one word in a first one of the first plurality of messages, wherein the predictive tag cloud comprises a plurality of words predicted to be related to the at least one word; and creating one or more clusters of messages from the first plurality of messages, wherein creating the one or more clusters of messages comprises: associating the first one of the first plurality of messages with at least a second one of the first plurality of messages based, at least in part, on the second one of the first plurality of messages containing at least one word from the generated predictive tag cloud., 22. The method of claim 21 , further comprising receiving a query requesting at least one message from the first plurality of messages., 23. The method of claim 22 , further comprising generating a result set to the query., 24. The method of claim 23 , wherein the result set comprises the at least one requested message and one or more messages from the first plurality of messages for which associations have been created to the requested message., 25. The method of claim 21 , wherein at least one of the one or more associations is between messages sent or received via two or more different protocols from among the first one or more protocols, and wherein at least one of the one or more associations is between messages in two or more different formats from among the first one or more formats.\n",
            "Similarity Score: 0.5978\n",
            "\n",
            "\n",
            "Patent ID: 10606995\n",
            "PubMed Claim: 1. A character input device, comprising: an operation unit configured to accept key input, and to display and accept selection of a prediction candidate that depends on a result of the key input; and a processor configured with a program to perform operations comprising operation as a character input determining unit configured to: determine an input character, using the result of the key input; or determine a selection result of the prediction candidate, using the result of the key input to accept the selection of the prediction candidate from one or more prediction candidates, wherein the processor is configured with the program to perform operations such that operation as the character input determining unit comprises operation the character input determining unit that: executes fingerprint authentication of a fingerprint at a time of accepting the key input, or at a time of accepting the selection of the prediction candidate, in response to successfully authenticating the fingerprint at the time accepting the key input, displays private information associated with the authenticated fingerprint, in response to being unable to successfully authenticate the fingerprint at the time of accepting the key input, displays information other than the private information, and in response to successfully authenticating the fingerprint at the time of selecting the prediction candidate, outputs a character string comprising private information associated with the selection result of the prediction candidate., 2. The character input device according to claim 1 , wherein: the operation unit comprises an operation surface; and the processor is configured with the program to perform operations such that operation as the character input determining unit comprises operation as the character input determining unit that executes the fingerprint authentication, based on contact on the operation surface., 3. The character input device according to claim 1 , wherein: the operation unit comprises a candidate display unit; the processor is configured with the program to perform operations further comprising operation as a private information saving unit in which the private information is saved; and the processor is configured with the program to perform operations such that operation as the character input determining unit comprises operation as the character input determining unit that, in response to the fingerprint authentication at the time of accepting the key input being successful, displays a private candidate of the private information saved in the private information saving unit on the candidate display unit., 4. The character input device according to claim 2 , wherein: the operation unit comprises a candidate display unit; the processor is configured with the program to perform operations further comprising operation as a private information saving unit in which the private information is saved; and the processor is configured with the program to perform operations such that operation as the character input determining unit comprises operation as the character input determining unit that, in response to the fingerprint authentication at the time of accepting the key input being successful, displays a private candidate of the private information saved in the private information saving unit on the candidate display unit., 5. The character input device according to claim 1 , wherein: the operation unit comprises a candidate display unit; and the processor is configured with the program to perform operations such that operation as the character input determining unit comprises operation as the character input determining unit that displays the prediction candidate on the candidate display unit so as to be partly concealed, and, in response to the fingerprint authentication at the time of accepting the selection of the prediction candidate being successful, outputs the prediction candidate externally., 6. The character input device according to claim 2 , wherein: the operation unit comprises a candidate display unit; and the processor is configured with the program to perform operations such that operation as the character input determining unit comprises operation as the character input determining unit that displays the prediction candidate on the candidate display unit so as to be partly concealed, and, in response to the fingerprint authentication at the time of accepting the selection of the prediction candidate being successful, outputs the prediction candidate externally., 7. A character input method according to which a computational processing device perform operations comprising: accepting key input, and displaying and accepting selection of a prediction candidate that depends on a result of the key input; and determining an input character, using the result of the key input; or determining a selection result of the prediction candidate, using the result of the key input to display one or more prediction candidates, and accept the selection of the prediction candidate from the one or more displayed prediction candidates, wherein fingerprint authentication of a fingerprint is executed at a time of accepting the key input, or at a time of accepting the selection of the prediction candidate; in response to successfully authenticating the fingerprint at the time accepting the key input, displaying private information associated with the authenticated fingerprint, in response to being unable to successfully authenticate the fingerprint at the time of accepting the key input, displaying information other than the private information, and in response to successfully authenticating the fingerprint at the time of selecting the prediction candidate, outputting a character string comprising private information associated with the selection result of the prediction candidate., 8. A non-transitory computer-readable storage medium storing a character input program that causes a computational processing device to perform operations comprising: accepting key input, and displaying and accepting selection of a prediction candidate that depends on a result of the key input; and determining an input character, using the result of the key input; or determining a selection result of the prediction candidate, using the result of the key input to display one or more prediction candidates, and accept the selection of the prediction candidate from the one or more displayed prediction candidates, wherein fingerprint authentication of a fingerprint is executed at a time of accepting the key input, or at a time of accepting the selection of the prediction candidate; in response to successfully authenticating the fingerprint at the time accepting the key input, displaying private information associated with the authenticated fingerprint, in response to being unable to successfully authenticate the fingerprint at the time of accepting the key input, displaying information other than the private information, and in response to successfully authenticating the fingerprint at the time of selecting the prediction candidate, outputting a character string comprising private information associated with the selection result of the prediction candidate.\n",
            "Similarity Score: 0.5973\n",
            "\n",
            "\n",
            "Patent ID: 10606958\n",
            "PubMed Claim: 1. A computer system comprising: a processing unit operatively coupled to memory; an artificial intelligence platform, in communication with the processing unit and memory; a knowledge engine operatively coupled to the processing unit to train a machine learning model (MLM), the knowledge engine configured to: select a first MLM from a natural language (NL) processing library of MLMs, aligned to a knowledge domain expressed in a first knowledge graph (KG); receive NL input and query the input against the first KG, and extract one or more triplets from the first KG; apply the selected MLM to a second KG different from the first KG, and extract one or more triplets from the second KG, wherein each triplet includes a subject, object, and a relationship; for each extracted triplet: obtain a blockchain (BC) identifier associated with each triplet; and identify a triplet veracity value from a corresponding BC ledger; detect a modification of the first KG from the extracted one or more triplets from the second KG, wherein the modification is selected from the group consisting of: content and structure, and combinations thereof; and evaluate the detected modification, including employ the obtained BC identifier to assess veracity of the detected modification; and dynamically augment the first MLM responsive to the received NL input., 2. The system of claim 1 , wherein the detected modification is content, and further comprising the knowledge engine to classify the detected modification, wherein the classification is selected from the group consisting of: synchronic and diachronic., 3. The system of claim 2 , wherein the detected modification is classified as conflicting data, and further comprising the knowledge engine to leverage the assessed veracity value of the first and second data, and limit modification of the first MLM subject to the assessed veracity value., 4. The system of claim 2 , further comprising the knowledge engine to employ the classification as a contribution factor with the modification evaluation., 5. The system of claim 1 , wherein the dynamic modification augmentation of the first MLM includes the MLM to create a new MLM., 6. A computer program product to process natural language (NL), the computer program product comprising a computer readable storage device having program code embodied therewith, the program code executable by a processing unit to: select a first machine learning model (MLM) from a NL processing library of MLMs, aligned to a knowledge domain expressed in a first knowledge graph (KG); receive NL input and query the input against the first KG, and extract one or more triplets from the first KG; apply the selected MLM to a second KG different from the first KG, and extract one or more triplets from the second KG, wherein each triplet includes a subject, object, and a relationship, and for each extracted triplet: obtain a blockchain (BC) identifier associated with each triplet; and identify a triplet veracity value from a corresponding BC ledger; detect a modification of the first KG from the extracted one or more triplets from the second KG, wherein the modification is selected from the group consisting of: content and structure, and combinations thereof; evaluate the detected modification, including employ the obtained BC identifier to assess veracity of the detected modification; and dynamically augment the first MLM responsive to the received NL input., 7. The computer program product of claim 6 , wherein the detected modification is content, and further comprising program code to: classify the detected modification, wherein the classification is selected from the group consisting of: synchronic and diachronic., 8. The computer program product of claim 7 , further comprising program code to employ the classification as a contribution factor with the modification evaluation., 9. The computer program product of claim 7 , wherein the detected modification is classified as conflicting data, and further comprising program code to: leverage the assessed veracity value of the first and second data, and limit modification of the first MLM subject to the assessed veracity value., 10. The computer program product of claim 6 , wherein the dynamic augmentation of the first MLM includes the MLM to create a new MLM., 11. A method for processing natural language (NL), comprising: selecting a first machine learning model (MLM) from a NL processing library of MLMs, aligned to a knowledge domain expressed in a first knowledge graph (KG); receiving NL input and query the input against the first KG, and extracting one or more triplets from the first KG; applying the selected MLM to a second KG different from the first KG, and extracting one or more triplets from the second KG, wherein each triplet includes a subject, object, and a relationship, and for each extracted triplet: obtaining a blockchain (BC) identifier associated with each triplet; and identifying a triplet veracity value from a corresponding BC ledger; detecting a modification of the first KG from the extracted one or more triplets from the second KG, wherein the modification is selected from the group consisting of: content and structure, and combinations thereof; evaluating the detected modification, including employing the obtained BC identifier to assess veracity of the detected modification; and dynamically augmenting the first MLM responsive to the received NL input., 12. The method of claim 11 , wherein the detected modification is content, and further comprising: classifying the detected modification, wherein the classification is selected from the group consisting of: synchronic and diachronic., 13. The method of claim 12 , further comprising employing the classification as a contribution factor with the modification evaluation., 14. The method of claim 12 , wherein the detected modification is classified as conflicting data, and further comprising: leveraging the assessed veracity value of the first and second data, and limiting modification of the first MLM subject to the assessed veracity value., 15. The method of claim 11 , wherein the dynamic augmentation of the first MLM includes the MLM creating a new MLM.\n",
            "Similarity Score: 0.5938\n",
            "\n",
            "\n",
            "Patent ID: 10606766\n",
            "PubMed Claim: 1. A method, comprising: designating one or more files within a shadow copy with restricted shadow copy access based on a shadow copy access policy comprising a protected file list that indicates which files are to be monitored to prevent unauthorized shadow copy access, wherein the shadow copy access policy supplements default file access policies that are configured in an operating system of a computing device; monitoring a request to access the one or more files via the shadow copy on the computing device, wherein monitoring the request to access the shadow copy comprises using a filter driver to intercept a request for a previously created shadow copy, wherein upon receiving a request for a shadow copy, the filter driver: determines a user account that is making the request; determines what volume the shadow copy is for; and determines whether the user account has authorization to access a requested file or folder on the shadow copy based on the shadow copy access policy; and preventing unauthorized access to the shadow copy based on the shadow copy access policy., 2. The method of claim 1 , wherein the request to access the shadow copy comprises a request to create a shadow copy of one or more volumes or a request to access a previously created shadow copy., 3. The method of claim 1 , wherein preventing unauthorized access to the shadow copy comprises: preventing access to the one or more files on the shadow copy based on a specific user, group membership, file path and time of day., 4. The method of claim 1 , wherein preventing unauthorized access to the shadow copy further comprises: determining whether a user account associated with the request is authorized to access the shadow copy on the computing device., 5. The method of claim 1 , wherein preventing unauthorized access to the shadow copy comprises: determining that a user account is not authorized to access the shadow copy according to the shadow copy access policy., 6. The method of claim 1 , further comprising designating one or more protected files with restricted shadow copy access., 7. The method of claim 1 , wherein the filter driver comprises a file system filter or minifilter driver., 8. The method of claim 1 , further comprising: loading the filter driver in a kernel of the computing device; attaching the filter driver to a volume that is being monitored; and receiving the request for a previously created shadow copy in a stack of callers., 9. The method of claim 1 , wherein monitoring a request to access a shadow copy comprises invoking a filter driver to intercept a request to create a shadow copy., 10. The method of claim 9 , wherein a volume shadow copy service monitor accesses a current executing thread to determine the invoker of the request., 11. The method of claim 9 , wherein if a request to create a shadow copy is not authorized by the shadow copy access policy, the filter driver prevents the shadow copy from being made., 12. The method of claim 1 , further comprising configuring a filter driver to perform copy monitoring via region access., 13. The method of claim 12 , wherein copy monitoring via region access comprises: mapping regions in a sensitive file or shadow copy with bits of a bit array; observing seeks to read the sensitive file or shadow copy; marking bits associated with the seeks as dirty; determining that all of the bits are dirty before the sensitive file or shadow copy is closed; and generating a flag indicating a copy., 14. A computing device, comprising: a processor; a memory in electronic communication with the processor; and instructions stored in the memory, the instructions being executable to: designate one or more files within a shadow copy with restricted shadow copy access based on a shadow copy access policy comprising a protected file list that indicates which files are to be monitored to prevent unauthorized shadow copy access, wherein the shadow copy access policy supplements default file access policies that are configured in an operating system of the computing device; monitor a request to access the one or more files via the shadow copy on the computing device, wherein the instructions executable to monitor a request to access a shadow copy comprise instructions executable to use a filter driver to intercept a request for a previously created shadow copy, wherein upon receiving a request for a shadow copy, the filter driver: determines a user account that is making the request; determines what volume the shadow copy is for; and determines whether the user account has authorization to access a requested file or folder on the shadow copy based on the shadow copy access policy; and prevent unauthorized access to the shadow copy based on the shadow copy access policy., 15. The computing device of claim 14 , wherein the instructions executable to prevent unauthorized access to the shadow copy comprise instructions executable to: prevent access to the one or more files on the shadow copy based on a specific user, group membership, file path and time of day., 16. The computing device of claim 14 , wherein the instructions executable to monitor a request to access a shadow copy comprise instructions executable to invoke a filter driver to intercept a request to create a shadow copy., 17. The computing device of claim 16 , wherein if a request to create a shadow copy is made by a user account that is not authorized by the shadow copy access policy, the filter driver prevents the shadow copy from being made.\n",
            "Similarity Score: 0.5936\n",
            "\n",
            "\n",
            "Patent ID: 10606951\n",
            "PubMed Claim: 1. A method for optimizing resource allocation to a bid request response based on a cognitive analysis of natural language artifacts, comprising: obtaining a request and a plurality of supporting artifacts in a natural language; performing a cognitive analysis of the request and supporting artifacts to extract a set of information entities; normalizing the extracted information entities using a lexical-relations based graph database to classify the set of extracted information entities as standardized concepts with which the set of extracted information entities are most closely associated; identifying, for a portion of the request, at least a subset of the set of the standardized concepts, with which the set of extracted information entities are most closely associated, as a set of parameters corresponding with a set of predetermined variables; weighting each variable of the set of predetermined variables according to a likelihood that the variable indicates a relevance of a resource to the portion of the request; and assigning a particular resource to the bid request response in response to a probability that the particular resource is relevant to the portion of the request based on the weighted variables., 2. The method of claim 1 , the method further comprising generating a list of probabilities that a set of resources are relevant to the portion of the request., 3. The method of claim 1 , the determining a probability further comprising applying a first-order supervised multi-label learning classification algorithm to the weighted set of predetermined variables., 4. The method of claim 1 , wherein the probability that the particular resource is relevant to the portion of the request has a variance and the method further comprises iterating the identifying, weighting, and determining until the variance is below a pre-defined threshold., 5. The method of claim 1 , wherein the plurality of supporting artifacts comprises an artifact selected from the group consisting of: historical data, public information, and correspondence., 6. The method of claim 1 , wherein at least one variable of the set of predetermined variables is a variable selected from the group consisting of: request type, deal size, techno-functional area of a deal, deal type, deal coverage, industry, sub-domain of an industry, techno-functional area of an industry, geography, client size, historical spending, inclination to a bidder, inclination to partners, bidder strength in a domain, sales organization size of a bidder, section of the request, and techno-functional entities of the request., 7. The method of claim 1 , wherein the likelihood that the variable indicates a relevance of a resource to the portion of the request is based on historical data processed by a self-learning system., 8. A computer system for optimizing resource allocation to a bid request response based on a cognitive analysis of natural language artifacts, the computer system comprising: a memory medium comprising program instructions; a bus coupled to the memory medium; and a processor, for executing the program instructions, coupled to a bid request analysis engine via the bus that when executing the program instructions causes the system to: obtain a request and a plurality of supporting artifacts in a natural language; perform a cognitive analysis of the request and supporting artifacts to extract a set of information entities; normalize the extracted information entities using a lexical-relations based graph database to classify the set of extracted information entities as standardized concepts with which the set of extracted information entities are most closely associated; identify, for a portion of the request, at least a subset of the set of the standardized concepts, with which the set of extracted information entities are most closely associated, as a set of parameters corresponding with a set of predetermined variables; weight each variable of the set of predetermined variables according to a likelihood that the variable indicates a relevance of a resource to the portion of the request; and assign a particular resource to the bid request response in response to a probability that the particular resource is relevant to the portion of the request based on the weighted variables., 9. The computer system of claim 8 , the instructions further causing the system to generate a list of probabilities that a set of resources are relevant to the portion of the request., 10. The computer system of claim 8 , the instructions further causing the system to apply a first-order supervised multi-label learning classification algorithm to the weighted set of predetermined variables., 11. The computer system of claim 8 , wherein the probability that the particular resource is relevant to the portion of the request has a variance and the instructions further cause the system to iterate the identifying, weighting, and determining until the variance is below a pre-defined threshold., 12. The computer system of claim 8 , wherein the plurality of supporting artifacts comprises an artifact selected from the group consisting of: historical data, public information, and correspondence., 13. The computer system of claim 8 , wherein at least one variable of the set of predetermined variables is a variable selected from the group consisting of: request type, deal size, techno-functional area of a deal, deal type, deal coverage, industry, sub-domain of an industry, techno-functional area of an industry, geography, client size, historical spending, inclination to a bidder, inclination to partners, bidder strength in a domain, sales organization size of a bidder, section of the request, and techno-functional entities of the request., 14. The computer system of claim 8 , wherein the likelihood that the variable indicates a relevance of a resource to the portion of the request is based on historical data processed by a self-learning system., 15. A computer program product for optimizing resource allocation to a bid request response based on a cognitive analysis of natural language artifacts, the computer program product comprising a computer readable hardware storage device, and program instructions stored on the computer readable hardware storage device, to: obtain a request and a plurality of supporting artifacts in a natural language; perform a cognitive analysis of the request and supporting artifacts to extract a set of information entities; normalize the extracted information entities using a lexical-relations based graph database to classify the set of extracted information entities as standardized concepts with which the set of extracted information entities are most closely associated; identify, for a portion of the request, at least a subset of the set of the standardized concepts, with which the set of extracted information entities are most closely associated, as a set of parameters corresponding with a set of predetermined variables; weight each variable of the set of predetermined variables according to a likelihood that the variable indicates a relevance of a resource to the portion of the request; and assign a particular resource to the bid request response in response to a probability that the particular resource is relevant to the portion of the request based on the weighted variables., 16. The computer program product of claim 15 , the computer readable storage device further comprising instructions to generate a list of probabilities that a set of resources are relevant to the portion of the request., 17. The computer program product of claim 15 , the computer readable storage device further comprising instructions to apply a first-order supervised multi-label learning classification algorithm to the weighted set of predetermined variables., 18. The computer program product of claim 15 , wherein the probability that the particular resource is relevant to the portion of the request has a variance and the computer readable storage device further comprising instructions to iterate the identifying, weighting, and determining until the variance is below a pre-defined threshold., 19. The computer program product of claim 15 , wherein at least one variable of the set of predetermined variables is a variable selected from the group consisting of: request type, deal size, techno-functional area of a deal, deal type, deal coverage, industry, sub-domain of an industry, techno-functional area of an industry, geography, client size, historical spending, inclination to a bidder, inclination to partners, bidder strength in a domain, sales organization size of a bidder, section of the request, and techno-functional entities of the request., 20. The computer program product of claim 15 , wherein the likelihood that the variable indicates a relevance of a resource to the portion of the request is based on historical data processed by a self-learning system.\n",
            "Similarity Score: 0.5924\n",
            "\n",
            "\n",
            "Patent ID: 10606916\n",
            "PubMed Claim: 1. A computer-implemented data processing method for monitoring consent record rate change of a particular capture point, the method comprising: providing a user interface at a particular capture point for initiating a transaction between an entity and a data subject; receiving, from a respective computing device associated with each of a plurality of data subjects via the user interface, a plurality of requests to initiate a respective transaction between the entity and each of the plurality of data subjects; in response to receiving each of the plurality of requests: generating, by a consent receipt management system, a unique consent receipt key for each respective request of the plurality of requests; storing, for each respective request, a respective consent record comprising the unique consent receipt key; monitoring the particular capture point to determine a rate of consent records generated at the particular capture point; identifying a change in the rate of consent records generated at the particular capture point; determining, based at least in part on the change in the rate of consent records generated at the particular capture point, that the particular capture point is not functioning properly; and in response to identifying the change in the rate of consent records generated at the particular capture point, generating an electronic alert and transmitting the electronic alert to an individual responsible for the particular capture point., 2. The computer-implemented data processing method of claim 1 , where the transaction involves a collection or processing of personal data associated with the data subject by the entity., 3. The computer-implemented data processing method of claim 2 , the method further comprising, in response to receiving each of the plurality of requests: identifying a transaction identifier associated with the transaction; and storing the transaction identifier with each respective consent record., 4. The computer-implemented data processing method of claim 1 , the method further comprising, in response to determining that the particular capture point is not functioning properly, flagging one or more pieces of computer code associated with the particular capture point for modification., 5. The computer-implemented data processing method of claim 1 , wherein the particular capture point comprises a particular webpage., 6. The computer-implemented data processing method of claim 1 , the method further comprising, in response to identifying the change in the rate of consent records generated at the particular capture point, automatically initiating a consent interface consent conversion test at the particular capture point., 7. A consent receipt management system comprising: one or more processors; and computer memory that stores a plurality of consent records associated with a unique subject identifier, each of the plurality of consent records being associated with a respective transaction of a plurality of transactions involving a data subject and an entity, wherein the consent receipt management system is configured for: receiving, at a particular consent capture point, a request to initiate a transaction between the entity and the data subject, the transaction involving collection or processing of personal data associated with the data subject by the entity as part of a processing activity undertaken by the entity that the data subject is consenting to as part of the transaction; in response to receiving the request: identifying a transaction identifier associated with the transaction; identifying a capture point identifier for the particular consent capture point; generating, a unique consent receipt key for the transaction; and determining a unique subject identifier for the data subject; electronically storing the unique subject identifier, the unique consent receipt key, the capture point identifier, and the transaction identifier in computer memory; electronically associating the unique subject identifier, the unique consent receipt key, the capture point identifier, and the transaction identifier; generating a consent record for the transaction, the consent record comprising at least the unique subject identifier and the unique consent receipt key; monitoring the particular consent capture point to determine a consent record rate for the particular consent capture point; analyzing the consent record rate to identify a particular change in the consent record rate; determining, based at least in part on the particular change in the consent record rate, that the particular consent capture point is not functioning properly; and in response to identifying the particular change in the consent record rate, taking one or more automated actions., 8. The consent receipt management system of claim 7 , wherein the one or more automated actions are selected from the group consisting of: generating an electronic alert and transmitting the electronic alert to an individual responsible for the particular consent capture point; and flagging one or more pieces of computer code associated with the particular consent capture point for modification., 9. The consent receipt management system of claim 8 , wherein the particular change in the consent record rate comprises a reduction in the consent record rate to zero., 10. The consent receipt management system of claim 8 , wherein the particular change in the consent record rate comprises a reduction in the consent record rate below a particular threshold level., 11. The consent receipt management system of claim 10 , wherein the system is further configured for, in response to the reduction in the consent record rate below the particular threshold level, automatically implementing a modified consent capture interface at the particular consent capture point., 12. The consent receipt management system of claim 11 , wherein the particular consent capture point comprises a particular domain., 13. The consent receipt management system of claim 7 , wherein the one or more automated actions comprise automatically initiating a consent interface consent conversion test at the particular consent capture point., 14. A computer-implemented data processing method for managing a consent capture point, the method comprising: providing, at the consent capture point, a user interface for initiating a transaction between an entity and a data subject; receiving a request to initiate the transaction between the entity and the data subject; in response to receiving the request, generating, by a third-party consent receipt management system, a unique consent receipt key; receiving, from the data subject, a unique subject identifier; identifying a capture point identifier associated with the capture point; electronically storing the unique subject identifier, the unique consent receipt key, the capture point identifier, and a unique transaction identifier associated with the transaction in a consent record; electronically associating the unique subject identifier, the unique consent receipt key, the consent capture point identifier, and the unique transaction identifier; accessing a plurality of consent records associated with the capture point identifier; analyzing each of the plurality of consent records associated with the consent capture point identifier to determine a consent record rate for the consent capture point; monitoring the consent record rate for the consent capture point to identify a particular change to the consent record rate; determining, based at least in part on the particular change to the consent record rate, that the consent capture point is not functioning properly; and in response to identifying the particular change in the consent record rate, taking one or more automated actions., 15. The computer-implemented data processing method of claim 14 , wherein the one or more automated actions are selected from the group consisting of: generating an electronic alert and transmitting the electronic alert to an individual responsible for the consent capture point; and flagging one or more pieces of computer code associated with the consent capture point for modification; and automatically initiating a consent interface consent conversion test at the consent capture point., 16. The computer-implemented data processing method of claim 14 , the method further comprising transmitting a consent receipt to the data subject, the consent receipt comprising at least the unique subject identifier and the unique consent receipt key., 17. The computer-implemented data processing method of claim 16 , wherein the transaction comprises processing, by the entity, one or more pieces of personal data associated with the data subject., 18. The computer-implemented data processing method of claim 16 , wherein the consent receipt comprises a mechanism for the data subject to withdraw consent for the entity to process the one or more pieces of personal data., 19. The computer-implemented data processing method of claim 14 , wherein the consent capture point is selected from the group consisting of: a particular domain; a particular webpage; and a particular mobile application.\n",
            "Similarity Score: 0.5922\n",
            "\n",
            "\n",
            "Patent ID: 10606881\n",
            "PubMed Claim: 1. A computer program product performing container sharing and scheduling in an environment having a plurality of content consuming nodes and a bypassable centralized container repository, the computer program product comprising a non-transitory computer readable storage medium having program instructions embodied therewith, the program instructions executable by a computer to cause the computer to perform a method comprising: deploying a container management service system that manages a list of layered images, the list of layered images specifying one or more container attributes for each of the layered images stored at the plurality of content consuming nodes; selecting, by a processor-based scheduler of the container management system based on the list of layered images, a given one of the plurality of content consuming nodes which (i) includes image layers residing in a container and (ii) communicates with one or more candidate nodes that include one or more missing image layers, wherein the one or more candidate nodes are determined from among the plurality of content consuming nodes based on one or more availability criterion; and bypassing, using a cluster membership registry service of the container management service system as an intermediary, wherein the cluster membership registry maintains a list of images downloaded from the plurality of content consumer nodes, the centralized container repository to satisfy a pull request by pulling the one or more missing image layers from the one or more candidate nodes and copying the one or more missing image layers to the given one of the plurality of content consuming nodes, wherein said pulling step comprises the one or more candidate nodes communicating with each other in order to satisfy the pull request., 2. The computer program product of claim 1 , wherein the method further comprises updating the list of layered images before launching a new container by any of the plurality of content consuming nodes., 3. The computer program product of claim 1 , wherein the method further comprises updating the list of layered images before performing an image garbage collection cycle on any of the plurality of content consuming nodes., 4. The computer program product of claim 1 , wherein the one or more candidate nodes comprise two candidate nodes, the two candidate nodes comprising a first candidate node and a second candidate node, wherein a given image layer from among the one or more missing image layers is missing from the first candidate node but present at the second candidate node, and wherein said pulling step provides a copy of the given image layer from the second candidate node to both the given one of the plurality of content consuming nodes and the first candidate node by pulling the given image layer through the first candidate node to the given one of the plurality of content consuming nodes and storing the given image layer at the first candidate node and the given one of the plurality of content consuming nodes., 5. The computer program product of claim 1 , wherein the one or more container attributes are selected from the group consisting of an image layer identifier, an image identifier, and a node distance., 6. The computer program product of claim 1 , wherein the one or more availability criterion are selected from the group consisting of CPU availability, communication bandwidth availability, and storage availability., 7. The computer program product of claim 1 , wherein the list of layered images comprises a respective unique identifier for each image layer of the layered images., 8. The computer program product of claim 1 , further comprising launching a new container by the given one of the plurality of content consuming nodes by pulling the layered images for the new container from one or more other ones of the plurality of content consuming nodes., 9. The computer program product of claim 8 , wherein pulling the layered images for the new container comprises bypassing a central repository that also includes copies of the layered images for the new container., 10. The computer program product of claim 1 , wherein the method further comprises registering a downloaded image list of each of the plurality of content consuming nodes with the container management service system., 11. The computer program product of claim 1 , wherein the environment is a cloud environment., 12. The computer program product of claim 1 , wherein software for implementing the method is provided as a service in the cloud environment., 13. The computer program product of claim 1 , wherein the list of images downloaded from the plurality of content consumer nodes further includes container attributes., 14. A system performing container sharing and scheduling in an environment having a plurality of content consuming nodes and a bypassable centralized container repository, the system comprising: a hardware-processor-based container management service system having a hardware-based processor and memory device configured to: manage a list of layered images, the list of layered images specifying one or more container attributes for each of the layered images stored at the plurality of content consuming nodes; select, based on the list of layered images, a given one of the plurality of content consuming nodes which (i) includes image layers residing in a container and (ii) communicates with one or more candidate nodes that include one or more missing image layers, wherein the one or more candidate nodes are determined from among the plurality of content consuming nodes based on one or more availability criterion; and bypass, using a cluster membership registry service of the container management service system as an intermediary, wherein the cluster membership registry maintains a list of images downloaded from the plurality of content consumer nodes, the centralized container repository to satisfy a pull request by pulling the one or more missing image layers from the one or more candidate nodes and copying the one or more missing image layers to the given one of the plurality of content consuming nodes, wherein said pulling comprises the one or more candidate nodes communicating with each other in order to satisfy the pull request., 15. The system of claim 14 , wherein the environment is a cloud environment.\n",
            "Similarity Score: 0.5914\n",
            "\n",
            "\n",
            "Patent ID: 10606952\n",
            "PubMed Claim: 1. A computer-implemented method, comprising: for a natural language input, performing, by a computing system, a process comprising: receiving the natural language input; performing a syntactic analysis of the natural language input to produce one or more linguistic analysis results; creating multiple semantic structures to represent the natural language input in part by using the one or more linguistic analysis results and knowledge induced from a large language corpora, wherein creating the multiple semantic structures includes creating multiple generative semantic primitive (GSP) structures by defining a predicate and one or more roles for a GSP structure of the multiple GSP structures to express a first understanding of the natural language input, the first understanding of the natural language input being based at least in part on the one or more linguistic analysis results, wherein defining the one or more roles includes mapping one or more entities in the natural language input to the one or more roles; associating a semantic structure of the multiple semantic structures with a particular theme or a particular context of the natural language input; engaging in a dialog session with a human user to receive input from the human user to use by the computing system to evaluate the multiple semantic structures as an understanding of the natural language input; and revising the multiple semantic structures based on one or more responses from the human user to improve the understanding of the natural language input, wherein revising the multiple semantic structures includes defining at least one of a new predicate or one or more new roles for at least one new GSP structure associated with the semantic structure, the at least one new GSP structure expressing a second understanding of the natural language input based at least in part on the one or more responses, wherein defining the at least one of the new predicate or the one or more new roles is based at least in part on the at least one new GSP structure having an above threshold probability of being included in the semantic structure associated with the particular theme or the particular context of the natural language input; and repeating, by the computing system, the process with the natural language input at least once to form one or more additional GSP structures for subsequent natural language inputs, wherein the subsequent natural language inputs have similar or increasingly higher reading comprehension levels., 2. The computer-implemented method of claim 1 , wherein the one or more linguistic analysis results comprises at least one of a syntactic parse, a predicate argument structure, entity type, or co-references of the natural language input., 3. The computer-implemented method of claim 1 , wherein creating the multiple semantic structures further includes forming the multiple GSP structures using the one or more linguistic analysis results, data maintained in a current world model that expresses confidences in how accurately the multiple GSP structures represent the natural language input, and the knowledge induced from the large language corpora., 4. The computer-implemented method of claim 3 , further comprising revising the multiple GSP structures based on the one or more responses from the human user and updating the current world model with information learned from the human user or used in revising the multiple GSP structures., 5. The computer-implemented method of claim 1 , wherein creating the multiple semantic structures further includes: forming the multiple GSP structures; and forming multiple frame structures composed of one or more GSP structures., 6. The computer-implemented method of claim 1 , wherein engaging in the dialog session comprises: generating one or more questions for the human user to answer to evaluate the multiple semantic structures; submitting the one or more questions for presentation via a computer user interface to the human user; and receiving the one or more responses from the human user., 7. The computer-implemented method of claim 1 , wherein engaging in the dialog session comprises engaging in multiple dialog sessions with multiple human users., 8. A computer-implemented method, comprising: receiving, by a computing system, multiple first natural language stories of a first reading comprehension level over a first period of time; for a story of the multiple first natural language stories, developing a story model representation of the story by conducting an understanding process comprising: parsing, by the computer system, the story to produce a syntactic representation of the story; performing, by the computer system, a predicate argument structure (PAS) analysis on the syntactic representation of the story; assigning, by the computer system, one or more entity types to one or more words in the story; determining, by the computer system, co-reference chains in the one or more words in the story; inferring, by the computing system, one or more semantic structures as a semantic representation of the story using, at least in part, the syntactic representation of the story; submitting, by the computing system to a user computing device, one or more questions for a human user to answer to evaluate the one or more semantic structures representing the story; responsive to one or more responses from the human user, revising the one or more semantic structures; and iterating the understanding process until one or more final semantic structures are defined, wherein a final version of the story model includes the one or more final semantic structures; storing, by the computing system, multiple first story models that were defined by iterating the understanding process over the first period of time for the multiple first natural language stories of the first reading comprehension level, wherein a first story model of the multiple first story models includes one or more first semantic structures; receiving, by the computing system, multiple second natural language stories of a second reading comprehension level over a second period of time, wherein the second period of time is after the first period of time; and for a second story of the multiple second natural language stories, developing an associated story model representation of the second story by conducting the understanding process for the second story over the second period of time and using, in part, information learned from conducting the understanding process of the multiple first story models for the multiple first natural language stories, wherein the associated story model representation includes at least one second semantic structure based at least in part on combining at least one of the one or more first semantic structures with another semantic structure., 9. The computer-implemented method of claim 8 , further comprising receiving reading comprehension questions along with the multiple first natural language stories and the multiple second natural language stories., 10. The computer-implemented method of claim 8 , wherein parsing the story comprises syntactically analyzing the story to produce one or more linguistic analysis results comprising at least one of a syntactic parse, a predicate argument structure, entity type, or co-references of the story., 11. The computer-implemented method of claim 10 , wherein inferring the one or more semantic structures as the semantic representation of the story comprises creating multiple generative semantic primitive (GSP) structures using the one or more linguistic analysis results, data maintained in a current world model that expresses confidences in how accurately the multiple GSP structures represent natural language in the story, and knowledge induced from large language corpora., 12. The computer-implemented method of claim 11 , wherein inferring the one or more semantic structures as the semantic representation of the story further comprises forming multiple frame structures composed of subsets of the multiple GSP structures., 13. The computer-implemented method of claim 8 , wherein revising the one or more semantic structures until the one or more final semantic structures are defined comprises iteratively submitting questions to the user and receiving user responses to revise the one or more semantic structures until a termination condition is reached, the termination condition being a function of a confidence value that is calculated to express an extent to which the one or more semantic structures fit the story., 14. The computer-implemented method of claim 8 , wherein the second natural language stories have a higher reading comprehension level than the first natural language stories., 15. The computer-implemented method of claim 8 , further comprising continuing to receive natural language stories of higher reading comprehension levels beyond the second natural language stories and conducting the understanding process on the natural language stories of the higher reading comprehension levels., 16. A computing system, comprising: a current world model maintained in a database; one or more processors to access the current world model maintained in the database; and memory coupled to the one or more processors, the memory storing computer executable instructions that, when executed by the one or more processors, perform acts comprising: processing multiple natural language stories of varying reading comprehension levels over time, the processing including inferring semantic structures as representations of the multiple natural language stories, in part by using information maintained in the current world model, and conducting dialog sessions with one or more human users to evaluate the semantic structures as understandings of the multiple natural language stories, wherein the processing includes: processing, over a first time period, a first story of the multiple natural language stories having a first reading comprehension level; performing analysis on the first story to produce a syntactic representation of the first story; performing predicate argument structure (PAS) analysis on the syntactic representation of the first story; assigning one or more entity types to one or more words in the first story; determining co-reference chains in the one or more words in the first story; inferring one or more first semantic structures as representations of the first story; processing, over a second time period after the first time period, a second story of the multiple natural language stories having a second reading comprehension level that is more difficult than the first reading comprehension level; and inferring at least one second semantic structure as a representation of the second story based at least in part on expanding at least one of the one or more first semantic structures to include a new semantic structure; and expanding the current world model in the database over time to include the semantic structures inferred from the multiple natural language stories and evaluated by the one or more human users., 17. The computing system of claim 16 , wherein the multiple natural language stories being processed over time are of increasingly higher reading comprehension levels., 18. The computing system of claim 16 , wherein the memory stores instructions perform further acts comprising: performing syntactic analysis on the multiple natural language stories to produce linguistic analysis results; creating multiple generative semantic primitive (GSP) structures to represent the multiple natural language stories in part by using the linguistic analysis results, the information maintained in the current world model, and knowledge induced from a large language corpora; and forming frame structures composed of the multiple GSP structures., 19. The computing system of claim 16 , wherein conducting the dialog sessions comprises: generating one or more questions for a human user to answer to evaluate the semantic structures; submitting the one or more questions for presentation via a computer user interface to the human user; and receiving one or more responses from the human user., 20. The computing system of claim 19 , wherein conducting the dialog sessions further comprises submitting reading comprehension questions to the human user., 21. The computing system of claim 19 , wherein the memory stores instructions perform further acts comprising: revising the semantic structures based on the one or more responses from the human user; and updating the current world model with information learned from the human user or used in revising the semantic structures., 22. A computing system, comprising: a datastore containing a current world model that expresses beliefs about how natural language is understood; one or more processors; and memory coupled to the one or more processors, the memory storing computer-executable modules comprising: a story parsing engine to syntactically analyze a natural language story to produce linguistic analysis results; a knowledge induction engine to induce information from a large language corpora to form induced information, wherein the knowledge induction engine comprises a word sense disambiguator to disambiguate word senses; a knowledge integration engine to form semantic structures that provide a semantic representation of the natural language story, the knowledge integration engine using the linguistic analysis results, information from the current world model, and the induced information to form the semantic structures, and to associate at least one semantic structure of the semantic structures with a particular context of the natural language story, wherein forming the semantic structures includes defining multiple generative semantic primitive (GSP) structures with one or more sets of roles; and a dialog engine to facilitate a dialog session with a human user by generating one or more questions, and submitting the one or more questions for presentation via a computer user interface to a computing device used by the human user and collecting one or more responses from the computing device indicative of input from the human user; wherein the knowledge integration engine revises the semantic structures based on the one or more responses from the human user and updates the current world model in the datastore, wherein revising the semantic structures includes defining at least one new GSP structure with a new set of roles for the semantic structure, the at least one new GSP structure having at least a threshold probability of being included with the semantic structure associated with the particular context of the natural language story; and wherein the story parsing engine, the knowledge integration engine, and the dialog engine process multiple stories over time to build the information in the current world model., 23. The computing system of claim 22 , wherein the semantic structures comprise the multiple GSP structures and frame structures composed of collections of GSP structures that are related by a common context., 24. The computing system of claim 22 , wherein the knowledge integration engine continues to revise the semantic structures until a termination condition is reached, the termination condition being a function of a confidence value that is calculated to express an extent to which the semantic structures fit the natural language story., 25. The computer-implemented method of claim 1 , wherein engaging in the dialog session comprises engaging in multiple dialog sessions with multiple human users in parallel and aggregating responses from the multiple human users to evaluate an extent to which the semantic structures represent the natural language input., 26. The computing system of claim 22 , wherein the dialog engine facilitates multiple dialog sessions with multiple human users in parallel and aggregates responses from the multiple human users to evaluate an extent to which the semantic structures represent the natural language story.\n",
            "Similarity Score: 0.5908\n",
            "\n",
            "\n",
            "Patent ID: 10606982\n",
            "PubMed Claim: 1. A method comprising: applying a classifier to each of a first plurality of medical images to generate a label and an associated confidence value for each of the first plurality of medical images, resulting in generated labels and associated confidence values, the classifier being pre-trained using a manually labeled set of medical images; selecting those of the first plurality of medical images having an associated confidence value below a predetermined threshold, resulting in selected medical images; providing the selected medical images to a user; receiving from the user updated labels for the selected medical images; retraining the classifier using the first plurality of medical images, with the updated labels for the selected medical images and the generated labels for medical images not selected., 2. The method of claim 1 , wherein said retraining uses the manually labeled set of medical images., 3. The method of claim 1 , wherein the classifier comprises a random decision forest, a linear classifier, logistic regression, a support vector machine, or an artificial neural network., 4. The method of claim 1 , further comprising: retraining the classifier using additional sets of medical images and user-updated labels until the classifier achieves a predetermined accuracy., 5. The method of claim 1 , further comprising: for a superset of medical images comprising the first plurality of medical images, dividing the superset of medical images into the first plurality of medical images and additional sets of medical images; retraining the classifier using the additional sets of medical images and user-updated labels until the classifier has been trained on all medical images in the superset., 6. The method of claim 1 , wherein providing the selected medical images to a user comprises displaying the selected medical images via a web interface., 7. The method of claim 1 , wherein receiving from the user updated labels comprises receiving a selection from among a plurality of predetermined labels., 8. A system comprising: a data store comprising a first plurality of medical images; a computing node comprising a computer readable storage medium having program instructions embodied therewith, the program instructions executable by a processor of the computing node to cause the processor to perform a method comprising: applying a classifier to each of the first plurality of medical images to generate a label and an associated confidence value for each of the first plurality of medical images, resulting in generated labels and associated confidence values, the classifier being pre-trained using a manually labeled set of medical images; selecting those of the first plurality of medical images having an associated confidence value below a predetermined threshold, resulting in selected medical images; providing the selected medical images to a user; receiving from the user updated labels for the selected medical images; retraining the classifier using the first plurality of medical images, with the updated labels for the selected medical images and the generated labels for medical images not selected., 9. The system of claim 8 , wherein said retraining uses the manually labeled set of medical images., 10. The system of claim 8 , wherein the classifier comprises a random decision forest, a linear classifier, logistic regression, a support vector machine, or an artificial neural network., 11. The system of claim 8 , the method further comprising: retraining the classifier using additional sets of medical images and user-updated labels until the classifier achieves a predetermined accuracy., 12. The system of claim 8 , the method further comprising: for a superset of medical images comprising the first plurality of medical images, dividing the superset of medical images into the first plurality of medical images and additional sets of medical images; retraining the classifier using the additional sets of medical images and user-updated labels until the classifier has been trained on all medical images in the superset., 13. The system of claim 8 , wherein providing the selected medical images to a user comprises displaying the selected medical images via a web interface., 14. The system of claim 8 , wherein receiving from the user updated labels comprises receiving a selection from among a plurality of predetermined labels., 15. A computer program product for semi-automatic annotation of medical images, the computer program product comprising a computer readable storage medium having program instructions embodied therewith, the program instructions executable by a processor to cause the processor to perform a method comprising: applying a classifier to each of a first plurality of medical images to generate a label and an associated confidence value for each of the first plurality of medical images, resulting in generated labels and associated confidence values, the classifier being pre-trained using a manually labeled set of medical images; selecting those of the first plurality of medical images having an associated confidence value below a predetermined threshold, resulting in selected medical images; providing the selected medical images to a user; receiving from the user updated labels for the selected medical images; retraining the classifier using the first plurality of medical images, with the updated labels for the selected medical images and the generated labels for medical images not selected., 16. The computer program product of claim 15 , wherein said retraining uses the manually labeled set of medical images., 17. The computer program product of claim 15 , wherein the classifier comprises a random decision forest, a linear classifier, logistic regression, a support vector machine, or an artificial neural network., 18. The computer program product of claim 15 , the method further comprising: retraining the classifier using additional sets of medical images and user-updated labels until the classifier achieves a predetermined accuracy., 19. The computer program product of claim 15 , the method further comprising: for a superset of medical images comprising the first plurality of medical images, dividing the superset of medical images into the first plurality of medical images and additional sets of medical images; retraining the classifier using the additional sets of medical images and user-updated labels until the classifier has been trained on all medical images in the superset., 20. The computer program product of claim 15 , wherein providing the selected medical images to a user comprises displaying the selected medical images via a web interface.\n",
            "Similarity Score: 0.5893\n",
            "\n",
            "\n",
            "Patent ID: 10606933\n",
            "PubMed Claim: 1. A method of converting a document in a page-image format into a form suitable for an arbitrarily sized display, comprising: deconstructing a document in a page image format into a set of segmented image elements which include lines of text, the lines of text found by: finding bounding boxes corresponding to characters of text; identifying a best match for a first text line; and identifying a next best text line by removing bounding boxes that participated in the best match for the first text line; prior to identifying column boundaries, using statistics about a distribution of horizontal distances between bounding boxes to estimate intercharacter and inter-words spacing; identifying the column boundaries by finding globally optimal maximum likelihood matches of a center of a left side of bounding boxes against a line model; synthesizing the deconstructed document into an intermediate data structure that is convertible into a commercially available format using a process other than optical character recognition; and distilling the intermediate data structure for redisplay by converting the intermediate data structure into a format usable for reflow on an arbitrarily sized display, wherein the intermediate data structure is automatically adaptable at the time of display to constraints of a corresponding display device or circumstance of viewing, and the text of each individual page is formatted for layout and rendered for human readable redisplay, and wherein distilling the intermediate data structure for redisplay in a format usable for reflow on an arbitrarily sized display for each individual page, includes redisplaying the document in human readable format., 2. The method of claim 1 , wherein deconstructing the document in a page image into the set of segmented image elements includes at least one of physical segmentation of data and logical segmentation of data., 3. The method of claim 1 , wherein the set of segmented image elements comprises at least one of blocks, words, groups of characters, and groups of non-text characters., 4. The method of claim 1 , wherein synthesizing includes converting non-text image areas, layout properties and segmented image areas into the intermediate data structure., 5. The method of claim 1 , wherein synthesizing the set of segmented image elements into an intermediate data structure includes integrating at least one of bitmapped images in an intelligible display layout and links to non-textual elements., 6. The method of claim 1 , wherein for layout analysis boundary boxes corresponding to characters in running text of the document are used to provide information about the layout of the page needed for the reflowing of the text., 7. The method of claim 1 , wherein distilling the intermediate data structure for redisplay in a format usable for reflow on an arbitrarily sized display for each individual page includes redisplaying the document in at least one of an electronic book format, Internet browsable format and a print format., 8. The method of claim 1 , wherein distilling the intermediate data structure includes converting the stored intermediate data structure into a device specific display format for display., 9. The method of claim 1 , wherein the intermediate data structure is adaptable to at least one of display screen size, page size, resolution, contrast, color and geometry, at the time of display., 10. The method of claim 1 further including: obtaining a collection of bounding boxes corresponding to connected components of the text; and finding text lines using the collection of bounding boxes by application of a branch and bound algorithm that finds maximum likelihood matches against text line models, wherein after a text line is found, the bounding box that bounds all the connected components that participated in the match is determined and all other connected components within that bounding box are assigned to the same text line, and wherein the bounding boxes and their spatial arrangement identify a rotation and skew, column boundaries, and tokens for token-based compression, reading order and/or how the text flows between different parts of the layout., 11. The method of claim 1 , wherein the intermediate data structure includes special image elements that are not extracted from the document, but are created as tagged or untagged elements, such special image elements are inserted into the intermediate data structure in an order that defines the desired functions and properties of other image elements, wherein a particular special image element includes a blank that represents a space between two words, and wherein special non-image markers, are inserted into the intermediate data structure so that functions and properties of at least some of the image elements are inferred from their relative position with respect to the markers within the intermediate data structure., 12. A system of converting a document in a page-image format into a form suitable for an arbitrarily sized display, comprising: an input/output device; a controller; a deconstructing device that deconstructs a document; a synthesizing device that synthesizes the deconstructed document into an intermediate data structure that is convertible into a commercially available format using a process other than optical character recognition; a distilling device that distills the intermediate data structure for redisplay by converting the intermediate data structure into a format usable for reflow on an arbitrarily sized display, the intermediate data structure being automatically adaptable at the time of display to constraints of the arbitrarily sized display; and a non-transitory memory, wherein: the deconstructing device first deconstructs the document in a page image format into non-text image areas, layout properties, and a set of compressed segmented image elements which include lines of text, and a column boundary, the lines of text found by: finding bounding boxes corresponding to characters of text; identifying a best match for a first text line; and identifying a next best text line by removing bounding boxes that participated in the best match for the first text line; the column boundary found by: prior to identifying the column boundary, using statistics about a distribution of horizontal distances between bounding boxes to estimate intercharacter and inter-words spacing; and identifying the column boundary by finding globally optimal maximum likelihood matches of a center of a left side of bounding boxes against a line model; the synthesizing device then synthesizes the non-text image areas, the layout properties, and the set of segmented image elements into the intermediate data structure using a process other than optical character recognition; and the distilling device then distills the intermediate data structure for redisplay in the format usable for reflow on an arbitrarily sized display, the text of each individual page being formatted for layout and rendered for display, wherein distilling the intermediate data structure for redisplay in a format usable for reflow on an arbitrarily sized display for each individual page, includes redisplaying the document in human readable format., 13. The system of claim 12 , wherein the deconstructing device deconstructs the document in a page image format into the set of segmented image elements that includes at least one of physical segmentation of data and logical segmentation of data., 14. The system of claim 12 , wherein the intermediate data structure includes at least one of bitmapped images in an intelligible display layout and links to non-textual elements., 15. The system of claim 12 , wherein the distilling device distills the intermediate data structure for redisplay of the document in a format usable for reflow on an arbitrarily sized display for each individual page includes redisplaying the document in at least one of an electronic book format, Internet browsable format, and a print format, wherein for layout analysis bounding boxes corresponding to characters in running text of the document are used to provide information about the layout of the page needed for the reflowing of the text., 16. The system of claim 12 , wherein the distilling device converts the stored intermediate data structure into a device specific display format for display., 17. The system of claim 12 , wherein the intermediate data structure is adaptable to at least one of display screen size, paper size, resolution, contrast, color and geometry, at the time of display., 18. The system of claim 12 , wherein the deconstructing device analyzes page layout and converts a sequence of page images into a sequence of document element images captured in a tagged format while maintaining pagination; and the distilling device converts the tagged format into at least one of an electronic book format, an Internet browsable format that can accept images and a print format., 19. The system of claim 18 , wherein the tagged format preserves at least one of reading order and logical page layout properties for each individual page of the document., 20. The system of claim 12 , wherein the deconstructing device includes a segmentation algorithm and a background structure analyzer., 21. A method for document image layout deconstruction and redisplay comprising: inputting a document to provide the document in a page image format, wherein the document is represented as page images, including being represented as at least one of bi-level images, gray-scale images, and color images; finding lines of text by: finding bounding boxes corresponding to characters of text; identifying a best match for a first text line; and identifying a next best text line by removing bounding boxes that participated in the best match for the first text line; finding a column boundary by: first, using statistics about a distribution of horizontal distances between bounding boxes to estimate intercharacter and inter-words spacing; and second, identifying the column boundary by finding globally optimal maximum likelihood matches of a center of a left side of bounding boxes against a line model; analyzing an image file in the page image format to identify text image areas and non-text image areas, wherein text image areas include at least one of blocks, columns, the lines of text, words, and the characters of text, and wherein non-text area images include at least one of illustrations, figures, graphics, line-art, photographs, handwriting, footnotes, and signatures; locating and isolating the identified text image areas and non-text image areas, wherein locating and isolating of the text image areas include at least one of locating and isolating a baseline and a top-line of each text line image, wherein the isolated line regions are modeled as line segments that run from one end of the text line image to another; selecting the isolated text image areas for further processing, wherein text line regions of the selected text image areas are located and isolated and layout properties of the selected text image areas are determined, wherein the layout properties include at least one of indentation, left and/or right justification, centering, hyphenation, and proximity to figures, and wherein layout properties include at least one of type size and typeface-family properties that indicate a function of the text within the page images; further processing the located text line regions into a set of segmented image elements; reading the segmented image elements and basic textual elements of the segmented image elements; locating and isolating the basic textual elements which include at least one of words, numbers, dates, proper names, bibliographic references, and references to figures, wherein the basic textual elements become basic image units which are configured to be reflowed and reconstructed, wherein each segmented image element is labeled with a position relative to the baseline of the text lines, wherein when the text lines are reflowed, a reconstructed baseline is referred to when placing corresponding segmented image elements so the segmented image elements appear to share a newly constructed baseline; labeling the set of segmented image elements with a baseline relative position; synthesizing the segmented image elements into an intermediate data structure; storing in memory the intermediate data structure to retain data in an intermediate format, wherein the intermediate data structure contains all information required to support the reflowing and reconstruction of the image elements of a page to be redisplayed; distilling data of the stored intermediate data structure to convert the data of the intermediate data structure into a device specific display format, wherein the stored intermediate data structure is automatically adaptable to constraints of a particular device specific display format at the time of display; and redisplaying the distilled data in human readable format., 22. The method according to claim 21 wherein at least one of the non-text image areas, compressed non-text image areas, the set of representative compressed image tokens, the segmented image elements and the layout characteristics are synthesized into the intermediate data structure., 23. The method according to claim 21 wherein the intermediate data structure contains a tagged list containing references to every textual and non-textual image element that are proximate to or references by textual image element as well as layout characteristics including at least one of indentation, hyphenation., 24. The method of claim 21 , wherein the intermediate data structure includes special image elements that are not extracted from the document, but are created as tagged or untagged elements, such special image elements are inserted into the intermediate data structure in an order that defines the desired functions and properties of other image elements, wherein a special image element includes a blank that represents a space between two words, and wherein special non-image markers, are inserted into the intermediate data structure so that functions and properties of at least some of the image elements are inferred from their relative position with respect to the markers within the intermediate data structure.\n",
            "Similarity Score: 0.5871\n",
            "\n",
            "\n",
            "Patent ID: 10606762\n",
            "PubMed Claim: 1. A virtual cache directory, in a processor having virtual memory support, the virtual cache directory having a plurality of directory entries, each entry associated with a cache line, comprising: a tag associated with each of the plurality of directory entries, the tag comprising: a logical address; an address space identifier; a real address bit indicator; and a virtual address to real address indicator wherein the virtual address to real address indicator is calculated upon every lookup in a translation lookaside buffer., 2. The virtual cache directory of claim 1 wherein the virtual address to real address indicator is a single bit., 3. The virtual cache directory of claim 1 wherein the virtual address to real address indicator is set when the logical address is the same as the real address., 4. The virtual cache directory of claim 1 wherein when the virtual address to real address indicator is set, dynamic address translation is not performed.\n",
            "Similarity Score: 0.5863\n",
            "\n",
            "\n",
            "Patent ID: 10606919\n",
            "PubMed Claim: 1. A method for performing prognostic surveillance operations based on sensor signals from a power plant and associated transmission grid, comprising: obtaining signals comprising time-series data obtained from sensors in the power plant and associated transmission grid during operation of the power plant and associated transmission grid; using an inferential model trained on previously received signals from the power plant and associated transmission grid to generate estimated values for the signals based on correlations between the signals; performing a pairwise differencing operation between actual values and the estimated values for the signals to produce residuals; performing a sequential probability ratio test (SPRT) on the residuals to detect incipient anomalies that arise during operation of the power plant and associated transmission grid; while performing the SPRT, dynamically updating SPRT parameters to compensate for non-Gaussian artifacts that arise in the sensor data due to changing operating conditions in the power plant and associated transmission grid by performing a bivariate optimization operation, which varies both a system disturbance magnitude parameter m and a variance parameter v, while seeking to minimize a resulting decision-time value ASN and maintaining a resulting empirical false alarm probability ? E below a threshold value ? t ; and when an incipient anomaly is detected, generating a notification regarding the anomaly., 2. The method of claim 1 , wherein the bivariate optimization operation involves: performing additional SPRT operations on the signals, wherein m and v are iteratively varied in both positive and negative directions to produce resulting values for ? E and ASN; and updating the m and v parameters whenever an additional SPRT operation causes a resulting ASN value to be reduced while a resulting ? E value remains less than ? t ., 3. The method of claim 2 , wherein the bivariate optimization operation performs an initial SPRT operation using initial parameter values m=m 0 and v=v 0 ; and wherein when a resulting ? E value from the initial SPRT operation is greater than ? t , the method further comprises iteratively performing additional SPRT operations wherein v is increased until a resulting ? E value is less than ? t ., 4. The method of claim 2 , wherein step sizes for the iterative variations of m and v are reduced as the m and v parameters converge toward optimal values that minimize a resulting ASN value while maintaining a resulting ? E value below ? t ., 5. The method of claim 1 , wherein the inferential model is trained using a nonlinear, nonparametric (NLNP) regression technique., 6. The method of claim 5 , wherein the NLNP regression technique comprises a Multivariate State Estimation Technique (MSET)., 7. The method of claim 1 , wherein the signals are obtained from one or more of the following types of components in the power plant and associated transmission grid: a pump; a turbine; a motor; a generator; a mechanical gear box; a transformer; a fluid-fluid or fluid-air heat-exchanger; and an air blower., 8. The method of claim 7 , wherein the signals are obtained from one or more of the following types of sensors located in components in the power plant and associated transmission grid: a voltage sensor; a current sensor; a pressure sensor; a rotational speed sensor; and a vibration sensor., 9. The method of claim 1 , wherein detecting the incipient anomaly comprises detecting an impending failure of a component in the power plant and associated transmission grid., 10. A non-transitory, computer-readable storage medium storing instructions that when executed by a computer cause the computer to perform a method for performing prognostic surveillance operations based on sensor signals from a power plant and associated transmission grid, the method comprising: obtaining signals comprising time-series data obtained from sensors in the power plant and associated transmission grid during operation of the power plant and associated transmission grid; using an inferential model trained on previously received signals from the power plant and associated transmission grid to generate estimated values for the signals based on correlations between the signals; performing a pairwise differencing operation between actual values and the estimated values for the signals to produce residuals; performing a sequential probability ratio test (SPRT) on the residuals to detect incipient anomalies that arise during operation of the power plant and associated transmission grid; while performing the SPRT, dynamically updating SPRT parameters to compensate for non-Gaussian artifacts that arise in the sensor data due to changing operating conditions in the power plant and associated transmission grid by performing a bivariate optimization operation, which varies both a system disturbance magnitude parameter m and a variance parameter v, while seeking to minimize a resulting decision-time value ASN and maintaining a resulting empirical false alarm probability ? E below a threshold value ? t ; and when an incipient anomaly is detected, generating a notification regarding the anomaly., 11. The non-transitory, computer-readable storage medium of claim 10 , wherein the bivariate optimization operation involves: performing additional SPRT operations on the signals, wherein m and v are iteratively varied in both positive and negative directions to produce resulting values for ? E and ASN; and updating the m and v parameters whenever an additional SPRT operation causes a resulting ASN value to be reduced while a resulting ? E value remains less than ? t ., 12. The non-transitory, computer-readable storage medium of claim 11 , wherein the bivariate optimization operation performs an initial SPRT operation using initial parameter values m=m 0 and v=v 0 ; and wherein when a resulting ? E value from the initial SPRT operation is greater than ? t , the method further comprises iteratively performing additional SPRT operations wherein v is increased until a resulting ? E value is less than ? t ., 13. The non-transitory, computer-readable storage medium of claim 11 , wherein step sizes for the iterative variations of m and v are reduced as the m and v parameters converge toward optimal values that minimize a resulting ASN value while maintaining a resulting ? E value below ? t ., 14. The non-transitory, computer-readable storage medium of claim 10 , wherein the inferential model is trained using a nonlinear, nonparametric (NLNP) regression technique., 15. The non-transitory, computer-readable storage medium of claim 14 , wherein the NLNP regression technique comprises a Multivariate State Estimation Technique (MSET)., 16. The non-transitory, computer-readable storage medium of claim 10 , wherein detecting the incipient anomaly comprises detecting an impending failure of a component in the power plant and associated transmission grid., 17. A system that performs prognostic surveillance operations based on sensor signals from a power plant and associated transmission grid, comprising: at least one processor and at least one associated memory; and an anomaly-detection mechanism that executes on the at least one processor, wherein during operation, the anomaly-detection mechanism: obtains signals comprising time-series data obtained from sensors in the power plant and associated transmission grid during operation of the power plant and associated transmission grid; uses an inferential model trained on previously received signals from the power plant and associated transmission grid to generate estimated values for the signals based on correlations between the signals; performs a pairwise differencing operation between actual values and the estimated values for the signals to produce residuals; performs a sequential probability ratio test (SPRT) on the residuals to detect incipient anomalies that arise during operation of the power plant and associated transmission grid; wherein while performing the SPRT, the anomaly-detection mechanism dynamically updates SPRT parameters to compensate for non-Gaussian artifacts that arise in the sensor data due to changing operating conditions in the power plant and associated transmission grid by performing a bivariate optimization operation, which varies both a system disturbance magnitude parameter m and a variance parameter v, while seeking to minimize a resulting decision-time value ASN and maintaining a resulting empirical false alarm probability ? E below a threshold value ? t ; and wherein when an incipient anomaly is detected, the anomaly-detection mechanism generates a notification regarding the anomaly.\n",
            "Similarity Score: 0.5858\n",
            "\n",
            "\n",
            "Patent ID: 10606795\n",
            "PubMed Claim: 1. A method, comprising: identifying, by a data storage computing device, a first global recycle queue in a set of global recycle queues based on a buffer priority to store data obtained by the data storage computing device, the buffer priority based on data type, wherein the global recycle queues are arranged within a circular data structure such that a head pointer points to a lowest priority global recycle queue and a position of each global recycle queue within the circular data structure is indicative of a priority level of each global recycle queue; wherein the circular data structure includes an insertion window having a subset of the set of the global recycle queues for randomly accepting buffers of same priority; wherein the head pointer is moved within the circular data structure from lower priority to higher priority, to promote and demote, the set of global recycle queues without evaluating an age of each global recycle queue; inserting, by the data storage computing device, the buffer and metadata associated with the buffer into the first global recycle queue using the insertion window, based on the buffer priority, wherein the metadata includes a thread identifier corresponding to a first thread from a plurality of threads executed by a plurality of processors of the data storage computing device, the first thread associated with the data, and the metadata indicates whether the buffer is eligible for scavenging; determining, by the data storage computing device, that the first global recycle queue has become a lowest priority queue of the set of global recycle queues, based on the head pointer location, and when the buffer is a least recently used buffer in the first global recycle queue; determining, by the data storage computing device, whether the buffer is scavengable, based on the metadata; wherein the buffer is moved to a holding queue, when the buffer is not scavengable, and when the buffer is scavengable, the buffer is moved to a first pre-flush recycle queue of a per-thread recycle queue set of the first thread; moving, by the data storage computing device, the head pointer to a next global recycle queue, when the first global recycle queue is determined to be empty; and scavenging, by the data storage computing device, the buffer from the first pre-flush recycle queue, when the buffer has a lowest priority in the first pre-flush recycle queue, wherein the buffer is scavenged by removing the buffer from the first pre-flush recycle queue to a first flush queue of the per-thread recycle queue set of the first thread, and placing the buffer in a free pool, when the buffer has a lowest priority in the first flush queue., 2. The method of claim 1 , wherein the buffer has a lowest priority in the first pre-flush recycle queue when the buffer is least recently used., 3. The method of claim 1 , further comprises: determining, by the data storage computing device, whether the buffer is requested by a victim cache; and removing, by the data storage computing device, the buffer from either the first global recycle queue or the first pre-flush recycle queue, prior to the scavenging, and moving the buffer to the victim cache, when the determining indicates the buffer is requested by the victim cache., 4. The method of claim 1 , wherein prior to the scavenging, the buffer is moved from the holding queue to a victim cache, when the buffer is requested by the victim cache., 5. The method of claim 1 , further comprising: promoting, by the data storage computing device, the buffer to a higher priority in response to a determination that the buffer has been accessed a threshold number of times; wherein to promote the buffer, the first thread takes a lock on a second global recycle queue of a higher priority than the first global recycle queue indicated by a position of the second global recycle queue within the circular data structure., 6. The method of claim 1 , wherein the buffer from the holding queue is released for scavenging when the buffer becomes eligible for scavenging., 7. The method of claim 1 , wherein the per-thread recycle queue set of the first thread includes a once queue with buffers that are expected to be accessed only once and then scheduled for scavenging after being accessed once., 8. A non-transitory computer readable medium having stored thereon instructions comprising executable code, which when executed by a processor, causes the processor to perform a method comprising: identifying a first global recycle queue in a set of global recycle queues based on a buffer priority to store data obtained by a data storage computing device, the buffer priority based on data type, wherein the global recycle queues are arranged within a circular data structure such that a head pointer points to a lowest priority global recycle queue and a position of each global recycle queue within the circular data structure is indicative of a priority level of each global recycle queue; wherein the circular data structure includes an insertion window having a subset of the set of the global recycle queues for randomly accepting buffers of same priority; wherein the head pointer is moved within the circular data structure from lower priority to higher priority, to promote and demote, the set of global recycle queues without evaluating an age of each global recycle queue; inserting the buffer and metadata associated with the buffer into the first global recycle queue using the insertion window, based on the buffer priority, wherein the metadata includes a thread identifier corresponding to a first thread from a plurality of threads executed by a plurality of processors of the data storage computing device, the first thread associated with the data, and the metadata indicates whether the buffer is eligible for scavenging; determining that the first global recycle queue has become a lowest priority queue of the set of global recycle queues, based on the head pointer location, and when the buffer is a least recently used buffer in the first global recycle queue; determining whether the buffer is scavengable, based on the metadata; wherein the buffer is moved to a holding queue, when the buffer is not scavengable; and when the buffer is scavengable, the buffer is moved to a first pre-flush recycle queue of a per-thread recycle queue set of the first thread; moving the head pointer to a next global recycle queue, when the first global recycle queue is determined to be empty; and scavenging the buffer from the first pre-flush recycle queue when the buffer has a lowest priority in the first pre-flush recycle queue, wherein the buffer is scavenged by removing the buffer from the first pre-flush recycle queue to a first flush queue of the per-thread recycle queue set of the first thread, and placing the buffer in a free pool, when the buffer has a lowest priority in the first flush queue., 9. The non-transitory computer readable medium of claim 8 , wherein the buffer has a lowest priority in the first pre-flush recycle queue when the buffer is least recently used., 10. The non-transitory computer readable medium of claim 8 , wherein the method further comprising: determining whether the buffer is requested by a victim cache; and removing the buffer from either the first global recycle queue or the first pre-flush recycle queue, prior to the scavenging, and moving the buffer to the victim cache, when the determining indicates the buffer is requested by the victim cache., 11. The non-transitory computer readable medium of claim 8 , wherein prior to the scavenging, the buffer is moved from the holding queue to a victim cache, when the buffer is requested by the victim cache., 12. The non-transitory computer readable medium of claim 8 , wherein the method further comprising: promoting the buffer to a higher priority in response to a determination that the buffer has been accessed a threshold number of times; wherein to promote the buffer, the first thread takes a lock on a second global recycle queue of a higher priority than the first global recycle queue indicated by a position of the second global recycle queue within the circular data structure., 13. The non-transitory computer readable medium of claim 8 , wherein the buffer from the holding queue is released for scavenging when the buffer becomes eligible for scavenging., 14. The non-transitory computer readable medium of claim 8 , wherein the per-thread recycle queue set of the first thread includes a once queue with buffers that are expected to be accessed only once and then scheduled for scavenging after being accessed once., 15. A data storage computing device, comprising a memory containing machine readable medium comprising machine executable code having stored thereon instructions; and a processor coupled to the memory, the processor configured to execute the machine executable code to: identify a first global recycle queue in a set of global recycle queues based on a buffer priority to store data obtained by a data storage computing device, the buffer priority based on data type, wherein the global recycle queues are arranged within a circular data structure such that a head pointer points to a lowest priority global recycle queue and a position of each global recycle queue within the circular data structure is indicative of a priority level of each global recycle queue; wherein the circular data structure includes an insertion window having a subset of the set of the global recycle queues for randomly accepting buffers of same priority; wherein the head pointer is moved within the circular data structure from lower priority to higher priority, to promote and demote, the set of global recycle queues without evaluating an age of each global recycle queue; insert the buffer and metadata associated with the buffer into the first global recycle queue using the insertion window, based on the buffer priority, wherein the metadata includes a thread identifier corresponding to a first thread from a plurality of threads executed by a plurality of processors of the data storage computing device, the first thread associated with the data, and the metadata indicates whether the buffer is eligible for scavenging; determine that the first global recycle queue has become a lowest priority queue of the set of global recycle queues, based on the head pointer location, and when the buffer is a least recently used buffer in the first global recycle queue; determine whether the buffer is scavengable, based on the metadata; wherein the buffer is moved to a holding queue, when the buffer is not scavengable; and when the buffer is scavengable, the buffer is moved to a first pre-flush recycle queue of a per-thread recycle queue set of the first thread; move the head pointer to a next global recycle queue, when the first global recycle queue is determined to be empty; and scavenge the buffer from the first pre-flush recycle queue when the buffer has a lowest priority in the first pre-flush recycle queue, wherein the buffer is scavenged by removing the buffer from the first pre-flush recycle queue to a first flush queue of the per-thread recycle queue set of the first thread, and placing the buffer in a free pool, when the buffer has a lowest priority in the first flush queue., 16. The data storage computing device of claim 15 , wherein the buffer has a lowest priority in the first pre-flush recycle queue when the buffer is least recently used., 17. The data storage computing device of claim 15 , wherein the processor further causes the machine executable code to: determine whether the buffer is requested by a victim cache; and remove the buffer from either the first global recycle queue or the first pre-flush recycle queue, prior to the scavenging, and moving the buffer to the victim cache, when the determining indicates the buffer is requested by the victim cache., 18. The data storage computing device of claim 15 , wherein prior to the scavenging, the buffer is moved from the holding queue to a victim cache, when the buffer is requested by the victim cache., 19. The data storage computing device of claim 15 , wherein the processor further causes the machine executable code to: promote the buffer to a higher priority in response to a determination that the buffer has been accessed a threshold number of times; wherein to promote the buffer, the first thread takes a lock on a second global recycle queue of a higher priority than the first global recycle queue indicated by a position of the second global recycle queue within the circular data structure., 20. The data storage computing device of claim 15 , wherein the buffer from the holding queue is released for scavenging when the buffer becomes eligible for scavenging.\n",
            "Similarity Score: 0.5858\n",
            "\n",
            "\n",
            "Patent ID: 10606848\n",
            "PubMed Claim: 1. A computer-implemented method, comprising: determining a promotion contact list for a user account comprising a subset of a contact list for the user account containing contacts with whom a user of the user account has not sent a message to within a defined recency; determining a predicted bidirectional communication interest for each contact on the promotion contact list for the user account; determining a user predicted likelihood of future activeness for the user account comprising a prediction that the user account will have a defined level of messaging activity in a defined period of time; determining a contact predicted likelihood of future activeness for each contact on the promotion contact list comprising a prediction that the contact will have a defined level of messaging activity in a defined period of time; determining a ranking weight for each contact on the promotion contact list based on the predicted bidirectional communication interest for each contact on the promotion contact list, the user predicted likelihood of future activeness and the contact predicted likelihood of future activeness; and ordering the promotion contact list for display based on the determined ranking weight for each contact on the promotion contact list., 2. The method of claim 1 , wherein the ranking weight for each contact on the promotion contact list weighs contacts with a higher contact predicted likelihood of future activeness more heavily where the user predicted likelihood of future activeness is higher, wherein the ranking weight for each contact on the promotion contact list weighs contacts with a higher contact predicted likelihood of future activeness less heavily where the user predicted likelihood of future activeness is lower., 3. The method of claim 1 , wherein contacts with a higher predicted communication interest have a higher ranking weight., 4. The method of claim 1 , wherein the user predicted likelihood of future activeness is based on a number of threads for the user account, a number of sends for the user account, and a number of highly-active threads for the user account, wherein the contact predicted likelihood of future activeness on the communication system for each contact is based on a number of threads for each contact, a number of sends for each contact, and a number of highly-active threads for each contact., 5. The method of claim 1 , wherein the user predicted likelihood of future activeness is a function of a number of threads for the user account, a number of sends for the user account, and a number of highly-active threads for the user account, wherein the contact predicted likelihood of future activeness on the communication system for each contact is a function of a number of threads for each contact, a number of sends for each contact, and a number of highly-active threads for each contact., 6. The method of claim 5 , the function determined based on a linear regression of an historical data set for the communication system., 7. The method of claim 1 , the ranking weight reduced for one or more previously-viewed contacts on the promotion contact list., 8. The method of claim 1 , further comprising: associating a contact of the promotion contact list with an event badge, the event badge selected based on event information for the contact., 9. An apparatus, comprising: a processor circuit on a device; and memory containing instructions that, when executed, cause the processor to: determine a promotion contact list for the user account comprising a subset of a contact list for the user account containing contacts with whom a user of the user account has not sent a message to within a defined recency; determine a bidirectional predicted communication interest for each contact on the promotion contact list; determine a user predicted likelihood of future activeness for the user account comprising a prediction that the user account will have a defined level of messaging activity in a defined period of time; determine a contact predicted likelihood of future activeness for each contact on the promotion contact list comprising a prediction that the contact will have a defined level of messaging activity in a defined period of time; determine a ranking weight for each contact on the promotion contact list based on the predicted bidirectional communication interest for each contact on the promotion contact list, the user predicted likelihood of future activeness and the contact predicted likelihood of future activeness; and transmit an ordered promotion contact list to the client device ordered for display based on a determined ranking weight for each contact on the ordered promotion contact list., 10. The apparatus of claim 9 , wherein the ranking weight for each contact on the promotion contact list weighs contacts with a higher contact predicted likelihood of future activeness more heavily where the user predicted likelihood of future activeness is higher, wherein the ranking weight for each contact on the promotion contact list weighs contacts with a higher contact predicted likelihood of future activeness less heavily where the user predicted likelihood of future activeness is lower, wherein contacts with a higher predicted communication interest have a higher ranking weight., 11. The apparatus of claim 9 , wherein the user predicted likelihood of future activeness is based on a number of threads for the user account, a number of sends for the user account, and a number of highly-active threads for the user account, wherein the contact predicted likelihood of future activeness on the communication system for each contact is based on a number of threads for each contact, a number of sends for each contact, and a number of highly-active threads for each contact., 12. The apparatus of claim 9 , wherein the user predicted likelihood of future activeness is a function of a number of threads for the user account, a number of sends for the user account, and a number of highly-active threads for the user account, wherein the contact predicted likelihood of future activeness on the communication system for each contact is a function of a number of threads for each contact, a number of sends for each contact, and a number of highly-active threads for each contact, the function determined based on a linear regression of an historical data set for the communication system., 13. The apparatus of claim 9 , the ranking weight reduced for one or more previously-viewed contacts of the promotion contact list., 14. The apparatus of claim 9 , the instructions further causing the processor to: associate a contact of the promotion contact list with an event badge, the event badge selected based on event information for the contact., 15. At least one computer-readable storage medium comprising instructions that, when executed, cause a system to: determine a promotion contact list for a user account comprising a subset of a contact list for the user account containing contacts with whom a user of the user account has not send a message to within a defined recency; determine a predicted bidirectional communication interest for each contact on the promotion contact list; determine a user predicted likelihood of future activeness comprising a prediction that the user account will have a defined level of messaging activity in a defined period of time; determine a contact predicted likelihood of future activeness for each contact on the promotion contact list comprising a prediction that the contact will have a defined level of messaging activity in a defined period of time; determine a ranking weight for each contact on the promotion contact list based on the predicted bidirectional communication interest for each contact on the promotion contact list, the user predicted likelihood of future activeness, and the contact predicted likelihood of future activeness; and order the promotion contact list for display based on the determined ranking weight for each contact on the promotion contact list., 16. The computer-readable storage medium of claim 15 , wherein the ranking weight for each contact on the promotion contact list weighs contacts with a higher contact predicted likelihood of future activeness more heavily where the user predicted likelihood of future activeness is higher, wherein the ranking weight for each contact on the promotion contact list weighs contacts with a higher contact predicted likelihood of future activeness less heavily where the user predicted likelihood of future activeness is lower, wherein contacts with a higher predicted communication interest have a higher ranking weight., 17. The computer-readable storage medium of claim 15 , wherein the user predicted likelihood of future activeness is based on a number of threads for the user account, a number of sends for the user account, and a number of highly-active threads for the user account, wherein the contact predicted likelihood of future activeness on the communication system for each contact is based on a number of threads for each contact, a number of sends for each contact, and a number of highly-active threads for each contact., 18. The computer-readable storage medium of claim 15 , wherein the user predicted likelihood of future activeness is a function of a number of threads for the user account, a number of sends for the user account, and a number of highly-active threads for the user account, wherein the contact predicted likelihood of future activeness on the communication system for each contact is a function of a number of threads for each contact, a number of sends for each contact, and a number of highly-active threads for each contact, the function determined based on a linear regression of an historical data set for the communication system., 19. The computer-readable storage medium of claim 15 , the ranking weight reduced for one or more previously-viewed contacts of the promotion contact list., 20. The computer-readable storage medium of claim 15 , comprising further instructions that, when executed, cause a system to: associate a contact of the promotion contact list with an event badge, the event badge selected based on event information for the contact.\n",
            "Similarity Score: 0.5856\n",
            "\n",
            "\n",
            "Patent ID: 10606943\n",
            "PubMed Claim: 1. An information handling system comprising: one or more processors; a memory coupled to at least one of the processors; a set of computer program instructions stored in the memory and executed by at least one of the processors in order to perform actions of: analyzing, by a natural language fault injection system, a first text segment sent from an author client, wherein the analyzing produces a set of analysis results; selecting a first fault class, from a plurality of fault classes, based on comparing the analysis results against a set of parameters, wherein each of the plurality of fault classes define one of a plurality of types of faults to inject into the first text segment; injecting, by the natural language fault injection system, a natural language fault, based on the selected first fault class, into the first text segment to produce a second text segment, wherein the first text segment and the second text segment are written in a same natural language; selecting a reviewer from a plurality of reviewers based on the selected first fault class; sending, by the fault injection system, the second text segment to a reviewer client corresponding to the reviewer; receiving, at the fault injection system, a third text segment from the reviewer client, wherein the third text segment comprises at least one correction to the second text segment by the reviewer; generating, by the fault injection system, an efficacy score by comparing the third text segment against the first text segment, wherein the efficacy score indicates whether the reviewer corrected the natural language fault included in the second text segment; updating a reviewer profile of the reviewer based on the efficacy score; and selecting the reviewer to review an upcoming text segment based on the updated efficacy score., 2. The information handling system of claim 1 wherein the processors perform additional actions comprising: determining that the first fault class is a noun swap fault class; and swapping a first noun in the first text segment with a second noun in the first text segment based on the first rule to produce the second text segment., 3. The information handling system of claim 1 wherein the processors perform additional actions comprising: determining that the first fault class is a factual discrepancy fault class; and modifying at least one fact in the first text segment based on the first rule to produce the second text segment., 4. The information handling system of claim 1 wherein the processors perform additional actions comprising: determining that the first fault class is a sentiment modifier fault class; and modifying a sentiment of the first text segment based on the first rule to produce the second text segment., 5. The information handling system of claim 1 wherein the processors perform additional actions comprising: injecting a different natural language fault into a different first text segment based on the updated reviewer profile to produce a different second text segment; and sending the different second text segment to the reviewer to review., 6. The information handling system of claim 1 wherein the processors perform additional actions comprising: injecting a different natural language fault into the first text segment to produce a different second text segment, wherein the different natural language fault is based on a second fault class from the plurality of fault classes; selecting a different reviewer based on the second fault class; and sending the different second text segment to the different reviewer to review., 7. A computer program product stored in a non-transitory computer readable storage medium, comprising computer program code that, when executed by an information handling system, causes the information handling system to perform actions comprising: analyzing, by a natural language fault injection system, a first text segment sent from an author client, wherein the analyzing produces a set of analysis results; selecting a first fault class, from a plurality of fault classes, based on comparing the analysis results against a set of parameters, wherein each of the plurality of fault classes define one of a plurality of types of faults to inject into the first text segment; injecting, by the natural language fault injection system, a natural language fault, based on the selected first fault class, into the first text segment to produce a second text segment, wherein the first text segment and the second text segment are written in a same natural language; selecting a reviewer from a plurality of reviewers based on the selected first fault class; sending, by the fault injection system, the second text segment to a reviewer client corresponding to the reviewer; receiving, at the fault injection system, a third text segment from the reviewer client, wherein the third text segment comprises at least one correction to the second text segment by the reviewer; generating, by the fault injection system, an efficacy score by comparing the third text segment against the first text segment, wherein the efficacy score indicates whether the reviewer corrected the natural language fault included in the second text segment; updating a reviewer profile of the reviewer based on the efficacy score; and selecting the reviewer to review an upcoming text segment based on the updated efficacy score., 8. The computer program product of claim 7 wherein the information handling system performs further actions comprising: determining that the first fault class is a noun swap fault class; and swapping a first noun in the first text segment with a second noun in the first text segment based on the first rule to produce the second text segment., 9. The computer program product of claim 7 wherein the information handling system performs further actions comprising: determining that the first fault class is a factual discrepancy fault class; and modifying at least one fact in the first text segment based on the first rule to produce the second text segment., 10. The computer program product of claim 7 wherein the information handling system performs further actions comprising: determining that the first fault class is a sentiment modifier fault class; and modifying a sentiment of the first text segment based on the first rule to produce the second text segment., 11. The computer program product of claim 7 wherein the information handling system performs further actions comprising: injecting a different natural language fault into a different first text segment based on the updated reviewer profile to produce a different second text segment; and sending the different second text segment to the reviewer to review.\n",
            "Similarity Score: 0.5851\n",
            "\n",
            "\n",
            "Patent ID: 10606737\n",
            "PubMed Claim: 1. A method for testing a resource constrained device, the method comprising: determining, via a testing engine, a plurality of test cases for testing the resource constrained device; accessing, via the testing engine, a plurality of test scripts corresponding to the plurality of test cases; determining, via the testing engine, a set of mutually independent primitive executables for the plurality of test scripts corresponding to the plurality of test cases, by: determining a plurality of steps of the plurality of test scripts; and determining one or more primitive executables for each of the plurality of steps of the plurality of test scripts, wherein the one or more primitive executables for each of the plurality of steps of the plurality of test scripts correspond to one or more atomic operations of the resource constrained device; determining, via the testing engine, a candidate test case from the plurality of test cases, wherein the candidate test case from the plurality of test cases is determined based on: computing a test score for each of the plurality of test cases based on a plurality of script execution parameters for a corresponding test script, wherein each of the plurality of script execution parameters for the corresponding test script comprises at least one of an estimated time of execution, an estimated usage of one or more resources, and a coverage of one or more components of the resource constrained device; and selecting the candidate test case from the plurality of test cases based on the computed test score for each of the plurality of test cases; transmitting, via the testing engine, the one or more primitive executables for each of the plurality of steps of the plurality of test scripts corresponding to the candidate test case from the plurality of test cases to the resource constrained device for execution; and receiving, via the testing engine, a result corresponding to the execution of the one or more primitive executables for each of the plurality of steps of the plurality of test scripts corresponding to the candidate test case from the plurality of test cases., 2. The method of claim 1 , further comprising: creating the one or more primitive executables for each of the plurality of steps of the plurality of test scripts; and determining a plurality of executable execution parameters for each of the plurality of one or more primitive executables for each of the plurality of steps of the plurality of test scripts., 3. The method of claim 2 , wherein each of the plurality of executable execution parameters comprises at least one of a name of the one or more primitive executables for each of the plurality of steps of the plurality of test scripts, a plurality of input parameters, a plurality of output parameters, an estimated time of execution, an estimated usage of one or more resources, and a coverage of one or more components of the resource constrained device., 4. The method of claim 1 , further comprising: creating the plurality of test scripts corresponding to the plurality of test cases; and determining the plurality of script execution parameters for each of the plurality of test scripts corresponding to the plurality of test cases., 5. The method of claim 1 , further comprising at least one of: determining a dependency of each of the plurality of steps of the plurality of test scripts with respect to each of a plurality of preceding steps of the plurality of test scripts; and determining a batch execution of the one or more primitive executables for each of the plurality of steps of the plurality of test scripts., 6. The method of claim 1 , wherein determining the candidate test case from the plurality of test cases further comprises sequencing the candidate test case based on a highest test score., 7. The method of claim 1 , wherein transmitting the one or more primitive executables for each of the plurality of steps of the plurality of test scripts corresponding to the candidate test case from the plurality of test cases to the resource constrained device for execution comprises: determining an availability of each of the one or more resources in the resource constrained device; and transmitting the one or more primitive executables for each of the plurality of steps of the plurality of test scripts corresponding to the candidate test case from the plurality of test cases to the resource constrained device based on the availability of each of the one or more resources in the resource constrained device., 8. The method of claim 7 , wherein the availability of each of the one or more resources in the resource constrained device is determined at a periodic interval or at run time., 9. A system for testing a resource constrained device, the system comprising: at least one processor; and a non-transitory computer-readable storage medium storing instructions that, when executed by the at least one processor, cause the at least one processor to perform operations comprising: determining, via a testing engine, a plurality of test cases for testing the resource constrained device; accessing, via the testing engine, a plurality of test scripts corresponding to the plurality of test cases; determining, via the testing engine, a set of mutually independent primitive executables for the plurality of test scripts corresponding to the plurality of test cases, by: determining a plurality of steps of the plurality of test scripts; and determining one or more primitive executables for each of the plurality of steps of the plurality of test scripts, wherein the one or more primitive executables for each of the plurality of steps of the plurality of test scripts correspond to one or more atomic operations of the resource constrained device; determining, via the testing engine, a candidate test case from the plurality of test cases, wherein the candidate test case from the plurality of test cases is determined based on: computing a test score for each of the plurality of test cases based on a plurality of script execution parameters for a corresponding test script, wherein each of the plurality of script execution parameters for the corresponding test script comprises at least one of an estimated time of execution, an estimated usage of one or more resources, and a coverage of one or more components of the resource constrained device; and selecting the candidate test case from the plurality of test cases based on the computed test score for each of the plurality of test cases; transmitting, via the testing engine, the one or more primitive executables for each of the plurality of steps of the plurality of test scripts corresponding to the candidate test case from the plurality of test cases to the resource constrained device for execution; and receiving, via the testing engine, a result corresponding to the execution of the one or more primitive executables for each of the plurality of steps of the plurality of test scripts corresponding to the candidate test case from the plurality of test cases., 10. The system of claim 9 , wherein the operations further comprise: creating the one or more primitive executables for each of the plurality of steps of the plurality of test scripts; and determining a plurality of executable execution parameters for each of the one or more primitive executables for each of the plurality of steps of the plurality of test scripts, wherein each of the plurality of executable execution parameters comprises at least one of a name of the one or more primitive executables for each of the plurality of steps of the plurality of test scripts, a plurality of input parameters, a plurality of output parameters, an estimated time of execution, an estimated usage of one or more resources, and a coverage of one or more components of the resource constrained device., 11. The system of claim 9 , wherein the operations further comprise: creating the plurality of test scripts corresponding to the plurality of test cases; and determining the plurality of script execution parameters for each of the plurality of test scripts corresponding to the plurality of test cases., 12. The system of claim 11 , wherein the operations further comprise at least one of: determining a dependency of each of the plurality of steps of the plurality of test scripts with respect to each of a plurality of preceding steps of the plurality of test scripts; and determining a batch execution of the one or more primitive executables for each of the plurality of steps of the plurality of test scripts., 13. The system of claim 9 , wherein determining the candidate test case from the plurality of test cases further comprises sequencing the candidate test case based on a highest test score., 14. The system of claim 9 , wherein transmitting the one or more primitive executables for each of the plurality of steps of the plurality of test scripts corresponding to the candidate test case from the plurality of test cases to the resource constrained device for execution comprises: determining an availability of each of the one or more resources in the resource constrained device; and transmitting the one or more primitive executables for each of the plurality of steps of the plurality of test scripts corresponding to the candidate test case from the plurality of test cases to the resource constrained device based on the availability of each of the one or more resources in the resource constrained device., 15. The system of claim 14 , wherein the availability of each of the one or more resources in the resource constrained device is determined at a periodic interval or at run time., 16. A non-transitory computer-readable storage medium having stored thereon, a set of computer-executable instructions for causing a computer comprising one or more processors to perform steps comprising: determining, via a testing engine, a plurality of test cases for testing a resource constrained device; accessing, via the testing engine, a plurality of test scripts corresponding to the plurality of test cases; determining, via the testing engine, a set of mutually independent primitive executables for the plurality of test scripts corresponding to the plurality of test cases, by: determining a plurality of steps of the plurality of test scripts; and determining one or more primitive executables for each of the plurality of steps of the plurality of test scripts, wherein the one or more primitive executables for each of the plurality of steps of the plurality of test scripts correspond to one or more atomic operations of the resource constrained device; determining, via the testing engine, a candidate test case from the plurality of test cases, wherein the candidate test case from the plurality of test cases is determined based on: computing a test score for each of the plurality of test cases based on a plurality of script execution parameters for a corresponding test script, wherein each of the plurality of script execution parameters for the corresponding test script comprises at least one of an estimated time of execution, an estimated usage of one or more resources, and a coverage of one or more components of the resource constrained device; and selecting the candidate test case from the plurality of test cases based on the computed test score for each of the plurality of test cases; transmitting, via the testing engine, the one or more primitive executables for each of the plurality of steps of the plurality of test scripts corresponding to the candidate test case from the plurality of test cases to the resource constrained device for execution; and receiving, via the testing engine, a result corresponding to the execution of the one or more primitive executables for each of the plurality of steps of the plurality of test scripts corresponding to the candidate test case from the plurality of test cases.\n",
            "Similarity Score: 0.5848\n",
            "\n",
            "\n",
            "Patent ID: 10606758\n",
            "PubMed Claim: 1. A method of operating a memory system, comprising: receiving an unmap command corresponding to logical addresses; setting a state of at least one unmap bit corresponding to the logical addresses among a plurality of unmap bits included in an unmap filter to an unmapped state in response to the unmap command; and updating first mapping information by maintaining logical-to-physical mapping information corresponding to the at least one unmap bit set to the unmapped state, among the logical addresses, and setting logical-to-physical mapping information about a logical address not corresponding to the at least one unmap bit, among the logical addresses, to the unmapped state., 2. The method according to claim 1 , wherein the unmap filter is stored in a nonvolatile memory device, and wherein the operation of setting a state of at least one unmap bit comprises writing the at least one unmap bit set to the unmapped state to the nonvolatile memory device., 3. The method according to claim 1 , wherein the logical-to-physical address mapping information is stored to the nonvolatile memory device, wherein the operation of setting a state of logical-to-physical address mapping information comprises: reading the logical-to-physical address mapping information from the nonvolatile memory device; modifying the state of the logical-to-physical address mapping information read from the nonvolatile memory device to the unmapped state; and writing the modified logical-to-physical address mapping information to the nonvolatile memory device., 4. The method according to claim 1 , wherein each of the plurality of unmap bits corresponds to a plurality of logical addresses., 5. The method according to claim 4 , wherein each of the plurality of unmap bits is set to the unmapped state when all of the corresponding logical addresses are unmapped., 6. The method according to claim 1 , further comprising setting a state of logical-to-physical address mapping information corresponding to the at least one unmap bit set to the unmapped state, to an unmapped state., 7. The method according to claim 6 , further comprising: receiving a write command for a first logical address among the logical addresses corresponding to the unmap command; and setting a state of an unmap bit, among the plurality of unmapped bits, corresponding to the first logical address to a mapped state., 8. The method according to claim 7 , further comprising: allocating a physical address corresponding to the first logical address in response to the write command; and updating a mapping relationship between the first logical address and the physical address to the logical-to-physical address mapping information corresponding to the unmap bit set to a mapped state., 9. The method according to claim 2 , wherein the writing comprises simultaneously writing all of the other plurality of unmap bits included in the unmap filter to the nonvolatile memory device., 10. The method according to claim 9 , wherein the unmap filter, before being set to the unmapped state, is stored to a first memory region of the nonvolatile memory device, and wherein the unmap filter set to the unmapped state is stored to a second memory region of the nonvolatile memory device., 11. A method of operating a memory system, comprising: checking an unmap bit set to an unmapped state, among a plurality of unmap bits included in an unmap filter stored in a first memory region of a nonvolatile memory; determining an unmapped first logical address based on the check of the unmap bit set to the unmapped state; determining an unmapped second logical address from logical-to-physical address mapping information stored in a second memory region of the nonvolatile memory; and determining an unmapped logical address region based on the first logical address and the second logical address., 12. The method according to claim 11 , further comprising loading logical-to-physical address mapping information to a buffer memory based on the unmapped logical address region., 13. The method according to claim 12 , further comprising performing at least one of a reading, modifying and writing operation on the logical-to-physical address mapping information loaded to the buffer memory to the second memory region., 14. The method according to claim 12 , further comprising: receiving a write command corresponding to the first logical address; and setting an unmap bit corresponding to the first logical address to a mapped state., 15. The method according to claim 14 , further comprising: allocating a physical address corresponding to the first logical address in response to the write command; and updating a mapping relationship between the first logical address and the physical address to the logical-to-physical address mapping information., 16. A memory system comprising: a nonvolatile memory device configured to store logical-to-physical address mapping information, and an unmap filter including a plurality of unmap bits; and a memory controller configured to receive an unmap command and logical addresses corresponding to the unmap command from a host, and control the nonvolatile memory device in response to the unmap command, wherein the memory controller is configured to: set at least one unmap bit corresponding to the logical addresses among the plurality of unmap bits to an unmapped state, and store the set at least one unmap bit to the nonvolatile memory device; and maintain logical-to-physical address mapping information corresponding to the at least one unmap bit set to the unmapped state among the logical addresses and modify logical-to-physical mapping information about a logical address not corresponding to the at least one unmap bit, among the logical addresses, to the unmapped state., 17. The memory system according to claim 16 , wherein the memory controller is configured to: read the logical-to-physical address mapping information from the nonvolatile memory device; temporarily store the logical-to-physical address mapping information read from the nonvolatile memory device to a buffer memory; modify the state of the logical-to-physical address mapping information temporarily stored in the buffer memory to the unmapped state; and write the modified logical-to-physical address mapping information to the nonvolatile memory device., 18. The memory system according to claim 16 , wherein each of the plurality of unmap bits corresponds to a plurality of logical addresses., 19. The memory system according to claim 18 , wherein each of the plurality unmap bits is set to the unmapped state when all of the corresponding logical addresses are unmapped., 20. The memory system according to claim 16 , wherein the memory controller comprises a buffer memory, and wherein the memory controller is configured to load the logical-to-physical address mapping information stored in the nonvolatile memory device to the buffer memory in response to a read command input from the host.\n",
            "Similarity Score: 0.5845\n",
            "\n",
            "\n",
            "Patent ID: 10606941\n",
            "PubMed Claim: 1. A method comprising: interacting with a content server to display electronic content at a computing device, the electronic content associated with a plurality of annotations, each annotation specifying a respective portion of the electronic content; while displaying the electronic content, receiving an annotation input for a first annotation based on user interaction with a user interface of the computing device, the annotation input including a single user input selection indicating a plurality of boundary points defining a first region of an image; in response to receiving the single user input selection, displaying a text entry box substantially simultaneously with displaying the first region of the image, the text entry box configured to receive a first comment; receiving the first comment via the text entry box; sending the first annotation to the content server; displaying the first annotation at the computing device, the first annotation including the first comment associated with the first region of the image, wherein displaying the first annotation comprises simultaneously displaying the first region of the image and the first comment with the first region of the image visually designated by a border; while displaying the first annotation, receiving a second input to display a second annotation associated with a second portion of the electronic content, the second annotation including one or more comments associated with the second portion, the second portion representing a second spatial segment of the electronic content; and responsive to receiving the second input, displaying the second portion of the electronic content and the one or more comments associated with the second portion at the computing device., 2. The method of claim 1 , wherein displaying the first annotation comprises: generating a display including a first region of the display and a second region of the display; displaying the first comment in the first region of the display; and displaying the first region of the image in the second region of the display., 3. The method of claim 2 , wherein the second input to display the second annotation comprises a swipe gesture received at the first region of the display., 4. The method of claim 2 , wherein the first region of the display is scrollable to display additional comments of the first annotation., 5. The method of claim 1 , wherein displaying the first annotation comprises: displaying the electronic content at a zoom level such that the first region of the image is displayed with the border defining a distance between at least one side of the first region of the image and an edge of a display screen of the computing device., 6. The method of claim 5 , further comprising: responsive to receiving the second input to display the second annotation, panning and zooming the electronic content until a second region of the image is displayed with a second border defining a distance between at least one side of the second region of the image and the edge of the display screen., 7. The method of claim 1 , wherein displaying the first annotation comprises displaying a box overlaid on the electronic content and identifying the first region of the image., 8. The method of claim 1 , further comprising: receiving a third input to create a new annotation associated with the electronic content; displaying an adjustable selection box around a third portion of the electronic content; receiving a third comment entered by a user; and associating the third comment with the third portion of the electronic content., 9. The method of claim 1 , further comprising, while displaying the first annotation: receiving a fourth comment from a user of the computing device; and adding the received fourth comment to a comment chain., 10. The method of claim 1 , wherein the single user input selection corresponds to a selection box, wherein the selection box is one of: a freeform shape or a non-freeform shape., 11. The method of claim 1 , further comprising: navigating to the second annotation by one of: repositioning the electronic content to a location associated with the second annotation, selecting the second annotation from a menu, and selecting an arrow key of the computing device or an arrow button on an electronic display of the computing device., 12. The method of claim 1 , further comprising: pushing from the content server to the computing device a new annotation to the electronic content, wherein the first annotation and the new annotation are initially input by different users., 13. The method of claim 1 , wherein the second portion of the electronic content is a second region of the image., 14. A non-transitory computer-readable storage medium storing executable computer program instructions that are executable by a processor to: interact with a content server to display electronic content, the electronic content associated with a plurality of annotations each specifying a respective portion of the electronic content; while displaying the electronic content, receive an annotation input for a first annotation based on user interaction with a user interface of a computing device, the annotation input including a single user input selection indicating a plurality of boundary points defining a first region of an image; in response to receiving the single user input selection, display a text entry box substantially simultaneously with displaying the first region of the image, the text entry box configured to receive a first comment; receive the first comment via the text entry box; send the first annotation to the content server; display the first annotation, the first annotation including the first comment associated with the first region of the image, wherein displaying the first annotation comprises simultaneously displaying the first region of the image and the first comment with the first region of the image visually designated by a border; while displaying the first annotation, receive a second input to display a second annotation associated with a second portion of the electronic content, the second annotation including one or more comments associated with the second portion, the second portion representing a spatial segment of the electronic content; and responsive to receiving the second input, display the second portion of the electronic content and the one or more comments associated with the second portion., 15. The non-transitory computer-readable storage medium of claim 14 , wherein the instructions for displaying the first annotation comprise instructions that are executable by the processor to: generate a display including a first region of the display and a second region of the display; display the first comment in the first region of the display; and display the first region of the image in the second region of the display., 16. The non-transitory computer-readable storage medium of claim 15 , wherein the second input to display the second annotation comprises a swipe gesture received at the first region of the display., 17. The non-transitory computer-readable storage medium of claim 15 , wherein the first region of the display is scrollable to display additional comments of the first annotation., 18. The non-transitory computer-readable storage medium of claim 14 , wherein the instructions for displaying the first annotation comprise instructions that are executable by the processor to: display the electronic content at a zoom level such that the first region of the image is displayed with the border defining a distance between at least one side of the first region of the image and an edge of a display screen., 19. The non-transitory computer-readable storage medium of claim 18 , further comprising instructions that are executable by the processor to: responsive to receiving the second input to display the second annotation, pan and zoom the electronic content until the second portion is displayed with a second border defining a distance between at least one side of the second portion and the edge of the display screen., 20. The non-transitory computer-readable storage medium of claim 14 , wherein the instructions for displaying the first annotation comprise instructions that are executable by the processor to display a box overlaid on the electronic content and identifying the first region of the image., 21. The non-transitory computer-readable storage medium of claim 14 , further comprising instructions that are executable by the processor to: receive a third input to create a new annotation associated with the electronic content; display an adjustable selection box around a third portion of the electronic content; receive a third comment entered by a user; and associate the third comment with the third portion of the electronic content., 22. The non-transitory computer-readable storage medium of claim 14 , further comprising instructions that are executable by the processor to, while displaying the first annotation: receive a fourth comment from a user; and add the received fourth comment to a comment chain., 23. The non-transitory computer-readable storage medium of claim 14 , wherein: the first annotation is displayed at a first computing device; the second input to display the second annotation is received from a second computing device; and the second portion of the electronic content is displayed at the second computing device.\n",
            "Similarity Score: 0.5845\n",
            "\n",
            "\n",
            "Patent ID: 10606957\n",
            "PubMed Claim: 1. A system for translating natural language policy text into logical access control policy code, comprising: a policy composer to receive a sequence of free text natural language policy text strings provided by a user; an attribute dictionary communicably connected to the policy composer defining attributes and their logical access control policy equivalents; and a natural language policy set communicably connected to the policy composer with samples of natural language policy rules and their logical access control policy equivalents; wherein the policy composer is configured to use natural language processing to automatically identify a plurality of candidate attributes in the sequence of free text natural language policy text strings and store the candidate attributes in the attribute dictionary; wherein the policy composer is configured to identify a plurality of candidate natural language policy rules from the natural language policy set and populate the plurality of candidate natural language policy rules with the candidate attributes to generate a populated rule and evaluate whether the populated rule is a well-formed rule; and wherein the policy composer uses the attribute dictionary and the natural language policy set to translate the input natural language policy text strings into logical access control code., 2. The system of claim 1 , wherein the logical access control code is in XACML format., 3. The system of claim 1 , wherein the logical access control code is in NGAC format., 4. The system of claim 1 , wherein the attribute dictionary is populated with attributes from the natural language policy set., 5. The system of claim 1 , wherein the attribute dictionary is populated by user input., 6. The system of claim 1 , wherein the natural language processing comprises named entity recognition that identifies a named entity that is a string in the input free text natural language policy text strings, wherein a first natural language policy set includes metadata for the named entity from a previously translated policy., 7. The system of claim 1 , wherein the natural language processing comprises morphological segmentation., 8. A method for translating natural language policy text into logical access control policy code, comprising: receiving a sequence of free text natural language policy text strings input by a user to a policy composer; using natural language processing to automatically identify a plurality of candidate attributes in the sequence of free text natural language policy text strings and store the candidate attributes in an attribute dictionary; identifying a plurality of candidate natural language policy rules from a natural language policy set; populating the plurality of candidate natural language policy rules with the candidate attributes to generate a populated rule; determining if the populated rule is well-formed; translating the populated rule into logical access control code; and storing the logical access control code in a policy archive., 9. The method of claim 8 , wherein the logical access control code is in XACML format., 10. The method of claim 8 , wherein the logical access control code is in NGAC format., 11. The method of claim 8 , wherein the attribute dictionary is populated with attributes from the natural language policy set., 12. The method of claim 8 , wherein the attribute dictionary is populated by user input., 13. The method of claim 8 , wherein the natural language processing comprises named entity recognition that identifies a named entity that is a string in the input free text natural language policy text strings, wherein a first natural language policy set includes metadata for the named entity from a previously translated policy., 14. The method of claim 8 , wherein the natural language processing comprises morphological segmentation., 15. A non-transitory computer-readable medium comprising instructions for translating natural language policy text into logical access control policy code, the non-transitory computer-readable medium comprising instructions for: receiving a sequence of free text natural language policy text strings input by a user to a policy composer; using natural language processing to automatically identify a plurality of candidate attributes in the sequence of free text natural language policy text strings and store the candidate attributes in an attribute dictionary; identifying a plurality of candidate natural language policy rules from a natural language policy set; populating the plurality of candidate natural language policy rules with the candidate attributes to generate a populated rule; determining if the populated rule is well-formed; translating the populated rule into logical access control code; and storing the logical access control code in a policy archive., 16. The non-transitory computer-readable medium of claim 15 , wherein the logical access control code is in XACML format., 17. The non-transitory computer-readable medium of claim 15 , wherein the logical access control code is in NGAC format., 18. The non-transitory computer-readable medium of claim 15 , wherein the attribute dictionary is populated with attributes from the natural language policy set., 19. The non-transitory computer-readable medium of claim 15 , wherein the attribute dictionary is populated by user input., 20. The non-transitory computer-readable medium of claim 15 , wherein the natural language processing comprises named entity recognition that identifies a named entity that is a string in the input free text natural language policy text strings, wherein a first natural language policy set includes metadata for the named entity from a previously translated policy.\n",
            "Similarity Score: 0.5841\n",
            "\n",
            "\n",
            "Patent ID: 10606944\n",
            "PubMed Claim: 1. A method for categorizing keywords, the method comprising: receiving, by a computer, a keyword to be categorized; receiving, by the computer, a category dictionary including categories having associated respective pluralities of registered keywords; receiving, by the computer, a text corpus; identifying, by the computer, one or more registered keywords in the category dictionary having a degree of similarity to the keyword to be categorized that is equal to or greater than a predetermined value, and extracting the categories associated with the identified registered keywords; identifying, by the computer, one or more registered keywords co-occurring in the text corpus with the keyword to be categorized, and extracting the categories associated with the identified co-occurring registered keywords; determining, by the computer, a degree of importance of each extracted category based on a function of the identified registered keywords in the category dictionary and/or a function of the identified co-occurring registered keywords; and outputting, by the computer, the extracted categories, with at least an indication of each category's relative importance, as category candidates for categorizing the keyword to be categorized., 2. A method in accordance with claim 1 , wherein the degree of similarity is determined on the basis of the number of insertion, deletion, and/or substitution edits required to be performed on the keyword to be categorized for the resulting edited word to match a registered keyword., 3. A method in accordance with claim 1 , wherein the degree of importance of the extracted categories is determined on the basis of the number of identified registered keywords associated with each extracted category., 4. A method in accordance with claim 1 , wherein the degree of importance of an extracted category is determined on the basis of the number of identified registered keywords associated with the category that are identified registered keywords associated with another category., 5. A computer program product for categorizing keywords, the computer program product comprising: one or more computer-readable storage devices and program instructions stored on the one or more computer-readable storage devices, the program instructions comprising: program instructions to receive a keyword to be categorized; program instructions to receive a category dictionary including categories having associated respective pluralities of registered keywords; program instructions to receive a text corpus; program instructions to identify one or more registered keywords in the category dictionary having a degree of similarity to the keyword to be categorized that is equal to or greater than a predetermined value, and to extract the categories associated with the identified registered keywords; program instructions to identify or more registered keywords co-occurring in the text corpus with the keyword to be categorized, and to extract the categories associated with the identified co-occurring registered keywords; program instructions to determine a degree of importance of each extracted category based on a function of the identified registered keywords in the category dictionary and/or a function of the identified co-occurring registered keywords; and program instructions to output the extracted categories, with at least an indication of each category's relative importance, as category candidates for categorizing the keyword to be categorized., 6. A computer program product in accordance with claim 5 , wherein the degree of similarity is determined on the basis of the number of insertion, deletion, and/or substitution edits required to be performed on the keyword to be categorized for the resulting edited word to match a registered keyword., 7. A computer program product in accordance with claim 5 , wherein the degree of importance of the extracted categories is determined on the basis of the number of identified registered keywords associated with each extracted category., 8. A computer program product in accordance with claim 5 , wherein the degree of importance of an extracted category is determined on the basis of the number of identified registered keywords associated with the category that are identified registered keywords associated with another category., 9. A computer system for categorizing keywords, the computer system comprising: one or more computer processors, one or more computer-readable storage devices, and program instructions stored on one or more of the computer-readable storage devices for execution by at least one of the one or more processors, the program instructions comprising: program instructions to receive a keyword to be categorized; program instructions to receive a category dictionary including categories having associated respective pluralities of registered keywords; program instructions to receive a text corpus; program instructions to identify one or more registered keywords in the category dictionary having a degree of similarity to the keyword to be categorized that is equal to or greater than a predetermined value, and to extract the categories associated with the identified registered keywords; program instructions to identify or more registered keywords co-occurring in the text corpus with the keyword to be categorized, and to extract the categories associated with the identified co-occurring registered keywords; program instructions to determine a degree of importance of each extracted category based on a function of the identified registered keywords in the category dictionary and/or a function of the identified co-occurring registered keywords; and program instructions to output the extracted categories, with at least an indication of each category's relative importance, as category candidates for categorizing the keyword to be categorized., 10. A computer system in accordance with claim 9 , wherein the degree of similarity is determined on the basis of the number of insertion, deletion, and/or substitution edits required to be performed on the keyword to be categorized for the resulting edited word to match a registered keyword., 11. A computer system in accordance with claim 9 , wherein the degree of importance of the extracted categories is determined on the basis of the number of identified registered keywords associated with each extracted category., 12. A computer system in accordance with claim 9 , wherein the degree of importance of an extracted category is determined on the basis of the number of identified registered keywords associated with the category that are identified registered keywords associated with another category.\n",
            "Similarity Score: 0.5830\n",
            "\n",
            "\n",
            "Patent ID: 10606870\n",
            "PubMed Claim: 1. A non-transitory computer readable medium comprising computer executable instructions stored thereon to cause one or more processing units of a processing device to: obtain a first plurality of unencrypted documents, wherein each document in the first plurality of unencrypted documents comprises: a Small Index of tags based, at least in part, on a content of the respective document; and a Large Index of tags based, at least in part, on a predictive analysis of the tags in the Small Index of the respective document; obtain a second encrypted document, wherein the second encrypted document comprises a Small Index of tags based, at least in part, on a content of the second encrypted document; create one or more associations between the second encrypted document and one or more documents of the first plurality of unencrypted documents based, at least in part, on the Small Index of tags of the second encrypted document and the respective Small Index of tags of the one or more of the first plurality of unencrypted documents; and generate a result set of documents in response to a received query, wherein the result set comprises the second encrypted document., 2. The non-transitory computer readable medium of claim 1 , wherein the first plurality of unencrypted documents are each owned by a first user., 3. The non-transitory computer readable medium of claim 1 , further comprising instructions to: generate a Large Index of tags for the second encrypted document based, at least in part, on a predictive analysis of the tags in the Small Index of tags of the second encrypted document; and augment the Large Index of tags for the second encrypted document based, at least in part, on the respective Large Index of tags for the one or more associated documents of the first plurality of unencrypted documents., 4. The non-transitory computer readable medium of claim 3 , wherein the instructions to augment the Large Index of tags for the second encrypted document further comprise instructions to: link the Large Index of tags of at least one of the one or more associated documents with the Large Index of tags of the second unencrypted document., 5. The non-transitory computer readable medium of claim 1 , wherein the Small Index of tags for the second encrypted document comprises a user-customized index of tags., 6. The non-transitory computer readable medium of claim 1 , wherein the instructions to create one or more associations between the second encrypted document and one or more documents of the first plurality of unencrypted documents further comprise instructions to use at least one of the following: a Markovian data model; neural networks; deep learning techniques; and semantic language training techniques., 7. The non-transitory computer readable medium of claim 1 , further comprising instructions to: augment the Small Index of tags for the second encrypted document based, at least in part, on the respective Small Index of tags for the one or more associated documents of the first plurality of unencrypted documents., 8. The non-transitory computer readable medium of claim 1 , wherein the processing device does not have the ability to decrypt the second encrypted document., 9. The non-transitory computer readable medium of claim 1 , wherein the instructions to create one or more associations between the second encrypted document and one or more documents of the first plurality of unencrypted documents further comprise instructions to base the created associations, at least in part, on metadata of the second encrypted document and metadata of the one or more documents of the first plurality of unencrypted documents., 10. The non-transitory computer readable medium of claim 1 , further comprising instructions to: obtain an updated version of the second encrypted document, wherein the updated version of the second encrypted document comprises an updated Small Index of tags based, at least in part, on the updated version of the second encrypted document., 11. A system, comprising: a memory; and one or more processing units, communicatively coupled to the memory, wherein the memory stores instructions to configure the one or more processing units to: obtain a first plurality of unencrypted documents, wherein each document in the first plurality of unencrypted documents comprises: a Small Index of tags based, at least in part, on a content of the respective document; and a Large Index of tags based, at least in part, on a predictive analysis of the tags in the Small Index of the respective document; obtain a second encrypted document, wherein the second encrypted document comprises a Small Index of tags based, at least in part, on a content of the second encrypted document; create one or more associations between the second encrypted document and one or more documents of the first plurality of unencrypted documents based, at least in part, on the Small Index of tags of the second encrypted document and the respective Small Index of tags of the one or more of the first plurality of unencrypted documents; and generate a result set of documents in response to a received query, wherein the result set comprises the second encrypted document., 12. The system of claim 11 , wherein the first plurality of unencrypted documents are each owned by a first user., 13. The system of claim 11 , wherein the memory stores instructions to further configure the one or more processing units to: generate a Large Index of tags for the second encrypted document based, at least in part, on a predictive analysis of the tags in the Small Index of tags of the second encrypted document; and augment the Large Index of tags for the second encrypted document based, at least in part, on the respective Large Index of tags for the one or more associated documents of the first plurality of unencrypted documents., 14. The system of claim 13 , wherein the instructions to augment the Large Index of tags for the second encrypted document further comprise instructions to: link the Large Index of tags of at least one of the one or more associated documents with the Large Index of tags of the second unencrypted document., 15. The system of claim 11 , wherein the Small Index of tags for the second encrypted document comprises a user-customized index of tags., 16. The system of claim 11 , wherein the instructions to create one or more associations between the second encrypted document and one or more documents of the first plurality of unencrypted documents further comprise instructions to use at least one of the following: a Markovian data model; neural networks; deep learning techniques; and semantic language training techniques., 17. The system of claim 11 , wherein the instructions further comprise instructions to cause the one or more processing units to: augment the Small Index of tags for the second encrypted document based, at least in part, on the respective Small Index of tags for the one or more associated documents of the first plurality of unencrypted documents., 18. The system of claim 11 , wherein the system does not have the ability to decrypt the second encrypted document., 19. The system of claim 11 , wherein the instructions to create one or more associations between the second encrypted document and one or more documents of the first plurality of unencrypted documents further comprise instructions to base the created associations, at least in part, on metadata of the second encrypted document and metadata of the one or more documents of the first plurality of unencrypted documents., 20. The system of claim 11 , wherein the instructions further comprise instructions to cause the one or more processing units to: obtain an updated version of the second encrypted document, wherein the updated version of the second encrypted document comprises an updated Small Index of tags based, at least in part, on the updated version of the second encrypted document., 21. A computer-implemented method, comprising: obtaining a first plurality of unencrypted documents, wherein each document in the first plurality of unencrypted documents comprises: a Small Index of tags based, at least in part, on a content of the respective document; and a Large Index of tags based, at least in part, on a predictive analysis of the tags in the Small Index of the respective document; obtaining a second encrypted document, wherein the second encrypted document comprises a Small Index of tags based, at least in part, on a content of the second encrypted document; creating one or more associations between the second encrypted document and one or more documents of the first plurality of unencrypted documents based, at least in part, on the Small Index of tags of the second encrypted document and the respective Small Index of tags of the one or more of the first plurality of unencrypted documents; and generating a result set of documents in response to a received query, wherein the result set comprises the second encrypted document., 22. The method of claim 21 , wherein the first plurality of unencrypted documents are each owned by a first user., 23. The method of claim 21 , further comprising: generating a Large Index of tags for the second encrypted document based, at least in part, on a predictive analysis of the tags in the Small Index of tags of the second encrypted document; and augmenting the Large Index of tags for the second encrypted document based, at least in part, on the respective Large Index of tags for the one or more associated documents of the first plurality of unencrypted documents., 24. The method of claim 23 , wherein augmenting the Large Index of tags for the second encrypted document further comprises linking the Large Index of tags of at least one of the one or more associated documents with the Large Index of tags of the second unencrypted document., 25. The method of claim 21 , further comprising: augmenting the Small Index of tags for the second encrypted document based, at least in part, on the respective Small Index of tags for the one or more associated documents of the first plurality of unencrypted documents.\n",
            "Similarity Score: 0.5816\n",
            "\n",
            "\n",
            "Patent ID: 10606752\n",
            "PubMed Claim: 1. A method for coordinating cache management for an exclusive cache hierarchy, the method comprising: managing, by a coordinated cache logic section, a level three (L3) cache; and managing, by the coordinated cache logic section, a level two (L2) cache, wherein managing the L3 cache and the L2 cache includes coordinating a cache block replacement policy among the L3 cache and the L2 cache by filtering first data having relatively lower reuse probability from second data having relatively higher reuse probability; and tracking reuse patterns of demand requests separately from reuse patterns of prefetch requests., 2. The method of claim 1 , further comprising: inserting a first cache block A into the L2 cache; determining, by the coordinated cache logic section, whether there is a cache hit in the L2 cache; in response to determining that there is the cache hit, determining whether a prefetch bit associated with the first cache block A is asserted; in response to determining that the prefetch bit associated with the first cache block A is asserted, increasing a dead block prediction counter for prefetch requests; in response to determining that the prefetch bit associated with the first cache block A is not asserted, increasing a dead block prediction counter for demand requests; asserting a re-reference bit associated with the first cache block A; and providing the first cache block A to a core processor., 3. The method of claim 1 , further comprising: inserting a first cache block A into the L2 cache; determining, by the coordinated cache logic section, whether there is a cache hit in the L2 cache; in response to determining that there is not the cache hit, determining, by the coordinated cache logic section, whether a cache block replacement is needed; in response to determining that the cache block replacement is not needed, determining, by the coordinated cache logic section, whether a request for the first cache block A is a prefetch request; in response to determining that the request for the first cache block A is the prefetch request: inserting the first cache block A into the L2 cache; deasserting a re-reference bit associated with the first cache block A; and asserting a prefetch bit associated with the first cache block A; in response to determining that the request for the first cache block A is not the prefetch request: inserting the first cache block A into the L2 cache; deasserting the re-reference bit associated with the first cache block A; and deasserting the prefetch bit associated with the first cache block A., 4. A method for coordinating cache management for an exclusive cache hierarchy, the method comprising: managing, by a coordinated cache logic section, a level three (L3) cache; managing, by the coordinated cache logic section, a level two (L2) cache; wherein managing the L3 cache and the L2 cache includes coordinating a cache block replacement policy among the L3 cache and the L2 cache by filtering first data having relatively lower reuse probability from second data having relatively higher reuse probability; inserting a first cache block A into the L2 cache; determining, by the coordinated cache logic section, whether there is a cache hit in the L2 cache; in response to determining that there is not the cache hit, determining, by the coordinated cache logic section, whether a cache block replacement is needed; in response to determining that the cache block replacement is needed, finding a replacement candidate second cache block B; determining, by the coordinated cache logic section, whether a re-reference bit associated with the second cache block B is asserted; in response to determining that the re-reference bit associated with the second cache block B is not asserted, determining, by the coordinated cache logic section, whether a prefetch bit associated with the second cache block B is asserted; and in response to determining that the prefetch bit associated with the second cache block B is asserted, decreasing a dead block prediction counter for prefetch requests., 5. The method of claim 4 , further comprising: determining, by the coordinated cache logic section, whether the dead block prediction counter for prefetch requests is 0; in response to determining that the dead block prediction counter for prefetch requests is 0: marking the second cache block B as non-temporal; sending the second cache block B to the L3 cache; and allocating the second cache block B at a least recently used (LRU) position in the L3 cache., 6. A method for coordinating cache management for an exclusive cache hierarchy, the method comprising: managing, by a coordinated cache logic section, a level three (L3) cache; managing, by the coordinated cache logic section, a level two (L2) cache; wherein managing the L3 cache and the L2 cache includes coordinating a cache block replacement policy among the L3 cache and the L2 cache by filtering first data having relatively lower reuse probability from second data having relatively higher reuse probability; inserting a first cache block A into the L2 cache; determining, by the coordinated cache logic section, whether there is a cache hit in the L2 cache; in response to determining that there is not the cache hit, determining, by the coordinated cache logic section, whether a cache block replacement is needed; in response to determining that the cache block replacement is needed, finding a replacement candidate second cache block B; determining, by the coordinated cache logic section, whether a re-reference bit associated with the second cache block B is asserted; in response to determining that the re-reference bit associated with the second cache block B is not asserted, determining, by the coordinated cache logic section, whether a prefetch bit associated with the second cache block B is asserted; and in response to determining that the prefetch bit associated with the second cache block B is not asserted, decreasing a dead block prediction counter for demand requests., 7. The method of claim 6 , further comprising: determining, by the coordinated cache logic section, whether the dead block prediction counter for demand requests is 0; in response to determining that the dead block prediction counter for demand requests is 0: marking the second cache block B as non-temporal; sending the second cache block B to the L3 cache; and allocating the second cache block B at a least recently used (LRU) position in the L3 cache., 8. The method of claim 6 , further comprising: determining, by the coordinated cache logic section, whether the dead block prediction counter for demand requests is 0; in response to determining that the dead block prediction counter for demand requests is not 0: marking the second cache block B as temporal; sending the second cache block B to the L3 cache; and allocating the second cache block B at a least recently used (LRU)+1 position in the L3 cache., 9. The method of claim 1 , further comprising: inserting a first cache block A into the L2 cache; determining, by the coordinated cache logic section, whether there is a cache hit in the L2 cache; in response to determining that there is not the cache hit, determining, by the coordinated cache logic section, whether a cache block replacement is needed; in response to determining that the cache block replacement is needed, finding a replacement candidate second cache block B; determining, by the coordinated cache logic section, whether a re-reference bit associated with the second cache block B is asserted; in response to determining that the re-reference bit associated with the second cache block B is asserted, determining, by the coordinated cache logic section, whether a prefetch bit associated with the second cache block B is asserted; and in response to determining that the prefetch bit associated with the second cache block B is not asserted, determining, by the coordinated cache logic section, whether a dead block prediction counter for demand requests is 0., 10. The method of claim 1 , further comprising: inserting a first cache block A into the L2 cache; determining, by the coordinated cache logic section, whether there is a cache hit in the L2 cache; in response to determining that there is not the cache hit, determining, by the coordinated cache logic section, whether a cache block replacement is needed; in response to determining that the cache block replacement is needed, finding a replacement candidate second cache block B; determining, by the coordinated cache logic section, whether a re-reference bit associated with the second cache block B is asserted; in response to determining that the re-reference bit associated with the second cache block B is asserted, determining, by the coordinated cache logic section, whether a prefetch bit associated with the second cache block B is asserted; in response to determining that the prefetch bit associated with the second cache block B is asserted, determining, by the coordinated cache logic section, whether a dead block prediction counter for prefetch requests is 0; in response to determining that the dead block prediction counter for prefetch requests is 0: marking the second cache block B as non-temporal; sending the second cache block B to the L3 cache; and allocating the second cache block B at a least recently used (LRU) position in the L3 cache; in response to determining that the dead block prediction counter for prefetch requests is not 0: marking the second cache block B as temporal; sending the second cache block B to the L3 cache; and allocating the second cache block B at a least recently used (LRU)+1 position in the L3 cache., 11. The method of claim 1 , further comprising: inserting a first cache block A into the L2 cache; determining, by the coordinated cache logic section, whether there is a cache hit in the L2 cache; in response to determining that there is not the cache hit, determining, by the coordinated cache logic section, whether a cache block replacement is needed; in response to determining that the cache block replacement is needed, finding a replacement candidate second cache block B; determining, by the coordinated cache logic section, whether a re-reference bit associated with the second cache block B is asserted; in response to determining that the re-reference bit associated with the second cache block B is asserted, determining, by the coordinated cache logic section, whether a prefetch bit associated with the second cache block B is asserted; in response to determining that the prefetch bit associated with the second cache block B is asserted, determining, by the coordinated cache logic section, whether a dead block prediction counter for prefetch requests is 0; in response to determining that the dead block prediction counter for prefetch requests is 0: marking the second cache block B as non-temporal; bypassing the L3 cache; and sending the second cache block B to a main memory; in response to determining that the dead block prediction counter for prefetch requests is not 0: marking the second cache block B as temporal; sending the second cache block B to the L3 cache; and allocating the second cache block B at a least recently used (LRU)+1 position in the L3 cache., 12. The method of claim 1 , further comprising: inserting a first cache block A into the L2 cache; determining, by the coordinated cache logic section, whether there is a cache hit in the L2 cache; in response to determining that there is not the cache hit, determining, by the coordinated cache logic section, whether a cache block replacement is needed; in response to determining that the cache block replacement is needed, finding a replacement candidate second cache block B; determining, by the coordinated cache logic section, whether a re-reference bit associated with the second cache block B is asserted; in response to determining that the re-reference bit associated with the second cache block B is asserted, determining, by the coordinated cache logic section, whether a prefetch bit associated with the second cache block B is asserted; in response to determining that the prefetch bit associated with the second cache block B is asserted, determining, by the coordinated cache logic section, whether a dead block prediction counter for prefetch requests is 0; in response to determining that the dead block prediction counter for prefetch requests is 0, determining, by the coordinated cache logic section, whether an L2 cache replacement policy is biased toward bimodal re-reference interval prediction; in response to determining that the L2 cache replacement policy is biased toward bimodal re-reference interval prediction: marking the second cache block B as non-temporal; sending the second cache block B to the L3 cache; and allocating the second cache block B at a least recently used (LRU) position in the L3 cache; in response to determining that the L2 cache replacement policy is not biased toward bimodal re-reference interval prediction: marking the second cache block B as temporal; sending the second cache block B to the L3 cache; and allocating the second cache block B at a least recently used (LRU)+1 position in the L3 cache., 13. The method of claim 1 , further comprising: inserting a first cache block A into the L2 cache; determining, by the coordinated cache logic section, whether there is a cache hit in the L2 cache; in response to determining that there is not the cache hit, determining, by the coordinated cache logic section, whether a cache block replacement is needed; in response to determining that the cache block replacement is needed, finding a replacement candidate second cache block B; determining, by the coordinated cache logic section, whether a re-reference bit associated with the second cache block B is asserted; in response to determining that the re-reference bit associated with the second cache block B is asserted, determining, by the coordinated cache logic section, whether a prefetch bit associated with the second cache block B is asserted; and in response to determining that the prefetch bit associated with the second cache block B is asserted, determining, by the coordinated cache logic section, whether a dead block prediction counter for prefetch requests is 0., 14. The method of claim 13 , further comprising in response to determining that the dead block prediction counter for prefetch requests is 0, determining, by the coordinated cache logic section, whether an L2 cache replacement policy is biased toward bimodal re-reference interval prediction., 15. The method of claim 14 , further comprising in response to determining that the L2 cache replacement policy is biased toward bimodal re-reference interval prediction: marking the second cache block B as non-temporal; sending the second cache block B to the L3 cache; and allocating the second cache block B at a least recently used (LRU) position in the L3 cache., 16. The method of claim 15 , further comprising in response to determining that the L2 cache replacement policy is not biased toward bimodal re-reference interval prediction: marking the second cache block B as temporal; sending the second cache block B to the L3 cache; and allocating the second cache block B at a least recently used (LRU)+1 position in the L3 cache.\n",
            "Similarity Score: 0.5802\n",
            "\n",
            "\n",
            "Patent ID: 10606882\n",
            "PubMed Claim: 1. A method of estimating remaining capacity of cosmetic product, the method comprising: a) using a body information analysis apparatus to receive a cosmetic product configuration operation to configure a plurality of cosmetic product data and configure a remaining capacity for each of the cosmetic product data, wherein each of the cosmetic product data is corresponding to a cosmetic product; b) receiving a habitual input operation to configure a habitual usage frequency and a habitual single usage amount for one of the cosmetic product data; c) configuring a reference consumption amount of the cosmetic product data based on the habitual single usage amount; d) adjusting the remaining capacity for each of the cosmetic product data based on a usage record of the body information analysis apparatus and the reference consumption amount and the habitual usage frequency of the cosmetic product data, wherein the usage record comprises time or counts of the body information analysis apparatus entering a non-standby mode or time or counts of the body information analysis apparatus entering a standby mode; e) sending a reminder message when the remaining capacity of any of the cosmetic product data is less than a safety capacity; f) receiving a verification feedback operation after sending the reminder message, configuring a verification feedback data based on the verification feedback operation, wherein the verification feedback data indicates whether an actual capacity a corresponding cosmetic product is excessively few; g) receiving a capacity feedback operation when the verification feedback data indicates that the actual capacity corresponding to the cosmetic product is excessively few, and configuring capacity feedback data based on the capacity feedback operation, wherein the capacity feedback data indicates the actual capacity of the corresponding cosmetic product; and h) modifying the remaining capacity of the cosmetic product data based on the capacity feedback data for the cosmetic product., 2. The method in claim 1 , wherein the step a) further comprises: a1) photo-taking an image of any of the cosmetic product by an image fetching unit of the body information analysis apparatus; a2) searching for the cosmetic product data corresponding to the image in a database; a3) receiving a cosmetic product establish operation to establish new cosmetic product data when search fails; a4) adding the searched cosmetic product data into a cosmetic cabinet dataset of a user; a5) obtaining an initial capacity for the cosmetic product data and configuring the initial capacity as the remaining capacity of the cosmetic product data., 3. The method in claim 2 , wherein the database stores a plurality of sample images corresponding to the cosmetic product data, the image is an appearance image of the cosmetic product, wherein in step a2) the cosmetic product data with sample image matched with the appearance image is searched for., 4. The method in claim 2 , wherein the database stores a plurality of identification data corresponding to the cosmetic product data, the image is a barcode image of the cosmetic product, wherein in step a2) the image is analyzed to obtain an input data, the cosmetic product data with identification data matched with the input data is searched for, wherein the input data is a barcode data for the cosmetic product., 5. The method in claim 1 , wherein the step d) comprises: d1) receiving a content selection operation for selecting one of tutor content data, wherein the tutor content data is corresponding to the combination of various cosmetic product data; d2) playing back a selected tutor content data when the method enters a tutor mode; d3) adjusting the remaining capacity of the cosmetic product data based on a tutor reference consumption amount and a tutor accumulation count for the body information analysis apparatus entering the tutor mode or a tutor accumulation time for the body information analysis apparatus entering the tutor mode, wherein the body information analysis apparatus obtains a suggested consumption amount corresponding to each of the cosmetic product data in the playbacked tutor content data and adjusts the remaining capacity in each of the cosmetic product data in the playbacked tutor content data based on the obtained suggested consumption amount for each of the cosmetic product data; d4) updating a cosmetic accumulation count and starting to counting time when the body information analysis apparatus enters a cosmetic mirror mode; d5) stopping to count time and obtain a single usage time when the body information analysis apparatus exits the cosmetic mirror mode; updating a cosmetic accumulation time based on the single usage time; d6) adjusting the remaining capacity of the cosmetic product data based on a cosmetic reference consumption amount and a cosmetic accumulation count for the body information analysis apparatus entering the cosmetic mirror mode or a cosmetic accumulation time for the body information analysis apparatus entering the cosmetic mirror mode, wherein the cosmetic reference consumption amount is less than the tutor reference consumption amount; d7) adjusting the remaining capacity in each of the cosmetic product data based on a default consumption amount of each cosmetic product data when a continual standby time of the body information analysis apparatus reaches a default standby time., 6. The method in claim 1 , further comprising a step i) after the step g) and before the step h): calculating a capacity error based on the capacity feedback data and the remaining capacity of the cosmetic product data; wherein the step h) the remaining capacity of the cosmetic product is modified based on the capacity feedback data of the cosmetic product, and the reference consumption amount is modified based on the capacity error., 7. A body information analysis apparatus, comprising: a display module configured to display a reminder message; an input module configured to receive a cosmetic product configuration operation and to receive a feedback operation when the reminder message is displayed; a memory module configured to store a plurality of cosmetic product data, a safety capacity, a remaining capacity and a reference consumption amount for each of the cosmetic product data, and configured to store a usage record of the body information analysis apparatus, wherein each of the cosmetic product data is corresponding to a cosmetic product, the usage record comprises time or counts of the body information analysis apparatus entering a non-standby mode or time or counts of the body information analysis apparatus entering a standby mode; and a control module electrically connected to the display module, the input module and the memory module and comprising: a configuring module configured to set up a plurality of cosmetic product data based on the cosmetic product configuration operation and set up the remaining capacity of the cosmetic product data; a reference consumption amount setting module configured to receive a habitual input operation through the input module, to set up a habitual usage frequency and a habitual single usage amount for one of the cosmetic product data based on the habitual input operation, and to set up the reference consumption amount in the cosmetic product data as the habitual single usage amount; an updating module configured to adjust the remaining capacity of the cosmetic product data based on usage record and the reference consumption amount and the habitual usage frequency of each cosmetic product data; a monitoring module configured to send the reminder message through the display module when determining that the remaining capacity of any of the cosmetic product data is less than the safety capacity; and a feedback module comprising: a verification module configured to receives a verification feedback operation through the input module after the reminder message is sent, and to set up a capacity feedback data based on the capacity feedback operation, wherein the verification feedback data indicates whether an actual capacity of a corresponding cosmetic product is excessively few; and a capacity feedback module configured to receive a capacity feedback operation through the input module when the verification feedback data indicates excessively little actual capacity, to set up a capacity feedback data based on the capacity feedback operation, wherein the capacity feedback data indicates the actual capacity of the corresponding cosmetic product; wherein the feedback module modifies the remaining capacity of the cosmetic product data based on the capacity feedback data., 8. The body information analysis apparatus in claim 7 , wherein the body information analysis apparatus further comprises an image fetching unit electrically connected to the control module and configured to take an image of any of the cosmetic product, the memory module is further configured to store a cosmetic cabinet dataset comprising cosmetic product data of a plurality of cosmetic products owned by a user, the memory module further comprises a database configured to store a plurality of cosmetic product data corresponding to a plurality of images; the control module further comprising: a searching module configured to search the cosmetic product data corresponding to the image of the photo-taken cosmetic product in the database; and a manual configuration module configured to receive a cosmetic product establish operation through the input module when the searching module fails in searching and sets up a new cosmetic product data based on the cosmetic product establish operation; wherein the configuring module is configured to add the cosmetic product data into the cosmetic cabinet dataset and set an initial capacity of the cosmetic product data as the remaining capacity of the cosmetic product data., 9. The body information analysis apparatus in claim 8 , wherein the database is configured to store a plurality of identification data for the plurality of cosmetic product data, the image fetching unit is configured to take an barcode image for the cosmetic product, the searching module is configured to analyze the barcode image to obtain an input data and search for the cosmetic product data with the identification data matched with the input data, wherein the input data is a barcode data for the cosmetic product., 10. The body information analysis apparatus in claim 7 , wherein the memory module is configured to store a plurality of tutor content data, a tutor reference consumption amount, a suggested consumption amount, a cosmetic reference consumption amount and a default consumption amount for each of the cosmetic product data, a tutor accumulation count or a tutor accumulation time for the body information analysis apparatus entering a tutor mode, a cosmetic accumulation count or a cosmetic accumulation time for the body information analysis apparatus entering a cosmetic mirror mode, and a default standby time, wherein each of the tutor content data is corresponding to corresponding to a combination of various cosmetic product data, wherein the cosmetic reference consumption amount is less than the tutor reference consumption amount; the control module further comprises: a tutor mode execution module configured to receive a content selection operation for one of the plurality of tutor content data through the input module and playback a selected tutor content data by the display module after the body information analysis apparatus enters tutor mode; the tutor mode execution module configured to adjust the remaining capacity in each of the cosmetic product data based on the tutor accumulation count or the tutor accumulation time with the tutor reference consumption amount for each cosmetic product data, wherein the tutor mode execution module is configured to adjust the remaining capacity in each of the cosmetic product data based on the suggested consumption amount in the cosmetic product data of playbacked tutor content data; a cosmetic mirror mode execution module configured to update the cosmetic accumulation count and then start time counting after the body information analysis apparatus enters cosmetic mirror mode, configured to stop time counting when the body information analysis apparatus exits cosmetic mirror mode and then obtain a single usage time, the cosmetic mirror mode execution module configured to update the cosmetic accumulation time based on the single usage time, the cosmetic mirror mode execution module configured to adjust the remaining capacity in each of the cosmetic product data based on the cosmetic reference consumption amount and the cosmetic accumulation count or the cosmetic accumulation time; and a standby mode execution module configured to adjust the remaining capacity in each of the cosmetic product data based on default consumption amount of each cosmetic product data when a continual standby time of the body information analysis apparatus reaches the default standby time., 11. The body information analysis apparatus in claim 7 , wherein the feedback module further comprises: an error calculation module configured to calculate a capacity error based on the capacity feedback data and the remaining capacity of the cosmetic product data, to modify the remaining capacity of the cosmetic product based on the capacity feedback data of the cosmetic product, and to modify the reference consumption amount based on the capacity error.\n",
            "Similarity Score: 0.5796\n",
            "\n",
            "\n",
            "Patent ID: 10606894\n",
            "PubMed Claim: 1. A computer implemented method for cognitively validating semantics of a query, comprising: generating, by one or more processor, a plurality of domain language detection models respectively corresponding to each domain from a plurality of domains, wherein the plurality of domain language detection models include respective hierarchies of classification labels applicable for respective content of each domain; obtaining, by the one or more processor, a query as submitted by a user; selecting, by the one or more processor, a domain language detection model applicable to the query from the plurality of domain language detection models; determining, by the one or more processor, intent of the query by use of the domain language detection model from selecting; formulating, by the one or more processor, a preconfigured number of alternative queries based on one or more classification labels corresponding to the intent of the query from the determining, wherein each of the queries is semantically valid; and producing, by the one or more processor, the alternative queries from the formulating to the user., 2. The computer implemented method of claim 1 , the generating comprising: associating, respectively, words from content of a domain into classification labels, by use of natural language classification tools; and organizing the classifications labels in a hierarchy suitable for the domain., 3. The computer implemented method of claim 1 , the obtaining comprising: receiving the query from a search engine, responsive to sending the query by the search engine as being unsuccessful to generate a search result corresponding to the query., 4. The computer implemented method of claim 1 , the selecting comprising: applying preconfigured domain selection rules selected from: a category of a present page from which the query was submitted, a department of the present page, one or more user-selected tags for narrowing a search result responding to the query, a topic of the query as returned by a high level topic detector, and combinations thereof; and determining one of the plurality of domain language detection model amongst respective domain language detection models corresponding to domains that fit best to the preconfigured domain selection rules as the domain language detection models applicable to the query., 5. The computer implemented method of claim 1 , the determining comprising: generating a plurality of tuples, wherein each tuple includes a classification label from the domain language detection model and a confidence value, wherein the classification label indicates one of intents that may be meant by the query, and wherein the confidence value indicates how probable the query meant the classification label corresponding to the confidence value., 6. The computer implemented method of claim 1 , the formulating comprising: generating a first alternative query from the preconfigured number of alternative queries by use of a first classification label corresponding to the greatest confidence value, and one or more other classification label relevant to the first classification label such that the first alternative query is semantically valid and most likely to mean what the user might have meant by the query., 7. The computer implemented method of claim 1 , the producing further comprising: providing a search result corresponding to one of the preconfigured number of alternative queries in association with the preconfigured number of alternative queries., 8. The computer implemented method of claim 1 , wherein the generating a plurality of domain language detection models respectively corresponding to each domain from a plurality of domains includes generating a plurality of domain language detection models respectively corresponding to each domain from a plurality of domains, wherein different ones of the plurality of domains are differentiated by subject matter., 9. The computer implemented method of claim 1 , wherein the method includes receiving feedback from the user as to the accuracy of the alternative queries, and adjusting a domain language detection model for a certain domain in dependence on the feedback., 10. The computer implemented method of claim 1 , wherein the method includes receiving input from the user in response to the alternative queries, and submitting a query of the alternative queries based on the input., 11. The computer implemented method of claim 1 , wherein the determining the intent of the query by use of the domain language detection model includes selecting hierarchical classification labels of the domain language detection model based on terms of the query., 12. The computer implemented method of claim 1 , wherein a hierarchy of classification labels of the domain language detection model includes (a) a top level having a classification label specifying a general product category, (b) a second level below the top level having classification labels that specify product types within the general product category, and (c) a third level below the second level having classification labels, for a certain product type referenced in the second level, different brands of the certain product type., 13. The computer implemented method of claim 1 , wherein a hierarchy of classification labels of the domain language detection model includes (a) a top level having a classification label specifying a general product category, (b) a second level below the top level having classification labels that specify product types within the general product category, and (c) a third level below the second level having classification labels, for a certain product type referenced in the second level, different brands of the certain product type, wherein the determining the intent of the query by use of the domain language detection model includes selecting hierarchical classification labels of the domain language detection model based on terms of the query, wherein the method includes receiving feedback from the user as to the accuracy of the alternative queries, and adjusting a domain language detection model for a certain domain in dependence on the feedback, wherein the method includes receiving input from the user in response to the alternative queries, and submitting a query of the alternative queries based on the input, wherein the formatting includes generating a first alternative query from the preconfigured number of alternative queries by use of a first classification label corresponding to the greatest confidence value, and one or more other classification label relevant to the first classification label such that the first alternative query is semantically valid and most likely to mean what the user might have meant by the query, wherein the determining comprises generating a plurality of tuples, wherein each tuple includes a classification label from the domain language detection model and a confidence value, wherein the classification label indicates one of intents that may be meant by the query, and wherein the confidence value indicates how probable the query meant the classification label corresponding to the confidence value., 14. A computer program product comprising: a computer readable storage medium readable by one or more processor and storing instructions for execution by the one or more processor for performing a method for cognitively validating semantics of a query, comprising: generating a plurality of domain language detection models respectively corresponding to each domain from a plurality of domains, wherein the plurality of domain language detection models include respective hierarchies of classification labels applicable for respective content of each domain; obtaining a query as submitted by a user; selecting a domain language detection model applicable to the query from the plurality of domain language detection models; determining intent of the query by use of the domain language detection model from selecting; formulating a preconfigured number of alternative queries based on one or more classification labels corresponding to the intent of the query from the determining, wherein each of the queries is semantically valid; and producing the alternative queries from the formulating to the user., 15. The computer program product of claim 14 , the generating comprising: associating, respectively, words from content of a domain into classification labels, by use of natural language classification tools; and organizing the classifications labels in a hierarchy suitable for the domain., 16. The computer program product of claim 14 , the obtaining comprising: receiving the query from a search engine, responsive to sending the query by the search engine as being unsuccessful to generate a search result corresponding to the query., 17. The computer program product of claim 14 , the selecting comprising: applying preconfigured domain selection rules selected from: a category of a present page from which the query was submitted, a department of the present page, one or more user-selected tags for narrowing a search result responding to the query, a topic of the query as returned by a high level topic detector, and combinations thereof; and determining one of the plurality of domain language detection model amongst respective domain language detection models corresponding to domains that fit best to the preconfigured domain selection rules as the domain language detection models applicable to the query., 18. The computer program product of claim 14 , the determining comprising: generating a plurality of tuples, wherein each tuple includes a classification label from the domain language detection model and a confidence value, wherein the classification label indicates one of intents that may be meant by the query, and wherein the confidence value indicates how probable the query meant the classification label corresponding to the confidence value., 19. A system comprising: a memory; one or more processor in communication with the memory; and program instructions executable by the one or more processor via the memory to perform a method for cognitively validating semantics of a query, comprising: generating a plurality of domain language detection models respectively corresponding to each domain from a plurality of domains, wherein the plurality of domain language detection models include respective hierarchies of classification labels applicable for respective content of each domain; obtaining a query as submitted by a user; selecting a domain language detection model applicable to the query from the plurality of domain language detection models; determining intent of the query by use of the domain language detection model from selecting; formulating a preconfigured number of alternative queries based on one or more classification labels corresponding to the intent of the query from the determining, wherein each of the queries is semantically valid; and producing the alternative queries from the formulating to the user., 20. The system of claim 19 , the formulating comprising: generating a first alternative query from the preconfigured number of alternative queries by use of a first classification label corresponding to the greatest confidence value, and one or more other classification label relevant to the first classification label such that the first alternative query is semantically valid and most likely to mean what the user might have meant by the query.\n",
            "Similarity Score: 0.5793\n",
            "\n",
            "\n",
            "Patent ID: 10606968\n",
            "PubMed Claim: 1. A non-transitory computer readable medium having stored thereon a plurality of software code portions defining logic for simulating a temporal process in a body, the logic comprising: providing a first system of node equations, including a first node equation for each of a first plurality of nodes of a uniform grid of nodes imposed on the body, the grid having three independent dimensions and having a uniform node spacing which is within ��10% of 0.27 nanometers, the first node equation for each particular one of the first nodes indicating a field value at the particular node in dependence upon quantities of a moveable particle within a first predetermined neighborhood around the particular node; providing a second system of node equations, including a second node equation for each of a second plurality of nodes in the grid, the second node equation for each subject one of the second nodes indicating a flux of the moveable particles at the subject node in dependence upon the field values within a seconedetermined neighborhood around the subject node, the second plurality of nodes including all of the first plurality of nodes or the first plurality of nodes including all of the second plurality of nodes or both; iterating through a plurality of the time steps to approximate quantities of the moveable particle at each of the nodes in the second plurality of nodes at the end of the plurality of time steps, and at each given time step in the plurality of time steps: approximating a field distribution for the given time step at each of the second plurality of nodes in dependence upon the first node equations and in further dependence upon a distribution of the moveable particles immediately prior to the given time step, and approximating a distribution of the moveable particles for the given time step in dependence upon the second node equations and in further dependence upon the field distribution approximated for the given time step., 2. The computer readable medium of claim 1 , wherein the moveable particles are charged particles, and wherein the field values are electric field values., 3. The computer readable medium of claim 1 , wherein the three independent dimensions are mutually orthogonal., 4. The computer readable medium of claim 1 , wherein approximating a field distribution for the given time step at each of the second plurality of nodes in dependence upon the first node equations comprises solving the first system of node equations as a set of simultaneous equations., 5. The computer readable medium of claim 1 , wherein the second system of node equations includes a system of discrete time probability equations, and wherein approximating a distribution of the moveable particles for the given time step comprises determining a particle quantity change at each of the nodes in the second plurality of nodes randomly in dependence upon the probability equation for that node., 6. The computer readable medium of claim 1 , wherein the second system of node equations includes a system of discrete time continuity equations, at least one of the discrete time continuity equations for each node in the second plurality of nodes, and wherein approximating a distribution of the moveable particles for the given time step comprises solving the system of continuity equations as a set of simultaneous equations., 7. The computer readable medium of claim 1 , wherein the first node equations for each particular one of the first nodes indicates the field value at the particular node in dependence upon quantities of the moveable particle within the first predetermined neighborhood assigned to nodes around the particular node, and wherein the first predetermined neighborhood around the particular node consists of the particular node and all nodes in the first plurality of nodes which in the grid are immediately adjacent to the particular node., 8. The computer readable medium of claim 1 , wherein the second node equation for each subject one of the second nodes indicates the flux of the moveable particles at the subject node in dependence upon the field values assigned to nodes within the second predetermined neighborhood around the subject node, and wherein the second predetermined neighborhood around the subject node consists of the subject node and all nodes in the second plurality of nodes which in the grid are immediately adjacent to the subject node., 9. The computer readable medium of claim 1 , wherein the first and second pluralities of nodes are the same., 10. The computer readable medium of claim 1 , wherein the moveable particles are disposed in the body in a crystal lattice structure whose vertex positions differ from the node positions in the uniform grid, wherein the logic comprises assigning each of the moveable particles to a corresponding node of the second plurality of nodes, wherein each of the first node equations indicates the field value at the particular node in dependence upon quantities of the moveable particle assigned to nodes in the second plurality of nodes which are within the first predetermined neighborhood of the particular node, and wherein approximating a field distribution for the given time step at each of the second plurality of nodes comprises evaluating the first node equations at the particular node in dependence upon the quantity of the moveable particle assigned to each node in the second plurality of nodes which are within the first predetermined neighborhood of the particular node, and further in dependence upon the distance to that node from the particular node., 11. The computer readable medium of claim 1 , wherein the moveable particles are disposed in the body in a crystal lattice structure whose vertex positions differ from the node positions in the uniform grid, wherein the logic comprises assigning each of the moveable particles to a corresponding node of the second plurality of nodes, and storing, in association with each node to which a particle is assigned, an identification of an actual position in the body of the particle assigned to the node, wherein each of the first node equations indicates the field value at the particular node further in dependence upon a distance to each of the moveable particles which are within the first predetermined neighborhood of the particular node, and wherein approximating a field distribution for the given time step at each of the second plurality of nodes comprises: determining, for each particular one of the nodes in the first plurality of nodes, whether the first predetermined neighborhood around the particular node includes a material border in the body; if the first predetermined neighborhood does include a material border, then for a particular one of the moveable particles within the first predetermined neighborhood, evaluating the first node equations at the particular node in dependence upon the actual distance to the particular particle as indicated by the actual position of the particle as stored in association with the node to which the particle is assigned; and if the first predetermined neighborhood does not include a material border, then evaluating the first node equations at the particular node in dependence upon the quantity of the moveable particle assigned to each node in the second plurality of nodes which are within the first predetermined neighborhood of the particular node, and further in dependence upon the distance to that node from the particular node., 12. The computer readable medium of claim 1 , wherein the moveable particles are disposed in the body in a crystal lattice structure whose vertex positions differ from the node positions in the uniform grid, wherein approximating a field distribution comprises assigning field values to nodes of the first plurality of nodes, wherein each of the second node equations indicates the flux of the moveable particles at the subject node in dependence upon the field values assigned to nodes within the second predetermined neighborhood around the subject node, and wherein approximating a distribution of the moveable particles for the given time step comprises evaluating the second node equations at the subject node in dependence upon the field value assigned to each node in the first plurality of nodes which are within the second predetermined neighborhood of the subject node, and further in dependence upon the distance to that node from the subject node., 13. The computer readable medium of claim 1 , wherein the code portions further define logic for reporting to a user values determined for the distribution of the moveable particles at the end of the plurality of time steps., 14. A computer-implemented method for simulating a temporal process in a body, comprising: providing a first system of node equations, including a first node equation for each of a first plurality of nodes of a uniform grid of nodes imposed on the body, the grid having three independent dimensions and having a uniform node spacing which is within ��10% of 0.27 nanometers, the first node equation for each particular one of the first nodes indicating a field value at the particular node in dependence upon quantities of a moveable particle within a first predetermined neighborhood around the particular node; providing a second system of node equations, including a second node equation for each of a second plurality of nodes in the grid, the second node equation for each subject one of the second nodes indicating a flux of the moveable particles at the subject node in dependence upon the field values within a second predetermined neighborhood around the subject node, the second plurality of nodes including al the first plurality of nodes or the first plurality of nodes including all of the second plurality of nodes or both; a computer system iterating through a plurality of the time steps to approximate quantities of the moveable particle at each of the nodes in the second plurality of nodes at the end of the plurality of time steps, and at each given time step in the plurality of time steps: a computer system approximating a field distribution for the given time step at each of the second plurality of nodes in dependence upon the first node equations and in further dependence upon a distribution of the moveable particles immediately prior to the given time step, and a computer system approximating a distribution of the moveable particles for the given time step in dependence upon the second node equations and in further dependence upon the field distribution approximated for the given time step., 15. A non-transitory computer readable medium having stored thereon a plurality of software code portions defining logic for simulating a temporal process in a body portion, the body portion including first particles of a first particle type, the logic comprising: assigning each of the first particles in the body portion to a corresponding one of a plurality of nodes in a uniform grid of nodes imposed on the body portion, the grid having three independent dimensions and having a uniform node spacing which is within ��10% of 0.27 nanometers, the first particles being disposed in a crystal lattice structure having vertices which do not coincide with any nodes of the uniform grid; providing a system of discrete time probability node equations, at least one of the node equations for each of the plurality of nodes of the grid to which a particle is assigned, each of the node equations describing probability of a predetermined physical event type occurring at the respective grid node during a predetermined timeiod, in dependence upon a material property of the particle assigned to the respective grid node, and further in dependence upon a distance to an adjacent particle in the body; and iterating through a first plurality of time steps in a simulation period, at each particular time step re-assigning the first particles in the body portion to nodes in the plurality of nodes in dependence upon the node equations and the particle assignments at the beginning of the particular time step, wherein iterating through the first plurality of time steps comprises, for a given one of the node equations during one of the iterations, approximating the distance to the adjacent particle as the distance between the given node and the grid node to which the adjacent particle is assigned., 16. The non-transitory computer readable medium of claim 15 , wherein each of the assignments of a first particle to a grid node comprises storing, in association with each grid node to which a particle is assigned, an identification of an actual position in the body portion of the particle assigned to the respective grid node, and wherein the logic comprises: determining, for each particular one of the grid nodes to which a particle is assigned, whether the particular node is within a predetermined neighborhood of a material border; if the particular node is within the predetermined neighborhood of a material border, then for the particular node equation, determining the distance to an adjacent particle in dependence upon the actual particle positions as stored in association with the particular node and the node to which the adjacent particle is assigned; and if the particular node is not within the predetermined neighborhood, then for the particular node equation, approximating the distance to the adjacent particle as the distance between the particular grid node and the grid node to which the adjacent particle is assigned., 17. A computer-implemented method for simulating a temporal process in a body portion, the body portion including first particles of a first particle type, comprising: a computer system assigning each of the first particles in the body portion to a corresponding one of a plurality of nodes in a uniform grid of nodes imposed on the body portion, the grid having three independent dimensions and having a uniform node spacing which is within ��10% of 0.27 nanometers, the first particles being disposed in a crystal lattice structure having vertices which do not coincide with any nodes of the uniform grid; providing a system of discrete time probability node equations, at least one of the node equations for each of the plurality of nodes of the grid to which a particle is assigned, each of the node equations describing probability of a predetermined physical event type occurring at the respective grid node during a predetermined time period, in dependence upon a material property of the particle assigned to thepective grid node, and further in dependence upon a distance to an adjacent particle in the body; and a computer system iterating through a first plurality of time steps in a simulation period, at each particular time step re-assigning the first particles in the body portion to nodes in the plurality of nodes in dependence upon the node equations and the particle assignments at the beginning of the particular time step, wherein iterating through the first plurality of time steps comprises, for a given one of the node equations during one of the iterations, approximating the distance to the adjacent particle as the distance between the given node and the grid node to which the adjacent particle is assigned.\n",
            "Similarity Score: 0.5780\n",
            "\n",
            "\n",
            "Patent ID: 10606784\n",
            "PubMed Claim: 1. A method for filtering communications received from a plurality of managed devices of an IHS (Information Handling System) by a remote access controller, the method comprising: configuring a sideband management connection with each of the plurality of managed devices via a first bus connection; receiving, via the first bus connection, PCIe (PCI Express) VDM (Vendor Defined Message) MCTP (Management Component Transport Protocol) messages from the plurality of managed devices; storing the MCTP messages to a circular buffer beginning at a write pointer location; and filtering a first MCTP message at a read pointer location of the circular buffer based on an identification of an organization associated with the managed device associated with the first MCTP message., 2. The method of claim 1 , further comprising: incrementing the write pointer location to the next location in the circular buffer after the stored MCTP messages., 3. The method of claim 1 , further comprising: if messages for the organization associated with the managed device are being processed, copying the PCIe VDM MCTP response message from the circular buffer to a buffer designated for messages from the managed device., 4. The method of claim 3 , further comprising: incrementing the read pointer to the address of the next message in the circular buffer., 5. A remote access controller configured for managing a plurality of devices of an IHS (Information Handling System), the remote access controller comprising: one or more processors; and a memory device coupled to the one or more processors, the memory device storing computer-readable instructions that, upon execution by the one or more processors, cause the system to: configure a first sideband management connection with a first managed device via a primary bus connection; transmit a message to the first managed device via the primary bus, wherein the message is encoded using a first symmetric key; configure a second sideband management connection via a secondary bus connection; and transmit the first symmetric key to the managed device via the secondary bus connection, wherein the first symmetric key is utilized to decode the message., 6. The remote access controller of claim 5 , further comprising: a hardware multiplexer for coupling the remote access controller to the first managed device via the secondary bus connection., 7. The remote access controller of claim 6 , wherein the hardware multiplexer establishes a secondary bus connection with the first managed device, wherein the secondary bus connection cannot be monitorable by any of the plurality of managed devices other than the first managed device., 8. The remote access controller of claim 7 , wherein all of the plurality of managed devices can monitor transmissions on the primary bus connection., 9. The remote access controller of claim 8 , wherein the primary bus connection is a PCIe (PCI Express) VDM (Vendor Defined Message) bus connection., 10. The remote access controller of claim 9 , wherein the secondary bus connection is an I2C bus connection., 11. A system for filtering PCIe (PCI Express) VDM (Vendor Defined Message) MCTP (Management Component Transport Protocol) messages received from a plurality of managed devices, the system comprising: the volatile memory of an IHS (Information Handling System), wherein the volatile memory supports DMA (Direct Memory Access) operations, and wherein the volatile memory comprises a circular buffer; a remote access controller configured to manage the plurality of managed devices of an IHS and further configured to: receive PCIe VDM MCTP messages from the plurality of managed devices; store the received PCIe VDM MCTP messages to a receive FIFO (First-In-First-Out) data structure; transfer, using a DMA operation, the PCIe VDM MCTP messages stored in the receive FIFO to the circular buffer, beginning at a write pointer location of the circular buffer; increment the write pointer location to the next location in the circular buffer after the transferred PCIe VDM MCTP messages; and filter the PCIe VDM MCTP message at a read pointer location in the circular buffer based on identification of the PCIe VDM MCTP message as associated with an organization managing the plurality of managed devices., 12. The system of claim 11 , wherein the remote access controller is further configured to determine the organization of the PCIe VDM MCTP message at the read pointer location based on a vendor identification provided in the PCIe VDM MCTP message., 13. The system of claim 11 , wherein the remote access controller is further configured to copy the filtered PCIe VDM MCTP message from the circular buffer to an endpoint buffer designated for filtered PCIe VDM MCTP messages from the managed device that generated the PCIe VDM MCTP message., 14. The system of claim 13 , wherein the remote access controller is further configured to increment the read pointer location to the address of the next PCIe VDM MCTP message in the circular buffer regardless of whether the MCTP message is filtered and copied to the endpoint buffer., 15. The system of claim 11 , wherein the MCTP messages are received via a PCIe VDM bus connection with the plurality of managed devices., 16. The system of claim 11 , wherein the endpoint buffer is a storage location in the volatile memory of the IHS.\n",
            "Similarity Score: 0.5751\n",
            "\n",
            "\n",
            "Patent ID: 10606873\n",
            "PubMed Claim: 1. A method comprising: prior to receiving, from a user device, a search query of one or more keywords searching for a relevant set of publications in a publication corpus, trimming, with one or more processors, candidate publications from a plurality of candidate publications to generate a trimmed plurality of candidate publications, the trimming based on (i) a machine-learned model of keywords to relevant publications; or (ii) historic user behavior comprising purchases, selections, and/or other interactions; receiving the search query; and in response to the search query, accessing, with the one or more processors, the trimmed plurality of candidate publications in the publication corpus., 2. The method of claim 1 , wherein the trimming is based on a machine learned model., 3. The method of claim 1 , wherein the trimming is based on historic user behavior data., 4. The method of claim 1 , further comprising: for at least one keyword of a plurality of keywords including publication corpus keywords and potential search keywords, aggregating the plurality of candidate publications in the publication corpus., 5. The method of claim 1 , wherein the search query includes any of user profile data, session context data, and non-textual input that includes at least any of audio input, video input, or image input., 6. The method of claim 1 , further comprising: responsive to receiving the search query, processing the trimmed plurality of candidate publications to search for the publication in the publication corpus., 7. The method of claim 6 , further comprising: responsive to the processing the trimmed plurality of candidate publications, causing display of the relevant set of publications at the user device; and after the causing display, receiving a selection signal originating from the user device, the selection signal indicating a selection from the at least one of the one or more closest matches., 8. A system comprising: one or more processors and executable instructions accessible on a computer-readable medium that, when executed by the one or more processors, configure the one or more processors to at least perform operations comprising: prior to receiving, from a user device, a search query of one or more keywords searching for a relevant set of publications in a publication corpus, trimming candidate publications from a plurality of candidate publications to generate a trimmed plurality of candidate publications, the trimming based on (i) a machine-learned model of keywords to relevant publications; or (ii) historic user behavior comprising purchases, selections, and/or other interactions; receiving the search query; and in response to the search query, accessing the trimmed plurality of candidate publications in the publication corpus., 9. The system of claim 8 , wherein the trimming is based on a machine learned model., 10. The system of claim 8 , wherein the trimming is based on historic user behavior data., 11. The system of claim 8 , wherein the operations further comprise: for at least one keyword of a plurality of keywords including publication corpus keywords and potential search keywords, aggregating the plurality of candidate publications in the publication corpus., 12. The system of claim 8 , wherein the search query includes any of user profile data, session context data, and non-textual input that includes at least any of audio input, video input, or image input., 13. The system of claim 8 , wherein the operations further comprise: responsive to receiving the search query, processing the trimmed plurality of candidate publications to search for the publication in the publication corpus., 14. The system of claim 13 , wherein the operations further comprise: responsive to the processing the trimmed plurality of candidate publications, causing display of the relevant set of publications at the user device; and after the causing display, receiving a selection signal originating from the user device, the selection signal indicating a selection from the at least one of the one or more closest matches., 15. A non-transitory machine-readable medium storing instructions that, when executed by one or more processors of a machine, cause the machine to at least perform operations comprising: prior to receiving, from a user device, a search query of one or more keywords searching for a relevant set of publications in a publication corpus, trimming candidate publications from a plurality of candidate publications to generate a trimmed plurality of candidate publications, the trimming based on (i) a machine-learned model of keywords to relevant publications; or (ii) historic user behavior comprising purchases, selections, and/or other interactions; receiving the search query; and in response to the search query, accessing the trimmed plurality of candidate publications in the publication corpus., 16. The non-transitory machine-readable medium of claim 15 , wherein the trimming is based on a machine learned model., 17. The non-transitory machine-readable medium of claim 15 , wherein the trimming is based on historic user behavior data., 18. The non-transitory machine-readable medium of claim 15 , wherein the operations further comprise: for at least one keyword of a plurality of keywords including publication corpus keywords and potential search keywords, aggregating the plurality of candidate publications in the publication corpus., 19. The non-transitory machine-readable medium of claim 15 , wherein the search query includes any of user profile data, session context data, and non-textual input that includes at least any of audio input, video input, or image input., 20. The non-transitory machine-readable medium of claim 15 , wherein the operations further comprise: responsive to receiving the search query, processing the trimmed plurality of candidate publications to search for the publication in the publication corpus.\n",
            "Similarity Score: 0.5750\n",
            "\n",
            "\n",
            "Patent ID: 10606839\n",
            "PubMed Claim: 1. A computer implemented method, the method comprising: receiving, by one or more processors, an asynchronously updated index corresponding to a main dataset in a database system; receiving, by the one or more processors, time-sequenced log data of modifications made to the main dataset after a cutoff time of a last asynchronous index update, wherein the time-sequenced log data is read once by the database system for joining the main dataset with the time-sequenced log data and filtering out updated dataset entries and deleted dataset entries from the asynchronously updated index; receiving, by the one or more processors, from an end user, a proximity-based query directed to the main dataset; joining, by the one or more processors, the main dataset with the time-sequenced log data resulting in a first intermediate result comprising a first one or more entries of the main dataset made after the cutoff time; processing, by the one or more processors, the proximity-based query to determine a second one or more entries satisfying the proximity-based query by emulating a function of the last asynchronous index update resulting in a second intermediate result, wherein the second intermediate result includes updated and deleted entries of a base table that are retrieved by the proximity-based query using an outdated asynchronously updated index, wherein the processing the proximity-based query further comprises receiving a staleness acceptability criterion; and determining, based at least in part on the staleness acceptability criterion, that one or more query results are acceptable; filtering out, by the one or more processors, the updated dataset entries from the asynchronously updated index using the time-sequenced log data to generate a lookup table as index table; processing, by the one or more processors, the proximity-based query against the main dataset using the lookup table resulting in a third intermediate result; and building, by the one or more processors, a union of the second intermediate result and the third intermediate result, to generate a final result of the proximity-based query., 2. The method of claim 1 , wherein the database system is a relational database system., 3. The method of claim 2 , wherein each dataset is a table of the relational database system., 4. The method of claim 1 , wherein the asynchronously updated index is selected from the group consisting of a text search index, and an image index.\n",
            "Similarity Score: 0.5744\n",
            "\n",
            "\n",
            "Patent ID: 10606835\n",
            "PubMed Claim: 1. A method of operating a database management system responsible for processing queries of a relational database which stores data in tables of records, the method comprising: selecting a table to undergo obsolescence control for a period of time, wherein the selection involves specifying: a total number of cycles for which obsolescence control will take place, which is at least three; a duration of each cycle; and a time limit ��M�� specified in terms of a number of cycles, which is at least two but less than the total number of cycles; storing a bitmap cycle counter associated with the table, and a bit mask associated with the table, in a metadata database store; monitoring results of database queries to that table during a first cycle, wherein records that are accessed by a database query are tagged; storing an obsolescence bitmap of records accessed during the first cycle; monitoring results of database queries to that table during a next cycle, wherein records that are accessed by a database queagged; storing a further obsolescence bitmap of records accessed during the next cycle; and repeating the monitoring and storing steps for subsequent cycles so that an obsolescence bitmap is stored for each cycle; wherein: (i) once ��M�� obsolescence bitmaps are available, queries are restricted to records which have been accessed during the last ��M�� cycles by applying the ��M�� most recently stored obsolescence bitmaps, (ii) the bitmap cycle counter counts which obsolescence cycle is current for the table, and (iii) the bit mask validates obsolescence records according to the binary values of , 2. The method of claim 1 , wherein selecting a table to undergo obsolescence control further involves specifying an update phase during each cycle, which will generally be shorter than the cycle duration, and wherein the monitoring of the results of database queries during the first cycle and subsequent cycles is restricted to the update phase of each cycle, so that the obsolescence bitmap of each cycle relates only to records accessed during the update phase of that cycle., 3. The method of claim 1 , wherein, at the end of the obsolescence control period, the obsolescence control for the table is de-selected allowing subsequent queries to access all records of the table., 4. The method of claim 1 , wherein, at the end of the obsolescence control period, the obsolescence control for the table is continued with by rotating the ��M�� most recently stored obsolescence bitmaps to where they would have been had they been generated in the first ��M�� cycles, so that subsequent queries continue to be restricted to records which have been accessed during the la, 5. The method of claim 1 , wherein, during the obsolescence control period, records which can no longer be accessed by queries are moved to higher latency storage., 6. The method of claim 1 , wherein, during the obsolescence control period, records which can no longer be accessed by queries and are hence obsolete are moved into a different table, to create an obsolete table distinct from the selected table which will now only contain records which are still accessible as identified by the most recently stored ��M�� obsolescence bitmaps, and, on conclusion of the obsolescence control period, the obsolete table is merged back into the selecte, 7. The method of claim 1 , wherein, when storing an obsolescence bitmap for a current cycle ��n��, the bitmaps of the ��n?1��th to ��n?M��th cycles are refreshed to untag records that were accessed in those previous cycles but have also been accessed in the current cycle, so that bitmaps of the ��n?1��th to ��n?M��th cycles only tag records that have not been accessed in the current cycle, b, 8. The method of claim 1 , wherein the obsolescence bitmaps are dis-associated from the tables with which they are associated in such a way that modifications to contents of a table during a period when obsolescence control is being applied do not cause modification of its obsolescence bitmaps.\n",
            "Similarity Score: 0.5743\n",
            "\n",
            "\n",
            "Patent ID: 10606978\n",
            "PubMed Claim: 1. A computer-implemented method, comprising: determining, by a system operatively coupled to a processor that executes instructions stored in a memory, that a first defined shape within a shape layout satisfies a layout specification and a second defined shape within the shape layout satisfies a defined rule; coloring, by the system, the shape layout with a plurality of colors in accordance with a defined design rule based on the determining; determining, by the system, respective vertical rectangles of one or more vertical shapes within the shape layout comprise a first width of one that is aligned to a square grid and separated by a space of a second width of at least one; and determining, by the system, respective Z-shapes of one or more Z-shapes within the shape layout occupy five squares and are adjacent to no more than four vertical rectangles., 2. The computer-implemented method of claim 1 , wherein the coloring the shape layout comprises identifying masks for the shape layout., 3. The computer-implemented method of claim 1 , wherein the first defined shape is a vertical rectangle and the second defined shape is a Z-shape., 4. The computer-implemented method of claim 1 , further comprising determining, by the system, at least one of the one or more Z-shapes and at least one of the vertical rectangles are aligned to the square grid and are located apart at a distance greater than or equal to one., 5. The computer-implemented method of claim 1 , wherein two shapes are adjacent based on a determination that a distance between the two shapes is one., 6. The computer-implemented method of claim 3 , wherein the coloring the shape layout comprises: splitting, by the system, the shape layout into columns comprising a width of two; splitting, by the system, a set of available four colors into a first color-pair and a second color-pair; labeling, by the system, odd columns with the first color-pair and even columns with the second color-pair; coloring, by the system, vertical shapes and parts of one or more Z-shapes in the columns from top to bottom; removing, by the system, color from the parts of the one or more Z-shapes; and coloring, by the system, the one or more Z-shapes without creating conflicts with the coloring of the vertical shapes., 7. The computer-implemented method of claim 3 , wherein vertical shapes and parts of one or more Z-shapes are linearly ordered in columns from top to bottom., 8. The computer-implemented method of claim 1 , wherein the plurality of colors comprises four colors.\n",
            "Similarity Score: 0.5740\n",
            "\n",
            "\n",
            "Patent ID: 10606975\n",
            "PubMed Claim: 1. A method for generating physical design layout patterns, comprising steps of: selecting one or more physical design layouts, a given one of the physical design layouts for a given patterned structure comprising a set of physical design layout patterns for features in at least one layer of the given patterned structure; converting the physical design layout patterns into coordinate arrays, a given coordinate array comprising feature center coordinates for the features in a given one of the physical design layout patterns; training, utilizing the coordinate arrays, a generative adversarial network (GAN) comprising a discriminator neural network and a generator neural network; and generating one or more synthetic coordinate arrays utilizing the trained generator neural network of the GAN, a given one of the synthetic coordinate arrays comprising feature center coordinates of features for a new physical design layout pattern; wherein converting the physical design layout patterns into coordinate arrays comprises generating the given coordinate array by populating designated entries of the given coordinate array with center coordinates for one or more features in a given field of view of the given physical design layout represented by the given physical design layout; and wherein the method is performed by at least one processing device comprising a processor coupled to a memory., 2. The method of claim 1 , wherein the features comprise vias of the given patterned structure., 3. The method of claim 1 , wherein the features comprise lines for the given patterned structure., 4. The method of claim 1 , wherein the given coordinate array has a size of M*N, where M is a number of values for representing the center coordinates of respective ones of the features in a designated coordinate system and Nis a maximum number of features in the given field of view of the given physical design layout represented by the given physical design layout pattern., 5. The method of claim 4 , wherein when the given field of view comprises fewer than N features, the given coordinate array is padded with null values outside a range of possible coordinates for the given field of view of the given physical design layout pattern., 6. The method of claim 1 , wherein the features comprise fixed-size rectangular features., 7. The method of claim 6 , wherein the given coordinate array comprises designated entries for coordinates of respective ones of the centers of the fixed-size rectangular features., 8. The method of claim 7 , wherein the coordinates of the centers of the fixed-size rectangular features comprise coordinates in a Cartesian coordinate system, wherein a first designated set of entries of the given coordinate array provide x-coordinates of the centers of the fixed-size rectangular features, and wherein a second designated set of entries of the given coordinate array provide y-coordinates of the centers of the fixed-size rectangular features., 9. The method of claim 1 , wherein the given physical design layout comprises features of at least two different sizes., 10. The method of claim 9 , wherein the coordinates of the centers of the features comprise coordinates in a Cartesian coordinate system, wherein a first designated set of entries of the given coordinate array provide x-coordinates of the centers of features of a first size, wherein a second designated set of entries of the given coordinate array provide y-coordinates of the centers of the features of the first size, wherein a third designated set of entries of the given coordinate array provide x-coordinates of the centers of features of a second size different than the first size, and wherein a fourth designated set of entries of the given coordinate array provide y-coordinates of the centers of the features of the second size., 11. The method of claim 1 , wherein at least one of the discriminator and generator neural networks comprise a series of fully connected neural network layers., 12. The method of claim 1 , further comprising applying post-processing to the generated synthetic coordinate arrays using one or more design rule checks., 13. The method of claim 1 , further comprising converting the generated synthetic coordinate arrays to a format used in an electronic design automation (EDA) software., 14. The method of claim 1 , further comprising utilizing the given synthetic coordinate array to evaluate manufacturability of the new physical design layout pattern., 15. A computer program product, the computer program product comprising a computer readable storage medium having program instructions embodied therewith, the program instructions executable by at least one computing device to cause the at least one computing device to perform steps of: selecting one or more physical design layouts, a given one of the physical design layouts for a given patterned structure comprising a set of physical design layout patterns for features in at least one layer of the given patterned structure; converting the physical design layout patterns into coordinate arrays, a given coordinate array comprising feature center coordinates for the features in a given one of the physical design layout patterns; training, utilizing the coordinate arrays, a generative adversarial network (GAN) comprising a discriminator neural network and a generator neural network; and generating one or more synthetic coordinate arrays utilizing the trained generator neural network of the GAN, a given one of the synthetic coordinate arrays comprising feature center coordinates of features for a new physical design layout pattern; wherein converting the physical design layout patterns into coordinate arrays comprises generating the given coordinate array by populating designated entries of the given coordinate array with center coordinates for one or more features in a given field of view of the given physical design layout represented by the given physical design layout., 16. The computer program product of claim 15 , wherein the given coordinate array has a size of M*N, where M is a number of values for representing the center coordinates of respective ones of the features in a designated coordinate system and N is a maximum number of features in the given field of view of the given physical design layout represented by the given physical design layout pattern., 17. The computer program product of claim 15 , wherein the program instructions further cause the at least one computing device to perform the step of utilizing the given synthetic coordinate array to evaluate manufacturability of the new physical design layout pattern., 18. An apparatus comprising: a memory; and at least one processor coupled to the memory and configured for: selecting one or more physical design layouts, a given one of the physical design layouts for a given patterned structure comprising a set of physical design layout patterns for features in at least one layer of the given patterned structure; converting the physical design layout patterns into coordinate arrays, a given coordinate array comprising feature center coordinates for the features in a given one of the physical design layout patterns; training, utilizing the coordinate arrays, a generative adversarial network (GAN) comprising a discriminator neural network and a generator neural network; and generating one or more synthetic coordinate arrays utilizing the trained generator neural network of the GAN, a given one of the synthetic coordinate arrays comprising feature center coordinates of features for a new physical design layout pattern; wherein converting the physical design layout patterns into coordinate arrays comprises generating the given coordinate array by populating designated entries of the given coordinate array with center coordinates for one or more features in a given field of view of the given physical design layout represented by the given physical design layout., 19. The apparatus of claim 18 , wherein the given coordinate array has a size of M*N, where M is a number of values for representing the center coordinates of respective ones of the features in a designated coordinate system and Nis a maximum number of features in the given field of view of the given physical design layout represented by the given physical design layout pattern., 20. The apparatus of claim 18 , wherein the at least one processor is further configured for utilizing the given synthetic coordinate array to evaluate manufacturability of the new physical design layout pattern.\n",
            "Similarity Score: 0.5739\n",
            "\n",
            "\n",
            "Patent ID: 10606948\n",
            "PubMed Claim: 1. A method of operating a user interface for a first system and a second system of a vehicle, the method comprising: receiving, by a processor, a command variable; identifying, by the processor, a first command and a second command from the received command variable, the first command including the command variable and configured for controlling the first system, the second command including the command variable and configured for controlling the second system; determining, by the processor, a current condition of the vehicle; filtering, by the processor, the identified first and second commands, including filtering out one of the identified first and second commands that are nonapplicable for the determined current condition of the vehicle, and including determining a predicted user command is the other of the first and second commands and is applicable for the determined current condition of the vehicle; outputting, by an output device of the user interface, the predicted user command for selection by a user; receiving, by an input device, a user selection of the predicted user command output by the output device; controlling, by a controller, at least one of the first system and the second system of the vehicle according to the user selection; wherein receiving the command variable includes receiving an initial user input and a subsequent user input that adds to the initial user input; and wherein identifying the first command and the second command includes identifying a command that includes the initial user input and subsequently identifying the command that includes both the initial user input and the subsequent user input., 2. The method of claim 1 , wherein the vehicle is an aircraft; and wherein determining the current condition includes determining a current flight phase of the aircraft; further comprising determining the predicted user command is the other of the first and second commands and is applicable to the determined current flight phase., 3. The method of claim 1 , wherein determining the predicted user command includes determining those of the identified first and second commands that satisfy a vehicle specific criteria; and wherein determining the predicted user command includes determining the predicted user command is the other of the first and second commands and satisfies the vehicle specific criteria., 4. The method of claim 1 , further comprising receiving, from an input device, a user input; further comprising determining, by the processor, that the user input is a shortcut input; and processing, by the processor, the shortcut input to generate the command variable., 5. The method of claim 1 , wherein determining the predicted user command includes determining a plurality of predicted user commands; and further comprising limiting a number of the plurality of predicted user commands simultaneously output by the output device., 6. The method of claim 1 , wherein receiving the command variable includes receiving a text-based command variable input from the input device., 7. A user interface system for controlling a first system and a second system a vehicle, the user interface comprising: an input device; a command database having a first command configured for controlling the first system of the vehicle and having a second command configured for controlling the second system of the vehicle; a sensor configured to sense a current condition of the vehicle; a controller with a processor that is configured to receive a command variable that is input via the input device, the processor configured to identify the first command and the second command from the received command variable, the first command incorporating the command variable and configured for controlling the first system, the second command incorporating the command variable and configured for controlling the second system, the processor configured to filter out one of the identified first and second commands that are nonapplicable for the current condition of the vehicle sensed by the sensor, the processor configured to determine a predicted user command is the other of the identified first and second commands and is applicable for the current condition of the vehicle sensed by the sensor; an output device configured to output the predicted user command for selection by a user; the input device being configured to receive a user selection of the predicted user command; the controller configured to control at least one of the first system and the second system according to the user selection; wherein the processor is configured to receive the command variable as an initial user input and a subsequent user input that adds to the initial user input; and wherein the processor is configured to identify the first command and the second command by identifying a command that includes the initial user input and subsequently identifying the command that includes both the initial user input and the subsequent user input., 8. The user interface system of claim 7 , wherein the vehicle is an aircraft; and the sensor is configured to sense a current flight phase of the aircraft; wherein the processor is configured to determine the predicted user command is the other of the first and second commands and is applicable to the sensed current flight phase., 9. The user interface system of claim 7 , wherein the processor is configured to determine the predicted user command by determining those of the identified first and second commands that satisfy a vehicle-specific criteria; and wherein the processor is configured to determine the predicted user command is the other of the first and second commands and satisfies the vehicle-specific criteria., 10. The user interface system of claim 7 , wherein the input device is configured to receive a user input; wherein the processor is configured to determine that the user input is a shortcut input; and wherein the processor is configured to process the shortcut input to generate the command variable., 11. The user interface system of claim 7 , wherein the processor is configured to determine a plurality of predicted user commands; and wherein the processor is configured to limit a number of the plurality of predicted user commands simultaneously output by the output device., 12. The user interface system of claim 7 , wherein the command variable is a text-based command variable input from the input device.\n",
            "Similarity Score: 0.5735\n",
            "\n",
            "\n",
            "Patent ID: 10606897\n",
            "PubMed Claim: 1. A computer-implemented process performed by a processor in a computer, comprising: receiving an initial search query string into memory of the computer; presenting the initial search query string to sources of items comprising applications executing on the computer, the items comprising computer-readable data, wherein the data items are identified by and accessible by the computer from the sources using name strings of the data items, respectively; receiving into the memory, suggestion strings from the sources in response to presenting the initial query, wherein name strings for data items provided by the sources are determined to match the initial search query string, wherein the sources generate the name strings based on query results including name strings for the data items that match the initial search query string, and wherein the received name strings respectively correspond to the data items matching the initial search query string; computing, by the computer, a suggestion score for each of the received suggestion strings as a weighted combination of features, wherein a weight is assigned to each feature, and each feature is related to a nature of a match between the initial search query string and the data item resulting in the suggestion string, wherein the sources are assigned respective sets of weights to be applied to a set of features for the suggestion strings from the respective sources, and wherein at least a first source has different weightings for those features than a second source; combining the received suggestion strings into a list of suggestion strings in the memory, according to the computed scores for the suggestion strings, including: generating source scores for the respective sources based on the scores for the suggestion strings from the respective sources, grouping the suggestion strings into suggestion groups corresponding to their respective sources, ranking the suggestion strings within each suggestion group by the corresponding suggestion scores, and ordering the suggestion groups relative to each other according to the source scores of the corresponding sources; presenting the ordered and ranked list of suggestion strings on an output device, wherein the suggestion groups are presented as ordered relative to each other, and wherein the suggestion strings within each suggestion group are presented in order relative to each other according to the suggestion scores within the suggestion group; receiving an indication of an interactively selected suggestion string from among the presented suggestion strings, wherein the selected suggestion string corresponds to a data item matching the initial query string; and in response to receiving the indication of the selected suggestion, accessing the corresponding data item., 2. The computer-implemented process of claim 1 , wherein at least one of the sources comprises a file system of a computer, and wherein the name strings include file names of files matching the initial search query string., 3. The computer-implemented process of claim 1 , wherein at least one of the sources comprises a search tool for a file system of an operating system on the computer and at least one of the sources comprises a search engine accessed by the computer over a computer network., 4. The computer-implemented process of claim 1 , wherein at least one of the sources generates suggestion strings based on an aggregated history of prior query strings submitted to the sources., 5. The computer-implemented process of claim 1 , wherein the list of suggestion strings is stored on the computer in a history of lists of suggestion strings., 6. The computer-implemented process of claim 1 , wherein data representing the indication of the selected suggestion string is stored on the computer in a history selected suggestion strings., 7. The computer-implemented process of claim 1 , wherein data representing the list of suggestion strings and data representing the indication of the selected suggestion string are transmitted to another computer over a computer network for aggregation and storage with data from other computers connected to the computer network., 8. An article of manufacture, the article of manufacture not comprising a signal, the article of manufacture comprising: a memory device or a storage device, neither comprising a signal; computer program instructions stored on the memory device or the storage device which, when processed by a processing device, instruct the processing device to perform a process comprising: receiving an initial search query string into memory; sending the initial search query string to applications executed by the processing device, the applications providing data items stored on the memory device or the storage device, the data items comprising computer-readable data, wherein each data item is identified by and accessible by the processing device from the applications using a name string for the data item; receiving, into the memory, suggestion name strings from the applications in response to the initial query string, the suggestion names strings corresponding to data items from the applications matching the initial search query string, wherein the applications generate the suggestion name strings based on query results for the data items that match the initial search query string, and wherein the received resource suggestion name strings correspond to the data items from the applications matching the initial search query string; computing data item scores for the respective suggestion name strings as weighted combinations of features, wherein a weight is assigned to each feature, and each feature is related to a nature of a match between the initial search query string and the data item resulting in the suggestion, wherein each of the applications is assigned a respective set of weights to be applied to features for the suggestion name strings for that source, and wherein at least a first application has different features and different weightings for those features than a second application; combining the received suggestion name strings into a list in memory, wherein the combining is performed according to the computed data item scores, the combining including: generating order scores the respective applications based on the data item scores, each application having a respective order score, grouping the suggestion name strings into suggestion groups by application, ranking the suggestion name strings within each suggestion group by the corresponding data item scores, and ordering the suggestion groups according to the order scores of the corresponding applications; displaying the ranked and ordered list on an a display, wherein the suggestion groups are presented in order according to the order scores, and wherein the suggestion name strings within each group are displayed in order according to the corresponding ranking within the suggestion group; receiving an indication of a selected suggestion name string from among the displayed suggestion name strings, wherein the selected suggestion name string corresponds to a data item matching the initial query; and in response to receiving the indication of the selected suggestion name string, accessing the data item corresponding to the selected suggestion name string., 9. The article of manufacture of claim 8 , wherein the combining further comprises removing duplicate suggestion name strings., 10. The article of manufacture of claim 8 , wherein at least one of the applications comprises a search tool for a file system of an operating system., 11. The article of manufacture of claim 10 , wherein another of the applications comprises a history that generates suggestion name strings based on data related to prior queries submitted to the applications., 12. The article of manufacture of claim 8 , wherein at least one of the applications comprises a file system of a computer, and wherein the received suggestion name strings include file names of files matching the initial search query string., 13. The article of manufacture of claim 8 , wherein the list is stored in a history of lists of suggestion name strings., 14. The article of manufacture of claim 8 , wherein data representing the indication of the selected suggestion name string is stored in a history of selected suggestion name strings., 15. A computing device comprising: processing hardware; a display; a user input device; storage hardware storing information configured to, when executed by the processing hardware, cause the computing device to perform a process, the process comprising: executing a first application, the first application configured to provide first objects in the storage hardware to applications executing on the computing device, the first application further configured to provide access to the first objects based on requests comprising names of the first objects, respectively; executing a second application, the second application configured to provide second objects in the storage hardware to applications executing on the computing device, the second application further configured to provide access to the second objects based on requests comprising names of the second objects, respectively; receiving a query string inputted from the user input device and displayed on the display, and based thereon: sending the query string to the first application and receiving in return corresponding first names returned by the first application; sending the query string to the second application and receiving in return corresponding second names returned by the first application; generating first scores for the respective first names in the first set by applying a scoring function to thereto, and ordering the first names according to the first scores; generating second scores for the respective second names in the first set by applying a scoring function to thereto, and ordering the second names according to the first scores; ranking the first application and the second application relative to each other; displaying the ordered first names adjacent to each other and the ordered second names adjacent to each other, wherein the ordered first names and ordered second names are displayed relative to each other according to the ranking of the first and second applications, and wherein the first names and second names are displayed with respective icons identifying types of objects represented by the first names and second names; and wherein a displayed first name or second name is selected with the user input device and provided to the corresponding first or second application, which in turn provides access to a corresponding first or second object., 16. A computing device according to claim 15 , wherein the ranking the first application relative to the second application is based on features of the first names and features of the second names., 17. A computing device according to claim 15 , wherein the process is performed by a search application executing on the computing device.\n",
            "Similarity Score: 0.5735\n",
            "\n",
            "\n",
            "Patent ID: 10606771\n",
            "PubMed Claim: 1. A stack protection circuitry configured to protect a stack, wherein the stack comprises a range of memory locations, wherein the stack includes a memory location storing a current topmost return address location corresponding to a return address for a most recently executed subroutine, the stack protection circuitry comprising: a memory configured to store a first identifier for the current topmost return address location and a first stack frame size; interface circuitry configured to receive a return instruction from a central processing unit (CPU), wherein the return instruction includes a second stack frame size; and computation circuitry configured to, in response to the return instruction: generate protection data based on the first stack frame size and the first identifier that i) identifies a new topmost return address location that is below the current topmost return address location and ii) specifies read only access for the new topmost return address location; store a second identifier for the new topmost return address location in place of the first identifier in the memory; and store the second stack frame size in place of the first stack frame size in the memory, wherein the interface circuitry is configured to provide the protection data to a memory protection unit to cause the memory protection unit to enforce a read only access restriction on the new topmost return address location., 2. The stack protection circuitry of claim 1 , wherein: the interface circuitry is further configured to receive, from the CPU, a call instruction that identifies a subsequent protected topmost return address location; and the computation circuitry is configured to, in response to the call instruction, generate protection data that identifies the subsequent protected topmost return address location; and wherein the interface circuitry is configured to provide the protection data to the memory protection unit to cause the memory protection unit to enforce a read only access restriction on the subsequent topmost return address location., 3. The stack protection circuitry of claim 1 , wherein: the interface circuitry is further configured to receive, from the central processing unit (CPU), a call instruction that includes a third identifier for a subsequent topmost return address location and a third stack frame size; and the computation circuitry is configured to, in response to the call instruction: generate protection data based on the third identifier; and update the memory to store the third stack frame size in place of the second stack frame size; and wherein the interface circuitry is configured to provide the protection data to the memory protection unit to cause the memory protection unit to enforce a read only access restriction on the subsequent topmost return address location., 4. The stack protection circuitry of claim 1 , wherein the interface circuitry is configured to store the protection data in special function registers in the memory protection unit., 5. The stack protection circuitry of claim 1 , further comprising the memory protection unit and a trap system, wherein the memory protection unit is configured to communicate an access violation to the trap system in response to an attempt to write access the new topmost return address location., 6. The stack protection circuitry of claim 5 , wherein the trap system is configured to generate a high priority interrupt for the CPU in response to receiving the access violation from the memory protection unit., 7. A method configured to protect a stack, wherein the stack comprises a range of memory locations, wherein the stack includes a memory location storing a current topmost return address location corresponding to a return address for a most recently executed subroutine, comprising: receiving a return instruction from a central processing unit (CPU), wherein the return instruction includes a second stack frame size; and in response to receiving the return instruction: generating protection data based on a first stack frame size and a first identifier for the current topmost return address location, wherein the protection data i) identifies a new topmost return address location that is below the current topmost return address location and ii) specifies read only access for the new topmost return address location; storing a second identifier for the new topmost return address location in place of the first identifier in a memory; and storing the second stack frame size in place of the first stack frame size in the memory; and providing the protection data to a memory protection unit to cause the memory protection unit to enforce a read only access restriction on the new topmost return address location., 8. The method of claim 7 , further comprising: receiving, from the CPU, a call instruction that identifies a subsequent protected topmost return address location; and in response to receiving the call instruction, generating protection data that identifies the subsequent protected topmost return address location; and providing the protection data to the memory protection unit to cause the memory protection unit to enforce a read only access restriction on the subsequent topmost return address location., 9. The method of claim 7 , further comprising: receiving, from the CPU, a call instruction that includes a third identifier for a subsequent topmost return address location and a third stack frame size; and in response to the call instruction: generating protection data based on the third identifier; updating the memory to store the third stack frame size in place of the second stack frame size; and providing the protection data to the memory protection unit to cause the memory protection unit to enforce a read only access restriction on the subsequent topmost return address location., 10. The method of claim 7 , further comprising storing the protection data in special function registers in the memory protection unit., 11. The method of claim 7 , further comprising: detecting an attempt to write access the new topmost return address location; and in response to the detecting, communicating an access violation to a trap system., 12. The method of claim 11 , further comprising, with the trap system, generating a high priority interrupt for the CPU in response to the access violation., 13. A stack protection system configured to protect a stack, wherein the stack comprises a range of memory locations, wherein the stack includes a memory location storing a current topmost return address location corresponding to a return address for a most recently executed subroutine, the stack protection system comprising: a trap system configured to generate an interrupt for a CPU in response to receiving a triggering input; a memory protection unit configured to: enforce a read only access limitation on a memory location; and provide a triggering input to the trap system in response to detecting an attempt to write to the memory location; stack protection circuitry, comprising: interface circuitry configured to receive a return instruction from a central processing unit (CPU); and computation circuitry configured to, in response to the return instruction, generate protection data that i) identifies a new topmost return address location that is below the current protected topmost return address location and ii) specifies read only access for the new topmost return address location; and wherein the interface circuitry is configured to provide the protection data to the memory protection unit to cause the memory protection unit to enforce a read only access restriction on the new topmost return address location., 14. The stack protection system of claim 13 , wherein the trap system is configured to generate a high priority interrupt for the CPU., 15. A method configured to protect a stack, wherein the stack comprises a range of memory locations, wherein the stack includes a memory location storing a current topmost return address location corresponding to a return address for a most recently executed subroutine, the method comprising: receiving a return instruction from a central processing unit (CPU); and in response to the return instruction, generating protection data that i) identifies a new topmost return address location that is below the current topmost return address location and ii) specifies read only access for the new topmost return address location; and providing the protection data to a memory protection unit to cause the memory protection unit to enforce a read only access restriction on the new topmost return address location; in response to an attempt to write to the new topmost return address location: generating, with the memory protection unit, a signal indicative of an access violation; providing the signal to a trap system configured to generate an interrupt for a CPU in response to receiving signal., 16. The method of claim 15 , further comprising generating a high priority interrupt for the CPU.\n",
            "Similarity Score: 0.5724\n",
            "\n",
            "\n",
            "Patent ID: 10606744\n",
            "PubMed Claim: 1. A method for accessing a flash memory module, comprising: building a plurality of physical block recording tables respectively corresponding to a plurality of logical address to physical address (L2P) mapping tables, wherein each physical block recording table records at least one block whose physical address is recorded in the corresponding L2P mapping table; and when a specific block within the flash memory module is under a garbage collection operation, for a data page of the specific block whose logical address is within a specific L2P mapping table of the plurality of L2P tables, referring to the corresponding physical block recording table to determine whether to read the specific L2P mapping table from the flash memory module, for determining the data page to be valid or invalid., 2. The method of claim 1 , wherein the step of referring to the physical block recording table to determine whether to read the specific L2P mapping table from the flash memory module, for determining the data page to be valid or invalid comprises: when the physical block recording table indicates that the specific L2P mapping table has a physical address of the specific block, reading the specific L2P mapping table from the flash memory module and determining the data page to be valid or invalid based on the specific L2P mapping table; and when the physical block recording table indicates that the specific L2P mapping table does not have the physical address of the specific block, determining the data page to be invalid., 3. The method of claim 2 , wherein the step of determining the data page to be invalid when the physical block recording table indicates that the specific L2P mapping table does not have the physical address of the specific block comprises: when the physical block recording table indicates that the L2P mapping table does not have the physical address of the specific block, directly determining the data page to be invalid without reading the specific L2P mapping table from the flash memory module., 4. The method of claim 1 , wherein the physical block recording tables is stored in a memory of a flash memory controller, and when the flash memory controller updates at least a portion of the L2P mapping tables, at least a portion of the physical block recording tables is updated in accordance with the updated contents of the L2P mapping table(s)., 5. The method of claim 1 , wherein each of the physical block recording tables records status of a plurality of blocks in the flash memory module, and the status of each block records whether the corresponding L2P mapping table has a physical address of any data page in the specific block., 6. The method of claim 5 , wherein the specific block comprises a plurality of pages; the status of each block is represented by a bit, and the two digit values of the bit are utilized to represent whether the corresponding L2P mapping table has a physical address of any data page in the specific block., 7. The method of claim 1 , wherein each of the physical block recording tables records status of a plurality of block groups in the flash memory module, each block group comprises a plurality of blocks, and the status of each block group records whether the corresponding L2P mapping table has a physical address of any data page of a block in the block group., 8. The method of claim 7 , wherein each of the blocks within the block group comprises a plurality of pages; the status of each block group is represented by a bit, and the two digit values of the bit are utilized to represent whether the corresponding L2P mapping table has a physical address of any data page of a block in the block group., 9. A flash memory controller, wherein the flash memory controller is utilized to access a flash memory module, and the flash memory controller comprises: a read-only memory (ROM), for storing a code; a microprocessor, for executing the code to control access to the flash memory module; and a memory, for storing a plurality of physical block recording tables respectively corresponding to a plurality of L2P mapping tables, wherein each physical block recording table records at least one block whose physical address is recorded in the corresponding L2P mapping table; wherein when a specific block within the flash memory module is under a garbage collection operation, for a data page of the specific block whose logical address is within a specific L2P mapping table of the plurality of L2P tables, referring to the corresponding physical block recording table to determine whether to read the specific L2P mapping table from the flash memory module, for determining the data page to be valid or invalid., 10. The flash memory controller of claim 9 , wherein when the physical block recording table indicates that the L2P mapping table has a physical address of the specific block, the microprocessor reads the specific L2P mapping table from the flash memory module and determines the data page to be valid or invalid based on the specific L2P mapping table; and when the physical block recording table indicates that the specific L2P mapping table does not have the physical address of the specific block, the microprocessor determines the data page to be invalid., 11. The flash memory controller of claim 10 , wherein when the physical block recording table indicates that the specific L2P mapping table does not have the physical address of the specific block, the microprocessor directly determines the data page to be invalid without reading the specific L2P mapping table from the flash memory module., 12. The flash memory controller of claim 9 , wherein when the microprocessor updates at least a portion of the L2P mapping tables, at least a portion of the physical block recording tables is updated in accordance with the updated contents of the L2P mapping table together(s)., 13. The flash memory controller of claim 9 , wherein each of the physical block recording tables records status of a plurality of blocks in the flash memory module, and the status of each block records whether the corresponding L2P mapping table has a physical address of any data page in the specific block., 14. The flash memory controller of claim 13 , wherein the specific block comprises a plurality of pages; the status of each block is represented by a bit, and the two digit values of the bit are utilized to represent whether the corresponding L2P mapping table has a physical address of any data page in the specific block., 15. The flash memory controller of claim 9 , wherein each of the physical block recording tables records status of a plurality of block groups in the flash memory module, each block group comprises a plurality of blocks, and the status of each block group records whether the corresponding L2P mapping table has a physical address of any data page of a block in the block group., 16. The flash memory controller of claim 15 , wherein each of the blocks within the block group comprises a plurality of pages; the status of each block group is represented by a bit, and the two digit values of the bit are utilized to represent whether the corresponding L2P mapping table has a physical address of any data page of a block in the block group., 17. An electronic device comprising: a flash memory module; and a flash memory controller, for accessing the flash memory module; wherein the flash memory controller builds a plurality of physical block recording tables respectively corresponding to a plurality of L2P mapping tables, wherein each physical block recording table records at least one block whose physical address is recorded in the corresponding L2P mapping table; and when a specific block within the flash memory module is under a garbage collection operation, for a data page of the specific block whose logical address is within a specific L2P mapping table, referring to the corresponding physical block recording table to determine whether to read the specific L2P mapping table from the flash memory module, for determining the data page to be valid or invalid., 18. The electronic device of claim 17 , wherein when the physical block recording table indicates that the L2P mapping table has a physical address of the specific block, the flash memory controller reads the specific L2P mapping table from the flash memory module and determines the data page to be valid or invalid based on the specific L2P mapping table; and when the physical block recording table indicates that the specific L2P mapping table does not have the physical address of the specific block, the flash memory controller directly determines the data page to be invalid without reading the specific L2P mapping table from the flash memory module.\n",
            "Similarity Score: 0.5722\n",
            "\n",
            "\n",
            "Patent ID: 10606748\n",
            "PubMed Claim: 1. An information processing apparatus that uses a socket object as a communication interface, the information processing apparatus comprising: at least one processor; and at least one memory that stores a program to be executed by the processor and that has a first memory region and a second memory region, wherein the processor is configured to execute the program and thereby cause the information processing apparatus to function as: a promote unit that transfer generated objects from the first memory region to the second memory region; a socket management unit that manages the number of generated socket objects of socket objects that have been generated; and a release unit that executes garbage collection if the number of generated socket objects is equal to or larger than a predetermined value, so as to close a socket object that has been generated and thereby release a resource for that socket object, wherein the release unit performs the garbage collection for the first memory region when the number of generated socket objects exceeds the predetermined value, and then performs the garbage collection for the second memory region regardless of whether or not there is free memory after performing the garbage collection for the first memory region., 2. The information processing apparatus according to claim 1 , wherein the socket management unit and the release unit are included in a virtual machine that is executed by the information processing apparatus, and the socket object is generated for an application that is executed on the virtual machine., 3. A resource management method to be performed by an information processing apparatus that uses a socket object as a communication interface and that has at least one memory including a first memory region and a second memory region, the method comprising: transferring generated objects from the first memory region to the second memory region; managing the number of generated socket objects of socket objects that have been generated; and executing garbage collection if the number of generated socket objects is equal to or larger than a predetermined value, so as to close a socket object that has been generated and thereby release a resource for that socket object, wherein the garbage collection for the first memory region is performed when the number of generated socket objects exceeds the predetermined value, and then the garbage collection for the second memory region is performed regardless of whether or not there is free memory after performing the garbage collection for the first memory region., 4. A non-transitory computer-readable medium storing a program configured to cause a computer to execute an information processing method, the computer using a socket object as a communication interface and having at least one memory including a first memory region and a second memory region, the method comprising: a promote step of transferring generated objects from the first memory region to the second memory region; a socket management step of managing the number of generated socket objects of socket objects that have been generated; and a release step of executing garbage collection if the number of generated socket objects is equal to or larger than a predetermined value, so as to close a socket object that has been generated and thereby release a resource for that socket object, wherein the garbage collection for the first memory region is performed when the number of generated socket objects exceeds the predetermined value, and then the garbage collection for the second memory region is performed regardless of whether or not there is free memory after performing the garbage collection for the first memory region.\n",
            "Similarity Score: 0.5721\n",
            "\n",
            "\n",
            "Patent ID: 10606945\n",
            "PubMed Claim: 1. A computer implemented method for identifying one or more definitions for a distinguished natural language term, the method comprising: identifying, by a computing system, among entries of a first table of an electronic database, each representing a natural language term, a first entry representing the distinguished natural language term; identifying, by the computing system, among entries of a second table of the electronic database, each representing a correspondence between a term and a definition defining the term, one or more second entries related to the first entry; for each particular second entry of the identified second entries, identifying, by the computing system, among entries of a third table of the electronic database, each representing a definition, a third entry related to the particular second entry, the third table being distinct from the second table; for each of the identified entries of the third table, accessing, by the computing system in the identified entry of the third table a natural language representation of the definition represented by the entry of the third table; and attributing, by the computing system writing to the electronic database, the accessed definition natural language representations to the distinguished natural language term., 2. The computer implemented method of claim 1 further comprising: in relation to a distinguished one of the identified entries of the third table, identifying an entry of a fourth table corresponding to the distinguished entry of the third table, wherein the identified entry of the fourth table represents a word type corresponding to the definition represented in the distinguished entry of the third table, and wherein the word type specifies a part of speech for which a word is being used when it has the definition represented in the distinguished entry of the third table., 3. The computer implemented method of claim 1 further comprising: identifying a fourth entry, from among entries of a fourth table, corresponding to both the first entry of the first table and a fifth entry of the first table, wherein the identified fourth entry defines a hierarchical relationship between the distinguished natural language term of the first entry and another natural language term of the fifth entry., 4. The computer implemented method of claim 3 , wherein the identified fourth entry includes a field defining a type of the hierarchical relationship., 5. The computer implemented method of claim 4 , wherein the type of the hierarchical relationship corresponds to one of: the distinguished natural language term being a type of the other natural language term; the distinguished natural language term being part of the other natural language term; the distinguished natural language term being a linguistic child of the other natural language term; the distinguished natural language term being created by the other natural language term; or the distinguished natural language term being enforced by the other natural language term., 6. The computer implemented method of claim 3 , wherein the identified fourth entry contains information indicating a source from which the hierarchical relationship defined in the identified fourth entry was derived., 7. The computer implemented method of claim 1 further comprising identifying one or more fourth entries, from among entries of a fourth table, corresponding to the first entry of the first table, wherein each identified fourth entry defines an alternate form of the distinguished natural language term., 8. The computer implemented method of claim 7 further comprising, for each particular fourth entry of the identified fourth entries, identifying, from among entries of a fifth table, a corresponding entry representing a type of difference that the particular fourth entry represents as compared to the first entry., 9. The computer implemented method of claim 1 further comprising identifying one or more fourth entries, from among entries of a fourth table, corresponding to the first entry of the first table, wherein each identified fourth entry identifies a term that is a synonym or antonym of the distinguished natural language term., 10. The computer implemented method of claim 1 further comprising identifying one or more fourth entries, from among entries of a fourth table, corresponding to the first entry of the first table, wherein each identified fourth entry defines an acronym of the distinguished natural language term., 11. The computer implemented method of claim 1 , wherein the first table further includes a fourth entry representing another natural language term identified, through entries in the second and third tables, as having the same meaning as the distinguished natural language term; wherein the fourth entry is designated as being a harmonized term; and wherein, when the first table is accessed such that both the first and fourth entries are retrieved, the fourth entry is selected for preferred used due to the harmonized designation., 12. The computer implemented method of claim 1 , wherein the identified third entries of the third table each relate to a control derived from an authority document., 13. The computer implemented method of claim 1 further comprising: identifying, based on the attributed definition natural language representations, one or more relationships between the distinguished natural language term and one or more other natural language terms; and wherein the identified one or more relationships are used in mapping portions of a document to controls., 14. A computer-readable storage medium, that is not a signal, storing data accessible by a program executable by a computing system, the computer-readable storage medium comprising: a dictionary data structure, wherein the dictionary data structure includes information usable by the program to identify one or more definitions for a distinguished natural language term, the dictionary data structure comprising: a first table comprising term entries, wherein each term entry represents a natural language term, and wherein a first entry of the term entries of the first table comprises a representation of the distinguished natural language term; a second table comprising correspondence entries, wherein each correspondence entry represents a correspondence between a term and a definition defining the term, and wherein one or more second entries of the correspondence entries are related to the first entry; and a third table comprising definition entries, wherein each definition entry represents a definition of a term, and wherein, for each particular second entry of the one or more second entries, the definition entries include a third entry related to the particular second entry, wherein the second entries are useable by the program to identify the third entries, and each particular third entry of the identified third entries is useable by the program to attribute a representation of the definition represented by the particular third entry to the distinguished natural language term., 15. The computer-readable storage medium of claim 14 , wherein the dictionary data structure further comprises a fourth table with hierarchy entries, wherein each particular hierarchy entry corresponds to two of the term entries of the first table and defines a hierarchical relationship between the two natural language terms represented by the two term entries corresponding to the particular hierarchy entry, and wherein each particular hierarchy entry contains information indicating a source from which the hierarchical relationship defined in the particular hierarchy entry was derived., 16. The computer-readable storage medium of claim 14 wherein the dictionary data structure further comprises a fourth table with alternate form entries, wherein each alternate form entry corresponds to one of the term entries of the first table and defines an alternate form of the natural language term represented by the corresponding term entry, and wherein the dictionary data structure further comprises a fifth table with same level entries, wherein each same level entry corresponds to one of the term entries of the first table and identifies a term that is a synonym or antonym of the natural language term represented by the corresponding term entry., 17. The computer-readable storage medium of claim 14 , wherein the third entries of the third table each relate to a control derived from an authority document., 18. The computer-readable storage medium of claim 14 , wherein the program attributes the representations of the definitions represented by the third entries to the distinguished natural language term; wherein the program identifies, based on the attributed representations of the definitions, one or more relationships between the distinguished natural language term and one or more other natural language terms; and wherein the identified one or more relationships are used in mapping portions of a document to controls., 19. The computer-readable storage medium of claim 14 , wherein the dictionary data structure is used by a computing system to augment a Part of Speech Tagger., 20. The computer-readable storage medium of claim 14 , wherein the dictionary data structure is used by a computing system to augment a Named Entity Tagger., 21. The computer-readable storage medium of claim 14 , wherein the dictionary data structure is used by a computing system to augment a Natural Language Processor., 22. A computing system for identifying one or more definitions for a distinguished natural language term, the computing system comprising: one or more processors; and memory storing instructions that, when executed by the one or more processors, cause the computing system to perform operations comprising: identifying, among entries of a first table each representing a natural language term, a first entry representing the distinguished natural language term; identifying, among entries of a second table each representing a correspondence between a term and a definition defining the term, one or more second entries related to the first entry; for each particular second entry of the identified second entries, identifying, among entries of a third table each representing a definition, a third entry related to the particular second entry, the third table being distinct from the second table; for each of the identified entries of the third table, accessing in the identified entry of the third table a natural language representation of the definition represented by the entry of the third table; and attributing the accessed definition natural language representations to the distinguished natural language term., 23. The computing system of claim 22 , wherein the operations further comprise: in relation to a distinguished one of the identified entries of the third table, identifying an entry of a fourth table corresponding to the distinguished entry of the third table, wherein the identified entry of the fourth table represents a word type corresponding to the definition represented in the distinguished entry of the third table, and wherein the word type specifies a part of speech for which a word is being used when it has the definition represented in the distinguished entry of the third table., 24. The computing system of claim 22 , wherein the operations further comprise: identifying a fourth entry, from among entries of a fourth table, corresponding to both the first entry of the first table and a fifth entry of the first table, wherein the identified fourth entry defines a hierarchical relationship between the distinguished natural language term of the first entry and another natural language term of the fifth entry., 25. The computing system of claim 24 , wherein the identified fourth entry includes a field defining a type of the hierarchical relationship., 26. The computing system of claim 25 , wherein the type of the hierarchical relationship corresponds to one of: the distinguished natural language term being a type of the other natural language term; the distinguished natural language term being part of the other natural language term; the distinguished natural language term being a linguistic child of the other natural language term; the distinguished natural language term being created by the other natural language term; or the distinguished natural language term being enforced by the other natural language term., 27. The computing system of claim 24 , wherein the identified fourth entry contains information indicating a source from which the hierarchical relationship defined in the identified fourth entry was derived., 28. The computing system of claim 22 , wherein the operations further comprise identifying one or more fourth entries, from among entries of a fourth table, corresponding to the first entry of the first table, wherein each identified fourth entry defines an alternate form of the distinguished natural language term., 29. The computing system of claim 28 , wherein the operations further comprise, for each particular fourth entry of the identified fourth entries, identifying, from among entries of a fifth table, a corresponding entry representing a type of difference that the particular fourth entry represents as compared to the first entry., 30. The computing system of claim 22 , wherein the operations further comprise identifying one or more fourth entries, from among entries of a fourth table, corresponding to the first entry of the first table, wherein each identified fourth entry identifies a term that is a synonym or antonym of the distinguished natural language term., 31. The computing system of claim 22 , wherein the operations further comprise identifying one or more fourth entries, from among entries of a fourth table, corresponding to the first entry of the first table, wherein each identified fourth entry defines an acronym of the distinguished natural language term., 32. The computing system of claim 22 , wherein the first table further includes a fourth entry representing another natural language term identified, through entries in the second and third tables, as having the same meaning as the distinguished natural language term; wherein the fourth entry is designated as being a harmonized term; and wherein, when the first table is accessed such that both the first and fourth entries are retrieved, the fourth entry is selected for preferred used due to the harmonized designation., 33. The computing system of claim 22 , wherein the identified third entries of the third table each relate to a control derived from an authority document., 34. The computing system of claim 22 , wherein the operations further comprise: identifying, based on the attributed definition natural language representations, one or more relationships between the distinguished natural language term and one or more other natural language terms; and wherein the identified one or more relationships are used in mapping portions of a document to controls.\n",
            "Similarity Score: 0.5720\n",
            "\n",
            "\n",
            "Patent ID: 10606908\n",
            "PubMed Claim: 1. A computer-implemented method comprising: providing, by a computing system, a first element in an interface presentable to a user through which a plurality of ephemeral media content items are accessible by the user for a selected period of time, wherein the first element is a listing comprising identifiers of a plurality of content providers associated with the plurality of ephemeral media content items; providing, by the computing system, a second element in the interface through which a plurality of non-ephemeral media content items are accessible by the user, wherein the second element is a listing comprising the plurality of non-ephemeral media content items; receiving, by the computing system, a designation by a content provider that a media content item is a non-ephemeral media content item; and providing, by the computing system, the media content item for presentation in the second element in the interface based on the designation., 2. The computer-implemented method of claim 1 , further comprising: receiving a designation by a content provider that a media content item is an ephemeral media content item; and providing an identifier of the content provider for potential presentation in the first element based on the designation., 3. The computer-implemented method of claim 1 , wherein the first element is a first scrollable array comprising identifiers of a plurality of content providers associated with the plurality of ephemeral media content items and the second element is a second scrollable array comprising the plurality of non-ephemeral media content items., 4. The computer-implemented method of claim 1 , wherein the first element and the second element are scrollable in different directions., 5. The computer-implemented method of claim 1 , further comprising: indicating in the first element a type of one or more ephemeral media content items of the plurality of ephemeral media content items., 6. A system comprising: at least one processor; and a memory storing instructions that, when executed by the at least one processor, cause the system to perform: providing a first element in an interface presentable to a user through which a plurality of ephemeral media content items are accessible by the user for a selected period of time, wherein the first element is a listing comprising identifiers of a plurality of content providers associated with the plurality of ephemeral media content items; and providing a second element in the interface through which a plurality of non-ephemeral media content items are accessible by the user, wherein the second element is a listing comprising the plurality of non-ephemeral media content items; receiving a designation by a content provider that a media content item is a non-ephemeral media content item; and providing the media content item for presentation in the second element in the interface based on the designation., 7. The system of claim 6 , further comprising: receiving a designation by a content provider that a media content item is an ephemeral media content item; and providing an identifier of the content provider for potential presentation in the first element based on the designation., 8. The system of claim 6 , wherein the first element is a first scrollable array comprising identifiers of a plurality of content providers associated with the plurality of ephemeral media content items and the second element is a second scrollable array comprising the plurality of non-ephemeral media content items., 9. The system of claim 6 , wherein the first element and the second element are scrollable in different directions., 10. The system of claim 6 , further comprising: indicating in the first element a type of one or more ephemeral media content items of the plurality of ephemeral media content items., 11. A non-transitory computer-readable storage medium including instructions that, when executed by at least one processor of a computing system, cause the computing system to perform a method comprising: providing a first element in an interface presentable to a user through which a plurality of ephemeral media content items are accessible by the user for a selected period of time, wherein the first element is a listing comprising identifiers of a plurality of content providers associated with the plurality of ephemeral media content items; and providing a second element in the interface through which a plurality of non-ephemeral media content items are accessible by the user, wherein the second element is a listing comprising the plurality of non-ephemeral media content items; receiving a designation by a content provider that a media content item is a non-ephemeral media content item; and providing the media content item for presentation in the second element in the interface based on the designation., 12. The non-transitory computer-readable storage medium of claim 11 , wherein the first element is a first scrollable array comprising identifiers of a plurality of content providers associated with the plurality of ephemeral media content items and the second element is a second scrollable array comprising the plurality of non-ephemeral media content items., 13. The non-transitory computer-readable storage medium of claim 11 , wherein the first element and the second element are scrollable in different directions., 14. The non-transitory computer-readable storage medium of claim 11 , further comprising: receiving a designation by a content provider that a media content item is an ephemeral media content item; and providing an identifier of the content provider for potential presentation in the first element based on the designation.\n",
            "Similarity Score: 0.5715\n",
            "\n",
            "\n",
            "Patent ID: 10606866\n",
            "PubMed Claim: 1. A system comprising: one or more processors; and memory storing instructions that, when executed by the one or more processors, cause the system to perform: accessing network activity information, the network activity information describing for an individual: respective relationships with one or more persons; and respective activity status information of the one or more persons, the respective activity status information indicating whether a given person has engaged in a particular activity; generating a network activity graph based on the network activity information, the network activity graph including two or more nodes representing the individual and the one or more persons, and connections between the two or more nodes representing the respective relationships between the individual and the one or more persons; providing data corresponding to the network activity graph to be presented through an interface; determining a density metric for the individual based on the connections of the network activity graph between the two or more nodes representing the respective relationships between the individual and the one or more persons, wherein the density metric for the individual is determined based on a number of relationship loops formed by the respective relationships of the individual with the one or more persons and one or more sizes of the relationship loops; determining an association metric for the individual based on the respective activity status information of the one or more persons; and providing information describing the individual for investigation to be presented through the interface based on a combination of the density metric and the association metric., 2. The system of claim 1 , wherein the respective relationships of the individual with the one or more persons include a linking entity that connects the individual to at least one of the one or more persons., 3. The system of claim 1 , wherein the association metric for the individual is determined based on a propagation function., 4. The system of claim 1 , wherein the association metric for the individual is determined further based on one or more weights associated with the one or more persons, one or more weights associated with the respective relationships between the individual and the one or more persons, or one or more weights associated with the one or more persons and the respective relationships between the individual and the one or more persons., 5. The system of claim 4 , wherein the instructions further cause the system to perform: assigning or changing at least one of the one or more weights associated with the one or more persons, at least one of the one or more weights associated with the respective relationships between the individual and the one or more persons, or at least one of the one or more weights associated with the one or more persons and the respective relationships between the individual and the one or more persons., 6. The system of claim 1 , wherein the instructions further cause the system to perform: changing an update rule by which the association metric is updated., 7. The system of claim 1 , wherein the instructions further cause the system to perform presenting a build-up user interface, the build-up user interface enabling a user to: view a list of entities added to an investigation; view a list of related entities; and add one or more of the related entities to the investigation., 8. A method implemented by a computing system including one or more processors and storage media storing machine-readable instructions, wherein the method is performed using the one or more processors, the method comprising: accessing network activity information, the network activity information describing for an individual: respective relationships with one or more persons; and respective activity status information of the one or more persons, the respective activity status information indicating whether a given person has engaged in a particular activity; generating a network activity graph based on the network activity information, the network activity graph including two or more nodes representing the individual and the one or more persons, and connections between the two or more nodes representing the respective relationships between the individual and the one or more persons; providing data corresponding to the network activity graph to be presented through an interface; determining a density metric for the individual based on the connections of the network activity graph between the two or more nodes representing the respective relationships between the individual and the one or more persons, wherein the density metric for the individual is determined based on a number of relationship loops formed by the respective relationships of the individual with the one or more persons and one or more sizes of the relationship loops; determining an association metric for the individual based on the respective activity status information of the one or more persons; and providing information describing the individual for investigation to be presented through the interface based on a combination of the density metric and the association metric., 9. The method of claim 8 , wherein the respective relationships of the individual with the one or more persons include a linking entity that connects the individual to at least one of the one or more persons., 10. The method of claim 8 , wherein the association metric for the individual is determined based on a propagation function., 11. The method of claim 8 , wherein the association metric for the individual is determined further based on one or more weights associated with the one or more persons, one or more weights associated with the respective relationships between the individual and the one or more persons, or one or more weights associated with the one or more persons and the respective relationships between the individual and the one or more persons., 12. The method of claim 11 , further comprising assigning or changing at least one of the one or more weights associated with the one or more persons, at least one of the one or more weights associated with the respective relationships between the individual and the one or more persons, or at least one of the one or more weights associated with the one or more persons and the respective relationships between the individual and the one or more persons., 13. The method of claim 8 , further comprising changing an update rule by which the association metric is updated., 14. The method of claim 8 , further comprising presenting a build-up user interface, the build-up user interface enabling a user to: view a list of entities added to an investigation; view a list of related entities; and add one or more of the related entities to the investigation., 15. A non-transitory computer readable medium comprising instructions that, when executed, cause one or more processors to perform: accessing network activity information, the network activity information describing for an individual: respective relationships with one or more persons; and respective activity status information of the one or more persons, the respective activity status information indicating whether a given person has engaged in a particular activity; generating a network activity graph based on the network activity information, the network activity graph including two or more nodes representing the individual and the one or more persons, and connections between the two or more nodes representing the respective relationships between the individual and the one or more persons; providing data corresponding to the network activity graph to be presented through an interface; determining a density metric for the individual based on the connections of the network activity graph between the two or more nodes representing the respective relationships between the individual and the one or more persons, wherein the density metric for the individual is determined based on a number of relationship loops formed by the respective relationships of the individual with the one or more persons and one or more sizes of the relationship lops; determining an association metric for the individual based on the respective activity status information of the one or more persons; and providing information describing the individual for investigation to be presented through the interface based on a combination of the density metric and the association metric.\n",
            "Similarity Score: 0.5715\n",
            "\n",
            "\n",
            "Patent ID: 10606802\n",
            "PubMed Claim: 1. A computer-implemented method, comprising: intercepting one or more updates made to a catalog data set, where: each of the one or more updates includes a system management facility (SMF) record, and the one or more updates are intercepted utilizing a program hook that retrieves the one or more updates from an SMF Exit routine; storing the one or more updates sequentially within an update buffer; retrieving the one or more updates from the update buffer, including sequentially reading the one or more updates from the update buffer; sequentially applying the one or more updates to a backup catalog data set, the backup catalog data set including a logically mirrored copy of a catalog data set; identifying a request to replace the catalog data set; and replacing the catalog data set with the backup catalog data set, in response to the request including: scanning the backup catalog data set to confirm an integrity of the backup catalog data set, in response to a confirmation of the integrity of the backup catalog data set, modifying one or more control blocks within a catalog address space of a mainframe computing system to change references from the catalog data set to the backup catalog data set; wherein replacing the catalog data set with the backup catalog data set utilizes a dynamic device reconfiguration (DDR) Swap interface for mirrored volume switching to direct updates to the backup catalog data set., 2. The computer-implemented method of claim 1 , wherein the catalog data includes a plurality of basic catalog structure (BCS) catalogs within the mainframe computing system., 3. The computer-implemented method of claim 1 , wherein the catalog data set includes a set of files used by the mainframe computing system to describe one or more data set attributes and indicate volumes on which a data set is located, the data set including a set of data that is used by an application., 4. The computer-implemented method of claim 1 , wherein the SMF record includes an insert action recorded in a 61 type., 5. The computer-implemented method of claim 1 , wherein the SMF record includes a delete action recorded in a 65 type., 6. The computer-implemented method of claim 1 , wherein the SMF record includes an alter action recorded in a 66 type., 7. The computer-implemented method of claim 1 , wherein the request to replace the catalog data set is sent in response to a determination that the catalog data set is not available or is corrupt., 8. The computer-implemented method of claim 1 , wherein: the catalog data includes a plurality of basic catalog structure (BCS) catalogs within the mainframe computing system, the catalog data set includes a set of files used by the mainframe computing system to describe one or more data set attributes and indicate volumes on which a data set is located, the data set including a set of data that is used by an application, the request to replace the catalog data set is sent in response to a determination that the catalog data set is not available or is corrupt, and the SMF record includes an insert action recorded in a 61 type., 9. A computer program product for catalog backup and recovery using logical mirroring, the computer program product comprising a computer readable storage medium having program instructions embodied therewith, wherein the computer readable storage medium is not a transitory signal per se, the program instructions executable by a processor to cause the processor to perform a method comprising: intercepting one or more updates made to a catalog data set, utilizing the processor, where: each of the one or more updates includes a system management facility (SMF) record, and the one or more updates are intercepted utilizing a program hook that retrieves the one or more updates from an SMF Exit routine; storing the one or more updates sequentially within an update buffer, utilizing the processor; retrieving the one or more updates from the update buffer, utilizing the processor including sequentially reading the one or more updates from the update buffer; sequentially applying the one or more updates to a backup catalog data set, utilizing the processor, the backup catalog data set including a logically mirrored copy of a catalog data set; identifying a request to replace the catalog data set, utilizing the processor; and replacing the catalog data set with the backup catalog data set, in response to the request, utilizing the processor, including: scanning the backup catalog data set to confirm an integrity of the backup catalog data set, in response to a confirmation of the integrity of the backup catalog data set, modifying one or more control blocks within a catalog address space of a mainframe computing system to change references from the catalog data set to the backup catalog data set; wherein replacing the catalog data set with the backup catalog data set utilizes a dynamic device reconfiguration (DDR) Swap interface for mirrored volume switching to direct updates to the backup catalog data set., 10. The computer program product of claim 9 , wherein the catalog data includes a plurality of basic catalog structure (BCS) catalogs within the mainframe computing system., 11. The computer program product of claim 9 , wherein the catalog data set includes a set of files used by the mainframe computing system to describe one or more data set attributes and indicate volumes on which a data set is located, the data set including a set of data that is used by an application., 12. The computer program product of claim 9 , wherein the SMF record includes an insert action recorded in a 61 type., 13. The computer program product of claim 9 , wherein the SMF record includes a delete action recorded in a 65 type., 14. The computer program product of claim 9 , wherein the SMF record includes an alter action recorded in a 66 type., 15. The computer program product of claim 9 , wherein the request to replace the catalog data set is sent in response to a determination that the catalog data set is not available or is corrupt., 16. The computer program product of claim 9 , wherein: the catalog data includes a plurality of basic catalog structure (BCS) catalogs within a mainframe computing system, the catalog data set includes a set of files used by the mainframe computing system to describe one or more data set attributes and indicate volumes on which a data set is located, the data set including a set of data that is used by an application, the request to replace the catalog data set is sent in response to a determination that the catalog data set is not available or is corrupt, and the SMF record includes an insert action recorded in a 61 type., 17. A system, comprising: a processor; and logic integrated with the processor, executable by the processor, or integrated with and executable by the processor, the logic being configured to: intercept one or more updates made to a catalog data set, where: each of the one or more updates includes a system management facility (SMF) record, and the one or more updates are intercepted utilizing a program hook that retrieves the one or more updates from an SMF Exit routine; store the one or more updates sequentially within an update buffer; retrieve the one or more updates from the update buffer, including sequentially reading the one or more updates from the update buffer; sequentially apply the one or more updates to a backup catalog data set, the backup catalog data set including a logically mirrored copy of a catalog data set; identify a request to replace the catalog data set; and replace the catalog data set with the backup catalog data set, in response to the request including: scanning the backup catalog data set to confirm an integrity of the backup catalog data set, in response to a confirmation of the integrity of the backup catalog data set, modifying one or more control blocks within a catalog address space of a mainframe computing system to change references from the catalog data set to the backup catalog data set; wherein replacing the catalog data set with the backup catalog data set utilizes a dynamic device reconfiguration (DDR) Swap interface for mirrored volume switching to direct updates to the backup catalog data set.\n",
            "Similarity Score: 0.5706\n",
            "\n",
            "\n",
            "Patent ID: 10606953\n",
            "PubMed Claim: 1. A method to extract relationships from text, the method comprising: receiving a training set of sentences comprising labeled objects and subjects for creating an initial relationship model; receiving a set of unlabeled sentences; determining, via a processor, objects and subjects from the set of unlabeled sentences based on the initial model; displaying the determined objects and subjects from the set of unlabeled sentences to a user for feedback and approval; receiving an indication of whether the determined objects and subjects from the set of unlabeled sentences are correct; and updating the initial relationship model based on the received indication, wherein creating the initial relationship model comprises executing a concept tagger against the training set of sentences to determine a domain and range of the sentences, wherein the domain and range is determined based upon a most frequently occurring subject-object semantic type pair., 2. The method of claim 1 , wherein the training set of sentences comprises less than thirty sentences., 3. The method of claim 1 , wherein creating the initial relationship model further comprises extracting word tokens from the training set of sentences wherein word tokens comprise words that are located between the subjects and the objects., 4. The method of claim 3 , wherein creating the initial relationship model further comprises determining extended word tokens comprising synonyms of the extracted word tokens., 5. The method of claim 4 , wherein the extended word tokens are weighted based on a similarity to the extracted word tokens., 6. A non-transitory computer-readable medium comprising instructions that when executed by a processor perform a method to extract relationships from text, the method comprising: receiving a training set of sentences comprising labeled objects and subjects for creating an initial relationship model; receiving a set of unlabeled sentences; determining, via a processor, objects and subjects from the set of unlabeled sentences based on the initial model; displaying the determined objects and subjects from the set of unlabeled sentences to a user for feedback and approval; receiving an indication of whether the determined objects and subjects from the set of unlabeled sentences are correct; and updating the initial relationship model based on the received indication, wherein creating the initial relationship model comprises executing a concept tagger against the training set of sentences to determine a domain and range of the sentences, wherein the domain and range is determined based upon a most frequently occurring subject-object semantic type pair., 7. The medium of claim 6 , wherein the training set of sentences comprises less than thirty sentences., 8. The medium of claim 6 , wherein creating the initial relationship model further comprises extracting word tokens from the training set of sentences wherein word tokens comprise words that are located between the subjects and the objects., 9. The medium of claim 6 , wherein creating the initial relationship model further comprises determining extended word tokens comprising synonyms of the extracted word tokens., 10. The medium of claim 9 , wherein the extended word tokens are weighted based on a similarity to the extracted word tokens., 11. A system to determine an asset event, the system comprising: a processor; and a non-transitory computer-readable medium comprising instructions that when executed by the processor perform a method to extract relationships from text, the method comprising: receiving a training set of sentences comprising labeled objects and subjects for creating an initial relationship model; receiving a set of unlabeled sentences; determining objects and subjects from the set of unlabeled sentences based on the initial model; displaying the determined objects and subjects from the set of unlabeled sentences to a user for feedback and approval; receiving an indication of whether the determined objects and subjects from the set of unlabeled sentences are correct; and updating the initial relationship model based on the received indication, wherein creating the initial relationship model comprises executing a concept tagger against the training set of sentences to determine a domain and range of the sentences, wherein the domain and range is determined based upon a most frequently occurring subject-object semantic type pair., 12. The system of claim 11 , wherein the training set of sentences comprises less than thirty sentences., 13. The system of claim 11 , wherein creating the initial relationship model further comprises extracting word tokens from the training set of sentences wherein word tokens comprise words that are located between the subjects and the objects., 14. The system of claim 13 , wherein creating the initial relationship model further comprises determining extended word tokens comprising synonyms of the extracted word tokens., 15. The system of claim 14 , wherein the extended word tokens are weighted based on a similarity to the extracted word tokens.\n",
            "Similarity Score: 0.5704\n",
            "\n",
            "\n",
            "Patent ID: 10606927\n",
            "PubMed Claim: 1. A method comprising: obtaining access to a hierarchically structured document having a plurality of hierarchical levels; for each of said hierarchical levels, obtaining a word list with a word count for each word included therein; for each of said hierarchical levels, creating a tag cloud based on said words in a respective one of said hierarchical levels and said word counts thereof; displaying a table of contents including a plurality of labels associated with respective ones of said hierarchical levels; displaying a first one of said tag clouds in association with a first hierarchical level upon detecting a selection of a corresponding one of said plurality of labels associated with said first hierarchical level, wherein said display of said first tag cloud one includes a nested icon representing a second tag cloud of said tag clouds corresponding to a second hierarchical level at a different hierarchical level of said hierarchically structured document than said first hierarchical level, wherein said table of contents and said tag clouds are associated to display in-context visualization of information about select levels of said hierarchical structure document; obtaining a selection of a given one of said words in said first tag cloud; highlighting, in response to said selection of said given one of said words, all entries in said table of contents for said hierarchically structured document containing at least one instance of said given one of said words; receiving a selection of said nested icon displayed in said first tag cloud; and displaying said second tag cloud corresponding to said second hierarchical level of said hierarchically structured document upon detecting said selection of said nested icon, wherein said second tag cloud is displayed simultaneously with said first tag cloud., 2. The method of claim 1 , wherein said step of creating said tag cloud comprises: removing stop words from each of said word lists; determining a total number of words in each of said word lists; determining a normalized word count for each word, other than said stop words, in each of said word lists, by dividing a corresponding one of said word counts by said total number of words in a corresponding one of said lists; wherein said tag clouds are based on said normalized word counts; and displaying, simultaneously, said first and second tag clouds, wherein each displayed tag cloud is displayed in a relatively closer proximity to an associated label displayed in said table of contents than to a label displayed in said table of contents associated with a different displayed tag cloud., 3. The method of claim 2 , wherein said step of creating said tag cloud further comprises: for each given one of said words in each of said word lists, other than said stop words, comparing a corresponding one of said normalized word counts to a pre-defined threshold; and including each given one of said words in each of said word lists in a corresponding one of said tag clouds, only if said pre-defined threshold is exceeded., 4. The method of claim 2 , wherein said displaying step comprises displaying given ones of said words in said first one of said tag clouds in a font size based on said normalized word count., 5. The method of claim 2 , wherein said displaying step comprises displaying given ones of said words in said first one of said tag clouds in alphabetical order., 6. The method of claim 2 , wherein said displaying step comprises displaying given ones of said words in said first one of said tag clouds in order of occurrence in said corresponding one of said hierarchical levels., 7. The method of claim 1 , further comprising providing a system, wherein the system comprises distinct software modules, each of the distinct software modules being embodied on a computer-readable storage medium, and wherein the distinct software modules comprise at least a word count extraction engine module, a tag cloud generation engine module, a control logic module, and a user interface module; wherein: said obtaining of said word list is carried out by said word count extraction engine module and said control logic module executing on at least one hardware processor; said creating of said tag cloud is carried out by said tag cloud generation engine module and said control logic module executing on said at least one hardware processor; and said displaying of said at least one of said tag clouds is facilitated by said user interface module executing on said at least one hardware processor.\n",
            "Similarity Score: 0.5692\n",
            "\n",
            "\n",
            "Patent ID: 10606804\n",
            "PubMed Claim: 1. A system for updating distributed file collection systems for logging types of online user events without shutdown, the system comprising: a producer system that is associated with an online content server and comprises a first memory that stores a first set of instructions and a first processor in communication with the first memory and configured to execute the first set of instructions to: detect a producer configuration file that specifies a log file type, wherein the log file type is selected, based on a producer system type associated with the producer system, from a group consisting of an impression log type, a click log type, an action log type, and a bid log type, the impression log type corresponding to a log of consumer impressions of online content, the click log type corresponding to a log of consumer interaction with online content, the bid log type corresponding to a log of bids submitted for online content; identify at least one file of the specified log file type, wherein the at least one file identifies data associated with a user event, the user event being one of at least one of an impression event, a click event, an action event, or a bid event; send the at least one file to a collector system; automatically detect a file associated with a new file type on the producer system, the new file type not being a listed type in the producer configuration file; in response to detecting the new file type, automatically generate and transmit a message to a conductor system, the message to the conductor system comprising information regarding the new file type; receive instructions from the conductor system to automatically update the producer configuration file based on the new file type; and update the producer configuration file, based on the received instructions from the conductor system, to include the new file type without shutting down the producer system; the conductor system comprising a second memory that stores a second set of instructions and a second processor in communication with the second memory and configured to execute the second set of instructions to: receive a request from a consumer associated with a consumer system, the request identifying a requested file type; allocate the at least one file to the consumer system based on the requested file type; receive, at the conductor system from the producer system, a notification of the producer configuration file; in response to receiving the notification, track events associated with the producer configuration file; receive the message, at the conductor system from the producer system, comprising information regarding the new file type; determine, at the conductor system, whether to change the producer configuration file to include the new file type based the new file type not being a listed type in the producer configuration file; and upon determining to change the producer configuration file to include the new file type, transmit instructions to the producer system to update the producer configuration file to include the new file type; the collector system comprising a third memory that stores a third set of instructions and a third processor in communication with the third memory and configured to execute the third set of instructions to receive the at least one identified file from the producer system; and the consumer system comprising a fourth memory that stores a fourth set of instructions and a fourth processor in communication with the fourth memory and configured to execute the fourth set of instructions to: receive the request from the consumer associated with the consumer system; send the request to the conductor system; pull the at least one file from the collector system; and provide the at least one file to the consumer., 2. The system of claim 1 , wherein the first processor is configured to execute the first set of instructions to receive a producer application configuration file from an application running on the first memory, and wherein detecting a producer configuration file comprises detecting the received producer application configuration file., 3. The system of claim 1 , wherein the first processor is configured to execute the first set of instructions to identify at least one file of the specified log file type by scanning the first memory for files of the specified log file type., 4. The system of claim 1 , wherein the first processor is configured to execute the first set of instructions to send the at least one file to the collector system using FTP., 5. The system of claim 1 , wherein the first processor is configured to execute the first set of instructions to send the at least one file to the collector system using UDT., 6. The system of claim 1 , wherein the request from the consumer system identifies a requested log file type., 7. The system of claim 6 , wherein the second processor is configured to execute the second set of instructions to determine whether the producer system has any files of the requested log file type., 8. The system of claim 1 , wherein: the third processor is configured to execute the third set of instructions to notify the conductor system that the at least one file has been received from the producer system; and the second processor is configured to execute the second set of instructions to track events associated with the at least one file., 9. The system of claim 1 , wherein: the second processor is configured to execute the second set of instructions to send a configuration file to the producer system; and the first processor is configured to execute the first set of instructions to: receive the configuration file from the conductor system; and configure the producer system based on the received configuration file., 10. The system of claim 1 , wherein: the second processor is configured to execute the second set of instructions to send a configuration file to the collector system; and the third processor is configured to execute the third set of instructions to: receive the configuration file from the conductor system; and configure the collector system based on the received configuration file., 11. The system of claim 1 , wherein: the first processor is configured to execute the first set of instructions to: send a request to the conductor system for a list of files that need to be resent to the collector system; and send files identified in the list of files to the collector system; and the second processor is configured to execute the second set of instructions to: determine the list of files for the producer system to resend to the collector system; and send the list of files to the producer system., 12. The system of claim 1 , wherein: the first processor is configured to execute the first set of instructions to: send a request to the conductor system for a list of files to delete; and delete the files identified in the list of files; and the second processor is configured to execute the second set of instructions to: determine the list of files for the producer system to delete; and send the list of files to the producer system., 13. The system of claim 1 , wherein: the third processor is configured to execute the third set of instructions to: send a request to the conductor system for a list of files to delete; and delete the files identified in the list of files; and the second processor is configured to execute the second set of instructions to: determine the list of files for the collector system to delete; and send the list of files to the collector system., 14. A method for updating distributed file collection systems for logging types of online user events without shutdown, the method comprising the following operations performed by one or more processors: detecting a configuration file that specifies a log file type, wherein the log file type is selected, based on a producer system type associated with a producer system, from a group consisting of an impression log type, a click log type, an action log type, and a bid log type, the impression log type corresponding to a log of consumer impressions of online content, the click log type corresponding to a log of consumer interaction with online content, the bid log type corresponding to a log of bids submitted for online content; identifying at least one file of the specified log file type, wherein the at least one file identifies data associated with a user event, the user event being one of an impression event, a click event, an action event, or a bid event; sending the at least one file to a collector system; automatically detecting a file associated with a new file type, the new file type not being a listed type in the producer configuration file; in response to detecting the new file type, automatically generating and transmitting a message to a conductor system, the message to the conductor system comprising information regarding the new file type; receiving instructions from the conductor system to automatically update the configuration file based on the new file type; updating the configuration file to include the new file type without shutting down; receiving a request from a consumer associated with a consumer system, the request identifying a requested file type; allocating, based on the requested file type, the at least one identified file to the consumer system; providing a notification of the producer configuration file; in response to receiving the notification, tracking events associated with the producer configuration file; receiving the request from the consumer associated with the consumer system; pulling the at least one identified file from the collector system to the consumer system; and providing the at least one identified file to the consumer., 15. The method of claim 14 , further comprising: sending a request to the conductor system for a list of files to delete; receiving, from the conductor system, the list of files; and deleting the files identified in the list of files., 16. The method of claim 14 , further comprising: sending a request to the conductor system for a list of files that need to be resent to the collector system; receiving, from the conductor system, the list of files; and sending files identified in the list of files to the collector system., 17. A computer-readable medium that stores a set of instructions executable by at least one processor to configure the at least one processor to perform operations for updating distributed file collection systems for logging types of online user events without shutdown, the operations comprising: detecting a configuration file that specifies a log file type, wherein the log file type is selected, based on a producer system type associated with a producer system, from a group consisting of an impression log type, a click log type, an action log type, and a bid log type, the impression loci type corresponding to a log of consumer impressions of online content, the click loci type corresponding to a log of consumer interaction with online content, the bid loci type corresponding to a log of bids submitted for online content; identifying at least one file of the specified log file type, wherein the at least one file identifies data associated with a user event, the user event being one of an impression event, a click event, an action event, or a bid event; sending the at least one file to a collector system; automatically detecting a file associated with a new file type, the new file type not being a listed type in the producer configuration file; in response to detecting the new file type, automatically generating and transmitting a message to a conductor system, the message to the conductor system comprising information regarding the new file type; receiving instructions from the conductor system to automatically update the configuration file based on the new file type; updating the configuration file to include the new file type without shutting down; receiving a request from a consumer associated with a consumer system, the request identifying a requested file type; allocating, based on the requested file type, the at least one identified file to the consumer system; providing a notification of the producer configuration file; in response to receiving the notification, tracking events associated with the producer configuration file; receiving the request from the consumer associated with the consumer system; pulling the at least one identified file from the collector system to the consumer system; and providing the at least one identified file to the consumer., 18. The computer-readable medium of claim 17 , wherein the set of instructions further configure the at least one processor to perform operations comprising: sending a request to the conductor system for a list of files to delete; receiving, from the conductor system, the list of files; and deleting the files identified in the list of files., 19. The computer-readable medium of claim 17 , wherein the set of instructions further configure the at least one processor to perform operations comprising: sending a request to the conductor system for a list of files that need to be resent to the collector system; receiving, from the conductor system, the list of files; and sending files identified in the list of files to the collector system.\n",
            "Similarity Score: 0.5676\n",
            "\n",
            "\n",
            "Patent ID: 10606940\n",
            "PubMed Claim: 1. An annotation sharing method, comprising: outputting a content of an electronic book; acquiring an annotation positioned in the content; calculating a position of the acquired annotation in the content by using metadata, which represents information related to the content, without using data included in the content, the metadata including a logical structure of the content, the logical structure including one or more logical elements representing a line, a paragraph, a section, and a chapter of the content, whose ranges widen in this order; and storing the calculated position and the annotation in association with each other and in a readable manner, wherein the calculating includes reading the metadata and specifying a finest logical element for part of the content that is being output, determining whether a near logical element, which is the finest logical element near the output part of the content, is specified or not, and when it is determined that the near logical element is not specified, widening a range of the logical elements to be focused for specifying the near logical element until the position of the acquired annotation in the content is specified by calculating the position thereof, the widening being performed step by step in an order of a line, a paragraph, a section, a chapter, and a whole of the content., 2. The method according to claim 1 , further comprising storing, in a server via a network, the calculated position in the content and the annotation in association with each other., 3. The method according to claim 1 , further comprising outputting the annotation at the stored position in the content during the output of the content., 4. The method according to claim 3 , further comprising: reading the position of the annotation in the content and the annotation that are stored in a readable manner; and outputting the annotation in a voice at the read position in the content., 5. The method according to claim 1 , further comprising calculating the position of the acquired annotation in the content using at least one of information that specifies a position in a logical element of the content, information that specifies a position in meta data of the content, and information that specifies a time elapsed from a time when a feature amount of the content reproduced in a voice is produced, a time elapsed until the feature amount is produced, and information that specifies a position in a logical element where a parameter in the content reproduced in a voice is designated., 6. The method according to claim 1 , further comprising acquiring the annotation for the content from handwritten input or voice input., 7. An annotation sharing apparatus, comprising: memory configured to function as a storing unit; and one or more processors configured to function as a content presentation unit, an acquisition unit, and a position calculation unit, wherein the content presentation unit outputs a content of an electronic book; the acquisition unit acquires an annotation positioned in the content output by the content presentation unit; the position calculation unit calculates a position of the acquired annotation in the content by using metadata, which represents information related to the content, without using data included in the content, the metadata including a logical structure of the content, the logical structure including one or more logical elements representing a line, a paragraph, a section, and a chapter of the content, whose ranges widen in this order; and the storing unit stores therein the position in the content and the annotation in association with each other, wherein in calculating the position of the acquired annotation in the content, the position calculation unit reads the metadata and specifies a finest logical element for part of the content that is being output, determines whether a near logical element, which is the finest logical element near the output part of the content, is specified or not, and when it is determined that the near logical element is not specified, widens a range of the logical elements to be focused for specifying the near logical element until the position of the acquired annotation in the content is specified by calculating the position thereof, the widening being performed step by step in an order of a line, a paragraph, a section, a chapter, and a whole of the content., 8. An annotation sharing apparatus, comprising: memory configured to function as a storing unit; and one or more processors configured to function as an annotation presentation unit, wherein the storing unit further stores therein an annotation positioned in a content of an electronic book and a position of the annotation in the content in association with each other and in a readable manner, the position being calculated by using metadata, which represents information related to the content, without using data included in the content, the metadata including a logical structure of the content, the logical structure including one or more logical elements representing a line, a paragraph, a section, and a chapter of the content, whose ranges widen in this order; and the annotation presentation unit presents, during the output of the content, the annotation at the position in the content, the position being stored by the storing unit, and wherein the calculation of the position of the annotation in the content includes processing of reading the metadata and specifying a finest logical element for part of the content that is being output, determining whether a near logical element, which is the finest logical element near the output part of the content, is specified or not, and when it is determined that the near logical element is not specified, widening a range of the logical elements to be focused for specifying the near logical element until the position of the annotation in the content is specified by calculating the position thereof, the widening being performed step by step in an order of a line, a paragraph, a section, a chapter, and a whole of the content., 9. An annotation sharing apparatus, comprising: memory configured to function as a storing unit; and one or more processors configured to function as a content presentation unit, an acquisition unit, a position calculation unit, and an annotation presentation unit, wherein the content presentation unit outputs a content of an electronic book; the acquisition unit acquires an annotation positioned in the content output by the content presentation unit; the position calculation unit calculates a position of the annotation in the content, the annotation being acquired by the acquisition unit, by using metadata, which represents information related to the content, without using data included in the content, the metadata including a logical structure of the content, the logical structure including one or more logical elements representing a line, a paragraph, a section, and a chapter of the content, whose ranges widen in this order; the storing unit stores, in a server, the annotation for the content and the calculated position of the annotation in the content in association with each other and in a readable manner; and the annotation presentation unit presents, during the output of the content, the annotation at the position in the content, the position being stored by the storing unit, wherein in calculating the position of the acquired annotation in the content, the position calculation unit reads the metadata and specifies a finest logical element for part of the content that is being output, determines whether a near logical element, which is the finest logical element near the output part of the content, is specified or not, and when it is determined that the near logical element is not specified, widens a range of the logical elements to be focused for specifying the near logical element until the position of the acquired annotation in the content is specified by calculating the position thereof, the widening being performed step by step in an order of a line, a paragraph, a section, a chapter, and a whole of the content., 10. A computer program product comprising a non-transitory computer-readable medium including programmed instructions, the instructions causing a computer to execute: outputting a content of an electronic book; acquiring an annotation positioned in the content; calculating a position of the acquired annotation in the content by using metadata, which represents information related to the content, without using data included in the content, the metadata including a logical structure of the content, the logical structure including one or more logical elements representing a line, a paragraph, a section, and a chapter of the content, whose ranges widen in this order; and storing the calculated position in the content and the annotation in association with each other and in a readable manner, wherein the calculating includes reading the metadata and specifying a finest logical element for part of the content that is being output, determining whether a near logical element, which is the finest logical element near the output part of the content, is specified or not, and when it is determined that the near logical element is not specified, widening a range of the logical elements to be focused for specifying the near logical element until the position of the acquired annotation in the content is specified by calculating the position thereof, the widening being performed step by step in an order of a line, a paragraph, a section, a chapter, and a whole of the content.\n",
            "Similarity Score: 0.5672\n",
            "\n",
            "\n",
            "Patent ID: 10606779\n",
            "PubMed Claim: 1. An integrated circuit, comprising: a first processing node; a second processing node; a third processing node; and a bus switch having outputs coupled to the first and second processing nodes in a hybrid shared-pipelined topology, wherein the bus switch is configured to receive a packet from the third processing node and to route the received packet to at most one of the first and second processing nodes, and wherein the bus switch is configured to route the received packet to the first processing node in response to determining that the second processing node is undergoing partial reconfiguration., 2. The integrated circuit of claim 1 , further comprising: an additional bus switch that receives the packet from a selected one of the first and second processing nodes, wherein the bus switch and the additional bus switch are part of a pipeline, and wherein the additional bus switch follows the bus switch in the pipeline., 3. The integrated circuit of claim 2 , further comprising: a bypass path that bypasses the first and second processing nodes and connects the bus switch directly to the additional bus switch., 4. The integrated circuit of claim 2 , further comprising: a fourth processing node that is connected to the additional bus switch; and a fifth processing node that is connected to the additional bus switch, wherein the additional bus switch is operable to route the packet to a selected one of the fourth and fifth processing nodes., 5. The integrated circuit of claim 1 , wherein the second processing node is temporarily inactive when the second processing node is undergoing partial reconfiguration., 6. The integrated circuit of claim 1 , wherein the bus switch comprises: a first input; a second input; a first multiplexer that receives signals from the first and second inputs and that has an output that is connected to the first processing node; and a second multiplexer that receives signals from the first and second inputs and that has an output that is connected to the second processing node., 7. The integrated circuit of claim 1 , further comprising: a first configuration register that stores an address of the first processing node; and a second configuration register that stores an address of the second processing node., 8. The integrated circuit of claim 7 , further comprising: a third configuration register that stores a bit that indicates whether the first processing node is active; and a fourth configuration register that stores a bit that indicates whether the second processing node is active., 9. A method of operating a system that includes a host processor and a coprocessor, the method comprising: initializing the coprocessor, wherein the coprocessor includes a plurality of processing nodes connected in a hybrid shared-pipelined topology; after initializing the coprocessor, performing partial reconfiguration on a selected processing node in the plurality of processing nodes; and while the selected processing node is undergoing partial reconfiguration, sending packets from the coprocessor to the host processor., 10. The method of claim 9 , further comprising: with the host processor, quiescing traffic to the selected processing node while the selected processing node is undergoing partial reconfiguration., 11. The method of claim 9 , wherein initializing the coprocessor comprises assigning a respective address to each processing node in the plurality of processing nodes., 12. The method of claim 11 , wherein the coprocessor includes a plurality of bus switches coupled in series with the plurality of processing nodes, wherein initializing the coprocessor comprises: for a given bus switch in the plurality of bus switches, assigning a first outbound address to the address of a first processing node in the plurality of processing nodes that is connected to the given bus switch; and for the given bus switch, assigning a second outbound address to the address of a second processing node in the plurality of processing nodes that is connected to the given bus switch., 13. The method of claim 12 , wherein initializing the coprocessor further comprises: for the given bus switch, asserting a first active state that indicates whether the first processing node is ready to receive data from the host processor; and for the given bus switch, asserting a second active state that indicates whether the second processing node is ready to receive data from the host processor., 14. The method of claim 13 , further comprising: sending a given packet from the host processor to the coprocessor; and comparing address information in the given packet to the first outbound address and the second outbound address to determine whether the given bus switch should route the given packet to the first processing node or the second processing node., 15. The method of claim 14 , further comprising: deasserting the first active state whenever the first processing node is undergoing partial reconfiguration; deasserting the second active state whenever the second processing node is undergoing partial reconfiguration; checking to see whether the first active state is asserted before sending the given packet to the first processing node; and checking to see whether the second active state is asserted before sending the given packet to the second processing node., 16. A system, comprising: a host processor; and a coprocessor that serves as a hardware accelerator for the host processor, wherein the coprocessor comprises: a first bus switch; a second bus switch coupled in series with the first bus switch; a third bus switch coupled in series with the second bus switch; first and second accelerator blocks coupled in parallel between the first and second bus switches; and third and fourth accelerator blocks coupled in parallel between the second and third bus switches., 17. The system of claim 16 , wherein the second bus switch is configured to receive information from the first bus switch via no more than one of the first and second accelerator blocks during normal operation, and wherein partial reconfiguration is performed on the first accelerator block while the host processor continues to pass data through the second accelerator block., 18. The system of claim 16 , wherein the coprocessor further comprises: a first bypass path connecting the first bus switch directly to the second bus switch; and a second bypass path connecting the second bus switch directly to the third bus switch., 19. The system of claim 16 , wherein the first, second, and third bus switches are controlled by the host processor., 20. The system of claim 16 , wherein the first bus switch determines whether to route an incoming packet to the first accelerator block or the second accelerator block based on address information and active state information associated with the first and second accelerator blocks.\n",
            "Similarity Score: 0.5662\n",
            "\n",
            "\n",
            "Patent ID: 10606947\n",
            "PubMed Claim: 1. A speech recognition apparatus comprising: one or more processors configured to: generate a word sequence based on word class probability distributions and word probabilities of words of the word sequence, generate, based on the word sequence, a word class probability distribution for word classes of a word following the word sequence, determine word probabilities with respect to candidate words, corresponding to the word following the word sequence, as results of a speech recognition model configured to predict the word following the word sequence, adjust the word probabilities with respect to the candidate words based on the word class probability distribution and a personalized language model, and output, as a speech recognition result, an extended word sequence including the word sequence and a candidate word having a highest adjusted probability value among the adjusted probability values., 2. The speech recognition apparatus of claim 1 , wherein: the word classes include either one or both of an entity name and a part of speech; and the entity name is any one or any combination of any two or more of a personal name, a location name, an organization name, a date, a time, a book title, a movie title, a music title, and a TV program name., 3. The speech recognition apparatus of claim 1 , wherein the one or more processors are configured to generate the word class probability distribution using a word class prediction model., 4. The speech recognition apparatus of claim 3 , wherein the word class prediction model is either one or both of: constructed in the form of a rule set based on a dictionary and a grammar; and constructed through machine learning using either one or both of a named entity recognition scheme and a part-of-speech tagging scheme., 5. The speech recognition apparatus of claim 3 , wherein the word class prediction model is a Recurrent Neural Network (RNN)-based model., 6. The speech recognition apparatus of claim 1 , wherein, for the determining of the word probabilities with respect to the candidate words, the one or more processors are configured to determine the word probabilities with respect to the candidate words using a pronunciation dictionary and a language model constructed in a data structure in a weighted finite-state transducer (WFST) form as the speech recognition model., 7. The speech recognition apparatus of claim 1 , wherein the one or more processors are configured to perform the generating and determining with respect to at least one extended word sequence, including the extended word sequence, with the at least one extended word sequence selectively excluding one or more of the candidate words determined to not belong to at least one word class determined based on the word class probability distribution, or with the at least one extended word sequence selectively excluding one or more extended word sequences that include the one or more candidate words., 8. The speech recognition apparatus of claim 1 , wherein: for the adjusting of the word probability, the one or more processors are configured to adjust the word probability by multiplying the word probability by the class probability., 9. The speech recognition apparatus of claim 1 , wherein the word sequence is a search result of speech recognition for the word sequence prior to the generation of the word class probability distribution and the determination of the probabilities with respect to the candidate words., 10. The speech recognition apparatus of claim 1 , wherein the determined probabilities with respect to the candidate words are probabilities of the candidate words or probabilities of extended word sequences that include the word sequence and respectively the candidate words., 11. A processor-implemented speech recognition method comprising: generating a word sequence based on word class probability distributions and word probabilities of words of the word sequence, predicting, based on the word sequence, a word class of a word following the word sequence and a word class probability of the word class; determining, based on a speech signal, a candidate word corresponding to the word following the word sequence and a word probability of the candidate word; determining whether the candidate word belongs to the word class, adjusting the word probability of the candidate word based on the class probability, in response to determining that the candidate word belongs to the word class, and outputting, as a speech recognition result, an extended word sequence including the word sequence and the determined candidate word, wherein the adjusting the probability value of the extended word sequence comprises increasing the probability value of the candidate word, in response to the candidate word belonging to the word class and being included in a personalized language model., 12. A speech recognition apparatus comprising: one or more processors configured to: predict, based on a word sequence, a word class of a word following a word sequence and a word class probability of the word class; extending, based on the word class, the word sequence to include a candidate word corresponding to the word class, in response to the candidate word belonging to the word class; predict, based on the extended word sequence, another word class of a word following the extended word sequence and another word class probability of the other word class; and extending, based on the other word class, the extended word sequence to include another candidate word corresponding to the other word class, in response to the other candidate word belonging to the other word class., 13. The speech recognition apparatus of claim 12 , wherein the one or more processors are further configured to: predict respective word class probabilities of a plurality of word classes based on the word sequence; and add the candidate word to the word sequence based on the word class probabilities, wherein the word class is one of the plurality of word classes and the word class probability is one of the plurality of word class probabilities., 14. The speech recognition apparatus of claim 13 , wherein: the candidate word belongs to the word class; and the adding of the candidate word comprised adding the candidate word to the word sequence in response to the word class having a highest probability among the plurality of word classes., 15. The speech recognition apparatus of claim 13 , wherein the one or more processors are further configured to: determine a plurality of candidate words that correspond to a speech signal; and determine whether to add one of the candidate words to the word sequence based on respective probabilities of the plurality of candidate words and the probabilities of the plurality of word classes, wherein the candidate word is one of the plurality of candidate words., 16. The speech recognition apparatus of claim 12 , wherein the one or more processors are further configured to: determine the candidate word based on a speech signal; and determine whether to add the candidate word to the word sequence based on the word class., 17. A processor-implemented speech recognition method comprising: generate a word sequence based on word class probability distributions and word probabilities of words of the word sequence, predicting, based on the word sequence, a word class or a word class probability distribution for word classes of a word following the word sequence; determining, based on a speech signal, word probabilities with respect to candidate words corresponding to the word following the word sequence using a speech recognition model; determining which of the candidate words belong to the word class or a select word class determined based on the word class probability distribution; selectively, based on a result of the determining of which candidate words belong to the word class or the select word class, adjusting the word probabilities with respect to the candidate words; and output, as a speech recognition result, an extended word sequence including the word sequence and a candidate word selected based on the selectively adjusted probabilities with respect to the candidate words., 18. The speech recognition method of claim 17 , wherein: the word class is either one or both of an entity name and a part of speech; and the entity name is any one or any combination of any two or more of a personal name, a location name, an organization name, a date, a time, a book title, a movie title, a music title, and a TV program name., 19. The speech recognition method of claim 17 , wherein the predicting the word class comprises predicting the word class using a word class prediction model., 20. The speech recognition method of claim 19 , wherein the word class prediction model is either one or both of: constructed in the form of a rule set based on a dictionary and a grammar; and constructed through machine learning using either one or both of a named entity recognition scheme and a part-of-speech tagging scheme., 21. The speech recognition method of claim 19 , wherein the word class prediction model is a Recurrent Neural Network (RNN)-based model., 22. The speech recognition method of claim 17 , wherein the determining the candidate word comprises searching for the candidate word using a pronunciation dictionary and a language model constructed in a data structure in a weighted finite-state transducer (WFST) form., 23. The speech recognition method of claim 17 , further comprising excluding the candidate word as a candidate word for a future target, in response to the candidate word not belonging to the word class., 24. The speech recognition method of claim 17 , wherein: the determining the word class comprises predicting a word class probability distribution of the word following the word sequence; and the adjusting the probability value of the extended word sequence comprises adjusting the probability value of the candidate word by multiplying a probability value of the candidate word by the probability value of the word class, wherein the candidate word belongs to the word class., 25. A non-transitory computer-readable storage medium storing instructions that, when executed by a processor, cause the processor to perform the method of claim 17 .\n",
            "Similarity Score: 0.5641\n",
            "\n",
            "\n",
            "Patent ID: 10606972\n",
            "PubMed Claim: 1. A design method including a high level synthesis process, the design method comprising: generating a hardware description of a circuit and high level synthesis report information from a source code in which a behavior of the circuit is described in a software language based on a high level synthesis constraint, the hardware description describing a circuit including a plurality of stages each stage having a stage circuit and an inter-stage register provided between each two stages of the plurality of stages; determining a bypass stage selection pattern based on bypass constraint information including a constraint condition related to a bypass of the inter-stage register and the high level synthesis report information, the bypass stage selection pattern including a plurality of patterns each pattern having a combination of stages of inter-stage registers for which a bypass setting is performed among stages of bypass setting-capable inter-stage registers; and generating bypass report information based on the bypass stage selection pattern, the bypass report information including combination information of the inter-stage registers for which the bypass setting is performed corresponding to a priority condition., 2. The design method according to claim 1 , wherein in the generating the hardware description, the high level synthesis constraint includes a constraint in which the circuit is able to operate at a requested fastest clock frequency, and a delay time of the plurality of stages of the circuit conforming to the hardware description is not more than a period of the requested fastest clock frequency., 3. The design method according to claim 2 , wherein the bypass constraint information includes the constraint condition having any of or any combination of a number of stages of the bypass setting-capable inter-stage registers, a stage of a specific bypass setting-capable inter-stage register, a stage of a specific inter-stage register for which the bypass setting is inhibited, and a minimum value of a number of consecutive stages of inter-stage registers for which the bypass setting is inhibited, and the bypass stage selection pattern includes a plurality of the combinations of the stages of the inter-stage registers for which the bypass setting is performed in which the constraint condition in the bypass constraint information being satisfied., 4. The design method according to claim 3 , wherein the high level synthesis report information includes a delay time of each stage of the plurality of stages and a number of the inter-stage registers of said each stage, the priority condition includes one of: a first priority condition in which a shorter maximum stage delay time in each combination of the plurality of the combinations is prioritized, and a second priority condition in which a greater total number of the inter-stage registers for which the bypass setting is performed in each combination of the plurality of the combinations is prioritized, and the bypass report information includes a ranking in an ascending order or a descending order of the shorter maximum stage delay time in a case of the first priority condition, and includes a ranking in a descending order or an ascending order of a total number of the inter-stage registers for which the bypass setting is performed in a case of the second priority condition., 5. The design method according to claim 1 , wherein each one of the bypass setting-capable inter-stage registers includes a latch circuit which retains an output signal of each said stage, a bypass wiring which bypasses the latch circuit, a selector which selects the latch circuit or the bypass wiring based on a bypass control signal, and a clock gate which allows or does not allow passage of a clock based on the bypass control signal, and the bypass setting of the bypass setting-capable inter-stage register is performed according to the bypass control signal., 6. The design method according to claim 5 , further comprising: generating, in accordance with a mode setting value corresponding to each pattern in the bypass stage selection pattern, the bypass control signal for the bypass setting or a bypass non-setting corresponding to the combination of the stages of the inter-stage registers for which the bypass setting is performed in each pattern; and adding to the hardware description a description of a bypass setting circuit configured to supply the bypass control signal to the bypass setting-capable inter-stage register., 7. The design method according to claim 5 , wherein in the determining the bypass stage selection pattern, the bypass setting-capable inter-stage register is selected by excluding the inter-stage register in a specific stage which is specified by the constraint condition and in which the bypass setting is inhibited, from the inter-stage register included in the circuit conforming to the hardware description., 8. A non-transitory computer-readable storage medium that stores therein a program causing a computer to execute a design program including a high level synthesis process comprising: generating a hardware description of a circuit and high level synthesis report information from a source code in which a behavior of the circuit is described in a software language based on a high level synthesis constraint, the hardware description describing a circuit including a plurality of stages each stage having a stage circuit and an inter-stage register provided between each two stages of the plurality of stages; determining a bypass stage selection pattern based on bypass constraint information including a constraint condition related to a bypass of the inter-stage register and the high level synthesis report information, the bypass stage selection pattern including a plurality of patterns each pattern having a combination of stages of inter-stage registers for which a bypass setting is performed among stages of bypass setting-capable inter-stage registers; and generating bypass report information based on the bypass stage selection pattern, the bypass report information including combination information of the inter-stage registers for which the bypass setting is performed corresponding to a priority condition., 9. The non-transitory computer-readable storage medium according to claim 8 , wherein in the generating the hardware description, the high level synthesis constraint includes a constraint in which the circuit is able to operate at a requested fastest clock frequency, and a delay time of the plurality of stages of the circuit conforming to the hardware description is not more than a period of the requested fastest clock frequency., 10. The non-transitory computer-readable storage medium according to claim 9 , wherein, the bypass constraint information includes the constraint condition having any of or any combination of a number of stages of the bypass setting-capable inter-stage registers, a stage of a specific bypass setting-capable inter-stage register, a stage of a specific inter-stage register for which the bypass, setting is inhibited, and a minimum value of a number of consecutive stages of inter-stage registers for which the bypass setting is inhibited, and the bypass stage selection pattern includes a plurality of the combinations of the stages of the inter-stage registers for which the bypass setting is performed in which the constraint condition in the bypass constraint information being satisfied., 11. A design apparatus comprising: a processor; and a memory being accessible by the processor; wherein the processor executes a design program including a high level synthesis process comprising: generating a hardware description of a circuit and high level synthesis report, information from a source code in which a behavior of the circuit is described in a software language based on a high level synthesis constraint, the hardware description describing a circuit including a plurality of stages each stage having a stage circuit and an inter-stage register provided between each two stages of the plurality of stages; determining a bypass stage selection pattern based on bypass constraint information including a constraint condition related to a bypass of the inter-stage register and the high level synthesis report information, the bypass stage selection pattern including a plurality of patterns each pattern having a combination of stages of inter-stage registers for which a bypass setting is performed among stages of bypass setting-capable inter-stage registers; and generating bypass report information based on the bypass stage selection pattern, the bypass report information including combination information of the inter-stage registers for which the bypass setting is performed corresponding to a predetermined priority condition., 12. The design apparatus according to claim 11 , wherein in the generating the hardware description, the high level synthesis constraint includes a constraint in which the circuit is able to operate, at a requested fastest clock frequency, and a delay time of the plurality of stages of the circuit conforming to the hardware description is not more than a period of the requested fastest clock frequency., 13. The design apparatus according to claim 12 , wherein the bypass constraint information includes the constrain condition having any of or any combination of a number of stages of the bypass setting-cable inter-stage registers, a stage of a specific bypass setting-capable inter-stage register, a stage of a specific inter-stage register for which the bypass setting is inhibited, and a minimum value of a number of consecutive stages of inter-stage registers for which the bypass setting is inhibited, and the bypass stage selection pattern includes a plurality of the combinations of the stages of the inter-stage registers for which the bypass setting is performed in which the constraint condition in the bypass constraint information being satisfied.\n",
            "Similarity Score: 0.5638\n",
            "\n",
            "\n",
            "Patent ID: 10606962\n",
            "PubMed Claim: 1. A computer-implemented method for optimizing transport alignments, comprising: reading terrain data, constraint data, and cost data; organizing and storing one or more terrain pixels, comprising elevation values, in a first grid structure comprising rows and columns to enable efficient access to each terrain pixel, wherein the first grid structure comprises a matrix; creating one or more raster layers of a same dimension and orientation as the first grid structure; obtaining a horizontal transportation starting alignment by: determining a first cheapest discrete path on a second grid structure that overlays the terrain data, constraint data, and cost data, wherein the second grid structure comprises a grid graph, wherein: in the grid graph, one or more edges, of the second grid structure, connect grid points; each of the one or more edges corresponds to a cost; the first cheapest discrete path is determined based on the cost for each of the one or more edges; smoothing the first cheapest discrete path, wherein the smoothing fits curvature to the first cheapest discrete path; minimizing a distance between the smoothed first cheapest discrete path and the first cheapest discrete path using an optimization method, wherein the optimization method uses a cost function that comprises: a measured distance that measures a similarity between the smoothed first cheapest discrete path and the first cheapest discrete path; and a penalty cost that occurs due to a violation of design constraints; and optimizing the starting horizontal transport alignment using the one or more raster layers., 2. The computer-implemented method of claim 1 , wherein a first raster layer of the one or more raster layers comprises water data., 3. The computer-implemented method of claim 2 , wherein a second raster layer of the one or more raster layers comprises an avoidance zone., 4. The computer-implemented method of claim 1 , wherein a first layer of the one or more of the raster layers comprises hard costs that are quantifiable in monetary values., 5. The computer-implemented method of claim 1 , wherein a first layer of the one or more of the raster layers comprises soft costs that are not quantifiable in monetary values., 6. The computer-implemented method of claim 1 , wherein the obtaining a starting horizontal transport alignment comprises: (a) obtaining a start point and an end point; (b) producing the second grid structure wherein: (1) the second grid structure is coarser than the first grid structure; and (2) one or more edges, of the second grid structure, connect grid points horizontally, vertically, and diagonally; (c) for each of the one or more edges: (1) computing a cost corresponding to an alignment segment that connects the grid points of each edge; (d) determining, based on the cost for each of the one or more edges, the first cheapest discrete path on the second grid structure; (e) smoothing the first cheapest discrete path to create the smoothed cheapest discrete path; and (f) selecting the smoothed cheapest discrete path as the starting horizontal transport alignment., 7. The computer-implemented method of claim 6 , wherein the cost comprises earthwork and construction costs., 8. The computer-implemented method of claim 6 , wherein the cost comprises a weighted and scaled combination of values from stored cost layers that lay under a portion of the alignment segment., 9. The computer-implemented method of claim 6 , wherein the selecting the smoothed cheapest discrete path as the starting horizontal transport alignment comprises: taking the smoothest cheapest discrete path and minimizing a distance between the smoothest cheapest discrete path and the first cheapest discrete path using an optimization method., 10. The computer-implemented method of claim 1 , wherein the optimizing utilizes a covariance matrix adaptation evolution strategy (CMA-ES)., 11. The computer-implemented method of claim 1 , wherein the optimizing comprises: (a) utilizing the starting horizontal transport alignment as an evaluating alignment; (b) projecting the evaluating alignment along a centerline onto the first grid structure; (c) reading one or more points where one or more tangents, of the evaluating alignment, intersect with the first grid structure; (d) storing, based on the one or more points, one or more elevation values to produce a first profile; (e) reading the one or more elevation values and a corresponding soft cost value, wherein the corresponding soft cast value cannot be measured as a monetary value and cannot be directly compared to hard costs; (f) obtaining, using the first profile, hard costs that are quantifiable in monetary values; (g) adding the soft cost value to the hard costs to determine an alignment cost; (h) changing a point of intersection configuration to provide a different evaluating alignment and repeating steps (b)-(g) for the changed point of intersection configuration to determine an additional alignment cost; (i) comparing the alignment cost and the additional alignment cost to determine the cheapest alignment cost; (j) storing the alignment corresponding to the cheapest alignment cost; and (k) returning the stored alignment to a user., 12. The computer-implemented method of claim 11 , further comprising: producing one or more offset second profiles, to a left and right of the centerline, to obtain additional elevation values., 13. The computer-implemented method of claim 11 , wherein: the optimizing is performed on multiple alignments in parallel utilizing different weights for soft costs., 14. The computer-implemented method of claim 11 , wherein the adding the soft cost value to the hard costs comprises: \n",
            " h(x)+?h(x)s(x)+p(x), where h(x) is the hard costs, s(x) is the soft cost value, p(x) is a penalty cost for violating a constraint, and ? is a weight factor that weights the soft cost value relative to the hard costs., 15. A non-transitory computer readable storage medium encoded with computer program instructions which when accessed by a computer cause the computer to load the program instructions to a memory therein creating a special purpose data structure causing the computer to operate as a specially programmed computer, executing a method of optimizing transport alignments, comprising: reading, in the specially programmed computer, terrain data, constraint data, and cost data; organizing and storing, in the specially programmed computer, one or more terrain pixels comprising elevation values in a first grid structure comprising rows and columns to enable efficient access to each terrain pixel, wherein the first grid structure comprises a matrix; creating, in the specially programmed computer, one or more raster layers of a same dimension and orientation as the first grid structure; obtaining, in the specially programmed computer, a starting horizontal transport alignment by: determining a first cheapest discrete path on a second grid structure that overlays the terrain data, constraint data, and cost data, wherein the second grid structure comprises a grid graph, wherein: in the grid graph, one or more edges, of the second grid structure, connect grid points; each of the one or more edges corresponds to a cost; the first cheapest discrete path is determined based on the cost for each of the one or more edges; smoothing the first cheapest discrete path, wherein the smoothing fits curvature to the first cheapest discrete path; and minimizing a distance between the smoothed first cheapest discrete path and the first cheapest discrete path using an optimization method, wherein the optimization method uses a cost function that comprises: a measured distance that measures a similarity between the smoothed first cheapest discrete path and the first cheapest discrete path; and a penalty cost that occurs due to a violation of design constraints; and optimizing, in the specially programmed computer, the starting horizontal transport alignment using the one or more raster layers., 16. The non-transitory computer readable storage medium of claim 15 , wherein a first raster layer of the one or more raster layers comprises water data., 17. The non-transitory computer readable storage medium of claim 16 , wherein a second raster layer of the one or more raster layers comprises an avoidance zone., 18. The non-transitory computer readable storage medium of claim 15 , wherein a first layer of the one or more of the raster layers comprises hard costs that are quantifiable in monetary values., 19. The non-transitory computer readable storage medium of claim 15 , wherein a first layer of the one or more of the raster layers comprises soft costs that are not quantifiable in monetary values., 20. The non-transitory computer readable storage medium of claim 15 , wherein the obtaining a starting horizontal transport alignment comprises: (a) obtaining, in the specially programmed computer, a start point and an end point; (b) producing, in the specially programmed computer, the second grid structure wherein: (1) the second grid structure is coarser than the first grid structure; and (2) one or more edges, of the second grid structure, connect grid points horizontally, vertically, and diagonally; (c) for each of the one or more edges: (1) computing, in the specially programmed computer, a cost corresponding to an alignment segment that connects the grid points of each edge; (d) determining, in the specially programmed computer, based on the cost for each of the one or more edges, a cheapest path on the second grid structure; (e) smoothing, in the specially programmed computer, the cheapest path; and (f) selecting, in the specially programmed computer, the smoothed cheapest path as the starting horizontal transport alignment., 21. The non-transitory computer readable storage medium of claim 20 , wherein the cost comprises earthwork and construction costs., 22. The non-transitory computer readable storage medium of claim 20 , wherein the cost comprises a weighted and scaled combination of values from stored cost layers that lay under a portion of the alignment segment., 23. The non-transitory computer readable storage medium of claim 20 , wherein the selecting the smoothed cheapest discrete path as the starting horizontal transport alignment comprises: taking the smoothest cheapest discrete path and minimizing a distance between the smoothest cheapest discrete path and the first cheapest discrete path using an optimization method., 24. The non-transitory computer readable storage medium of claim 15 , wherein the optimizing utilizes a covariance matrix adaptation evolution strategy (CMA-ES)., 25. The non-transitory computer readable storage medium of claim 15 , wherein the optimizing comprises: (a) utilizing, in the specially programmed computer, the starting horizontal transport alignment as an evaluating alignment; (b) projecting, in the specially programmed computer, the evaluating alignment along a centerline onto the first grid structure; (c) reading, in the specially programmed computer, one or more points where one or more tangents, of the evaluating alignment, intersect with the first grid structure; (d) storing, in the specially programmed computer, based on the one or more points, one or more elevation values to produce a first profile; (e) reading, in the specially programmed computer, the one or more elevation values and a corresponding soft cost value; (f) obtaining, in the specially programmed computer, using the first profile, hard costs that are quantifiable in monetary values; (g) adding, in the specially programmed computer, the soft cost value to the hard costs to determine an alignment cost; (h) changing, in the specially programmed computer, a point of intersection configuration to provide a different evaluating alignment and repeating steps (b)-(g) for the changed point of intersection configuration to determine an additional alignment cost; (i) comparing, in the specially programmed computer, the alignment cost and the additional alignment cost to determine the cheapest alignment cost; (j) storing, in the specially programmed computer, the alignment corresponding to the cheapest alignment cost; and (k) returning, in the specially programmed computer, the stored alignment to a user., 26. The non-transitory computer readable storage medium of claim 25 , further comprising: producing one or more offset second profiles, to a left and right of the centerline, to obtain additional elevation values., 27. The non-transitory computer readable storage medium of claim 25 , wherein: the optimizing is performed on multiple alignments in parallel utilizing different weights for soft costs., 28. The non-transitory computer readable storage medium of claim 25 , wherein the adding the soft cost value to the hard costs comprises: \n",
            " h(x)+?h(x)s(x)+p(x), where h(x) is the hard costs, s(x) is the soft cost value, p(x) is a penalty cost for violating a constraint, and ? is a weight factor that weights the soft cost value relative to the hard costs., 29. A computer-implemented method for optimizing transport alignments, comprising: reading terrain data, constraint data, and cost data, wherein the cost data comprises soft costs and hard costs, wherein the soft costs cannot be expressed in monetary values and the hard costs are expressed in monetary values; organizing and storing one or more terrain pixels, comprising elevation values, in a first grid structure comprising rows and columns to enable efficient access to each terrain pixel; creating one or more raster layers of a same dimension and orientation as the first grid structure; obtaining a starting alignment; and optimizing the starting alignment using the one or more raster layers with an Evolutionary Strategy method based on covariance matrix adaptation (CMA-ES), wherein: the Evolutionary Strategy method uses directional information based on an evaluation of the cost data: the Evolutionary Strategy method repeatedly changes a Points of Intersection (PI) configuration and a curve radius of the starting alignment; the Evolutionary Strategy method evaluates a soft cost of a new road alignment; the Evolutionary Strategy adds the soft costs to a total cost by scaling the soft costs as a multiple of the hard costs, and by weighing the scaled soft costs with respect to the hard costs; the Evolutionary Strategy method optimizes the starting alignment by minimizing a distance between a smoothed first cheapest discrete path and a first cheapest discrete path using a cost function that comprises: a measured distance that measures a similarity between the smoothed first cheapest discrete path and the first cheapest discrete path; and a penalty cost that occurs due to a violation of design constraints., 30. The computer-implemented method of claim 29 , wherein: the optimizing stops upon a given solving time expiring., 31. The computer-implemented method of claim 29 , wherein: the optimizing stops upon exceeding a given number of iterations., 32. The computer-implemented method of claim 29 , wherein: the optimizing stops when an improvement in the total costs is less than a tolerance., 33. The computer-implemented method of claim 29 , wherein: the optimizing stops when a change in the starting alignment is smaller than a tolerance.\n",
            "Similarity Score: 0.5632\n",
            "\n",
            "\n",
            "Patent ID: 10606967\n",
            "PubMed Claim: 1. A computer-implemented method, comprising: receiving actual distributed temperature sensing (DTS) data and pressure data in response to a stimulation treatment applied to a hydrocarbon field through a well in the hydrocarbon field; building a pre-stimulation model that includes reservoir parameters, the pre-stimulation model generating simulated DTS and pressure data as a function of the reservoir parameters, the reservoir parameters comprising a permeability parameter and a skin parameter of the hydrocarbon field; determining whether a thermal match between the actual DTS and pressure data and the simulated DTS and pressure data is obtained; in response to determining that the thermal match between the actual DTS and pressure data and the simulated DTS and pressure data is not obtained: updating the reservoir parameters, wherein updating the reservoir parameters comprises updating the permeability parameter and the skin parameter; updating the pre-stimulation model based on the updated reservoir parameters; and re-generating the simulated DTS and pressure data based on the updated pre-stimulation model until the thermal match between the actual DTS and pressure data and the simulated DTS and pressure data is obtained; determining whether the updated permeability parameter and the updated skin parameter match a performed pressure transient analysis (PTA); and in response to determining that the updated permeability parameter and the updated skin parameter do not match the PTA: updating the reservoir parameters, wherein updating the reservoir parameters comprises the updated permeability parameter and the updated skin parameter; updating the pre-stimulation model based on the updated reservoir parameters; and re-generating the simulated DTS and pressure data based on the updated pre-stimulation model until the thermal match between the actual DTS and pressure data and the simulated DTS and pressure data is obtained and the updated permeability parameter and the updated skin parameter match the PTA., 2. The computer-implemented method of claim 1 , further comprising: receiving input well data associated with the stimulation treatment for the hydrocarbon field through the well in the hydrocarbon field; and preparing the stimulation treatment based on input well data, wherein preparing the stimulation treatment of the hydrocarbon field comprises one or more of: designing a coiled tubing stimulation; testing the well infectivity; monitoring movement of injected fluid in the well; creating a pressure transient event to be analyzed for the permeability parameter and the skin parameter; or monitoring a warmback profile of the hydrocarbon field., 3. The computer-implemented method of claim 2 , wherein preparing a stimulation treatment of the hydrocarbon field comprises obtaining pre-stimulation DTS data and pressure data associated with the well in the hydrocarbon field, the method further comprising: determining whether the obtained pre-stimulation DTS data and pressure data are sufficient for executing the stimulation treatment; and in response to determining that the obtained pre-stimulation DTS data and pressure data not sufficient for executing the stimulation treatment, obtaining more pre-stimulation DTS and pressure data by creating more events in the preparing the stimulation treatment., 4. The computer-implemented method of claim 3 , further comprising, in response to determining that the obtained pre-stimulation DTS data and pressure data are sufficient for executing the stimulation treatment, performing the stimulation treatment., 5. The computer-implemented method of claim 4 , wherein performing the stimulation treatment comprises one or more of: detecting high intake zones of the well based on the pre-stimulation DTS data; optimizing stimulation fluid pumping schedule by adjusting a flow rate to match an actual well condition; or pumping stimulation fluid into the well according to a stimulation fluid pumping schedule., 6. The computer-implemented method of claim 2 , wherein the input well data comprises one or more of a wellbore diagram, directional survey, while-drilling mobility data, processed lithological data or petro-physical logs., 7. The computer-implemented method of claim 1 , further comprising evaluating the stimulation treatment, wherein evaluating the stimulation treatment comprises one or more of: obtaining actual DTS data while injecting a post-flush fluid into the well; comparing an injection/fall-off of a pre-flush into the well with an injection/fall-off of the post-flush into the well to evaluate chemical diversion and stimulation efficiency; detecting improvements in flow paths or pressure response; or performing a production logging tool (PLT) run., 8. The computer-implemented method of claim 1 , wherein building a pre-stimulation model comprises one or more of: applying a change of the reservoir parameters to match a transient event; or building the pre-stimulation model to match a thermal event., 9. The computer-implemented method of claim 1 , further comprising fine-tuning the actual DTS and pressure data and the simulated DTS and pressure data for building the pre-stimulation model., 10. The computer-implemented method of claim 1 , further comprising: comparing the reservoir parameters with a result of a production logging tool (PLT) run; or outputting the reservoir parameters., 11. A non-transitory computer-readable medium storing instructions executable by a computer system to perform operations comprising: receiving actual distributed temperature sensing (DTS) data and pressure data in response to a stimulation treatment applied to a hydrocarbon field through a well in the hydrocarbon field; building a pre-stimulation model that includes reservoir parameters, the pre-stimulation model generating simulated DTS and pressure data as a function of the reservoir parameters, the reservoir parameters comprising a permeability parameter and a skin parameter of the hydrocarbon field; determining whether a thermal match between the actual DTS and pressure data and the simulated DTS and pressure data is obtained; in response to determining that the thermal match between the actual DTS and pressure data and the simulated DTS and pressure data is not obtained: updating the reservoir parameters, wherein updating the reservoir parameters comprises updating the permeability parameter and the skin parameter; updating the pre-stimulation model based on the updated reservoir parameters; and re-generating the simulated DTS and pressure data based on the updated pre-stimulation model until the thermal match between the actual DTS and pressure data and the simulated DTS and pressure data is obtained; determining whether the updated permeability parameter and the updated skin parameter match a performed pressure transient analysis (PTA); and in response to determining that the updated permeability parameter and the updated skin parameter do not match the PTA: updating the reservoir parameters, wherein updating the reservoir parameters comprises the updated permeability parameter and the updated skin parameter; updating the pre-stimulation model based on the updated reservoir parameters; and re-generating the simulated DTS and pressure data based on the updated pre-stimulation model until the thermal match between the actual DTS and pressure data and the simulated DTS and pressure data is obtained and the updated permeability parameter and the updated skin parameter match the PTA., 12. The non-transitory computer-readable medium of claim 11 , wherein the operations further comprises: receiving input well data associated with the stimulation treatment for the hydrocarbon field through the well in the hydrocarbon field; and preparing the stimulation treatment based on input well data, wherein preparing the stimulation treatment of the hydrocarbon field comprises one or more of: designing a coiled tubing stimulation; testing the well infectivity; monitoring movement of injected fluid in the well; creating a pressure transient event to be analyzed for the permeability parameter and the skin parameter; or monitoring a warmback profile of the hydrocarbon field., 13. The non-transitory computer-readable medium of claim 12 , wherein preparing a stimulation treatment of the hydrocarbon field comprises obtaining pre-stimulation DTS data and pressure data associated with the well in the hydrocarbon field, the opeations further comprising: determining whether the obtained pre-stimulation DTS data and pressure data are sufficient for executing the stimulation treatment; and in response to determining that the obtained pre-stimulation DTS data and pressure data not sufficient for executing the stimulation treatment, obtaining more pre-stimulation DTS and pressure data by creating more events in the preparing the stimulation treatment., 14. The non-transitory computer-readable medium of claim 11 , wherein the operations further comprises evaluating the stimulation treatment, wherein evaluating the stimulation treatment comprises one or more of: obtaining actual DTS data while injecting a post-flush fluid into the well; comparing an injection/fall-off of a pre-flush into the well with an injection/fall-off of the post-flush into the well to evaluate chemical diversion and stimulation efficiency; detecting improvements in flow paths or pressure response; or performing a production logging tool (PLT) run., 15. The non-transitory computer-readable medium of claim 11 , wherein building a pre-stimulation model comprises one or more of: applying a change of the reservoir parameters to match a transient event; or building the pre-stimulation model to match a thermal event., 16. A computer-implemented system comprising: memory; and data processing apparatus operable to: receive actual distributed temperature sensing (DTS) data and pressure data in response to a stimulation treatment applied to a hydrocarbon field through a well in the hydrocarbon field; build a pre-stimulation model that includes reservoir parameters, the pre-stimulation model generating simulated DTS and pressure data as a function of the reservoir parameters, the reservoir parameters comprising a permeability parameter and a skin parameter of the hydrocarbon field; determine whether a thermal match between the actual DTS and pressure data and the simulated DTS and pressure data is obtained; in response to determining that the thermal match between the actual DTS and pressure data and the simulated DTS and pressure data is not obtained: update the reservoir parameters, wherein updating the reservoir parameters comprises updating the permeability parameter and the skin parameter; update the pre-stimulation model based on the updated reservoir parameters; and re-generate the simulated DTS and pressure data based on the updated pre-stimulation model until the thermal match between the actual DTS and pressure data and the simulated DTS and pressure data is obtained; determine whether the updated permeability parameter and the updated skin parameter match a performed pressure transient analysis (PTA); and in response to determining that the updated permeability parameter and the updated skin parameter do not match the PTA: update the reservoir parameters, wherein updating the reservoir parameters comprises the updated permeability parameter and the updated skin parameter; update the pre-stimulation model based on the updated reservoir parameters; and re-generate the simulated DTS and pressure data based on the updated pre-stimulation model until the thermal match between the actual DTS and pressure data and the simulated DTS and pressure data is obtained and the updated permeability parameter and the updated skin parameter match the PTA., 17. The computer-implemented system of claim 16 , the data processing apparatus further operable to: receive input well data associated with the stimulation treatment for the hydrocarbon field through the well in the hydrocarbon field; and prepare the stimulation treatment based on input well data, wherein preparing the stimulation treatment of the hydrocarbon field comprises one or more of: designing a coiled tubing stimulation; testing the well infectivity; monitoring movement of injected fluid in the well; creating a pressure transient event to be analyzed for the permeability parameter and the skin parameter; or monitor a warmback profile of the hydrocarbon field., 18. The computer-implemented system of claim 16 , the data processing apparatus further operable to: obtain actual DTS data while injecting a post-flush fluid into the well; compare an injection/fall-off of a pre-flush into the well with an injection/fall-off of the post-flush into the well to evaluate chemical diversion and stimulation efficiency; detect improvements in flow paths or pressure response; or perform a production logging tool (PLT) run., 19. The computer-implemented system of claim 16 , the data processing apparatus further operable to fine-tune the actual DTS and pressure data and the simulated DTS and pressure data for building the pre-stimulation model., 20. The computer-implemented system of claim 16 , the data processing apparatus further operable to: compare the reservoir parameters with a result of a production logging tool (PLT) run; or output the reservoir parameters.\n",
            "Similarity Score: 0.5623\n",
            "\n",
            "\n",
            "Patent ID: 10606991\n",
            "PubMed Claim: 1. A user-centric cyber security system, comprising: a plurality of DAAs (Data Acquisition Agents) configured to collect data relative to activities of a user in online accounts from a plurality of user's OSPs (Online Service Providers) and from a plurality of electronic user communication devices, wherein the data received from said plurality of user's OSPs is used to build a combined profile of a user that holds two kinds of data, one specific for each specific OSP among said plurality of user's OSPs and the second a cross OSPs profile data, thus said combined profile represents the identity and usage characteristic of said user in online accounts; and a system server communicating with said plurality of DAAs, said system server configured to receive said collected data from said plurality of DAAs, analyze said data for threats by identifying deviation from normal usage characteristic of said user, alert said user accordingly, receive feedback from said user regarding said alert and improve said threat analysis using said user's feedback., 2. The system of claim 1 , wherein said system server comprises: a CTAS (Cyber Threats Analysis System) configured to analyze said data and to determine whether it introduces a threat to said user's account or data; and a Threat Broker configured to determine a course of action relating to a determined threat., 3. The system of claim 2 , wherein said course of action comprises informing the user about the threat that his accounts and data are facing through at least one User Interface., 4. The system of claim 3 , wherein said at least one User Interface is selected from the group consisting of software client on a mobile device, software client on a PC and Web client interface., 5. The system of claim 2 , wherein said course of action is selected from the group consisting of informing at least one of said user's OSPs (Online Service Providers), informing an IT (Information Technology) and informing a security specialist., 6. The system of claim 2 , wherein said Threat Broker is further configured to offer remediation steps to said user., 7. The system of claim 6 , wherein said remediation steps are selected from the group consisting of changing OSP's password, closing all active connections to the OSP and reporting the threat to the OSP., 8. The system of claim 1 , wherein said data collected by said DAAs is selected from the group consisting of user activities in his accounts, user's stored data in the accounts and user's accounts settings., 9. The system of claim 1 , wherein said data collected by said DAAs comprises at least one of session data, behavioral data and content data., 10. The system of claim 9 , wherein said session data comprises at least one of IPs (Internet Protocols) used to login to the OSPs, locations the OSPs were logged from, devices used to login to the OSPs and browser types and signatures that were used to login to the OSPs., 11. The system of claim 9 , wherein said behavioral data comprises at least one of usual time of activities in the OSPs, average activities count per time frame, rules the user enforced on the OSPs and languages used by the user when interacting with the OSPs., 12. The system of claim 9 , wherein said content data comprises at least one of template of malicious posts in the OSPs, malicious URLs found in content of the OSPs and malicious files found in the OSPs., 13. The system of claim 1 , wherein said system server comprises a User Profiles database, a Cross User's database and an External Intelligence database., 14. The system of claim 13 , wherein said user profiles database is continuously updated and comprises at least one user characteristic selected from user's typical IPs, user's typical browsers, user's typical devices, user's typical activity times on the OSPs, user's typical posts and user's typical sequence of actions in the OSP., 15. The system of claim 14 , wherein said user profiles database comprises profile data specific for each one of said plurality of OSPs and a cross OSPs profile data., 16. The system of claim 14 , wherein each one of said at least one user characteristic comprises a weight representing the degree to which said characteristic matches the user's identity and behavior., 17. The system of claim 16 , wherein said analyzing comprises finding similarities and/or discrepancies between the characteristics received and deduced from a DAA data and the characteristics residing in the User Profile., 18. The system of claim 13 , wherein said Cross User database is continuously updated and comprises generalized characteristics applicable to a group of similar users., 19. The system of claim 13 , wherein said External Intelligence database comprises external sources from which the system collects and aggregates known threats to users' online accounts and data., 20. The system of claim 19 , wherein said known threats are selected from the group consisting of: malicious hosts IPs, anonymous proxy nodes, malicious URLs, phishing and scam mail templates and known malicious files signatures., 21. The system of claim 1 , wherein at least one of said plurality of DAAs is deployed on the user's devices as a part of a user application., 22. The system of claim 1 , wherein at least one of said plurality of DAAs is deployed on a user's OSP., 23. The system of claim 1 , wherein at least one of said plurality of DAAs is deployed on a remote server., 24. A method of providing user-centric cyber security, comprising: receiving from at least one DAA (Data Acquisition Agents) raw data collected from at least one user's OSPs (Online Service Providers) and from at least one user's electronic communication device, wherein said raw data relative to activities of a user in online accounts; building a combined profile of a user from the data received from said user's OSPs, wherein said profile holds two kinds of data, one specific for each OSP and the second a cross OSPs profile data, thus said combined profile represents the identity and usage characteristic of said user in online accounts; analyzing said data for threats by identifying deviation from normal usage characteristic of said user; and if said analysis indicates that the data is inconsistent with a stored profile of said user, generating a threat alert to said user's device; receiving feedback from said user regarding said threat alert; and improving said threat analysis using said user's feedback., 25. The method of claim 24 , wherein said analyzing comprises: using said user's profile to normalize said received raw data; using external sources to enrich said normalized data; and comparing said enriched data to said user's profile., 26. The method of claim 25 , further comprising comparing said enriched data to a Cross User database., 27. The method of claim 24 , further comprising updating said user's profile according to said feedback., 28. The method of claim 25 , further comprising comparing said enriched data to other users aggregated data., 29. The method of claim 24 , further comprising determining a course of action relating to a determined threat., 30. The method of claim 29 , wherein said course of action comprises informing the user about the threat that his accounts and data are facing through at least one User Interface., 31. The method of claim 30 , wherein said at least one User Interface is selected from the group consisting of software client on a mobile device, software client on a PC and Web client interface., 32. The method of claim 31 , wherein said course of action is selected from the group consisting of informing at least one of said user's OSPs, informing an IT (Information Technology) and informing a security specialist., 33. The method of claim 24 , further comprising offering remediation steps to said user., 34. The method of claim 33 , wherein said remediation steps are selected from the group consisting of changing OSP's password, closing all active connections to the OSP and reporting the threat to the OSP., 35. The method of claim 24 , wherein said received data is selected from the group consisting of user activities in his accounts, user's stored data in the accounts and user's accounts settings., 36. The method of claim 24 , wherein said data is collected from said user's electronic communication devices., 37. The method of claim 24 , wherein said data comprises at least one of session data, behavioral data and content data., 38. The method of claim 37 , wherein said session data comprises at least one of IPs used to login to the OSPs, locations the OSPs were logged from, devices used to login to the OSPs and browser types and signatures that were used to login to the OSPs., 39. The method of claim 37 , wherein said behavioral data comprises at least one of usual time of activities in the OSPs, average activities count per time frame, rules the user enforced on the OSPs and languages used by the user when interacting with the OSPs., 40. The method of claim 37 , wherein said content data comprises at least one of template of malicious posts in the OSPs, malicious URLs found in content of the OSPs and malicious files found in the OSPs., 41. One or more computer-storage media embedded with computer-executable instructions, the embedded computer-executable instructions are executed by at least one processor for performing a method of providing user-centric cyber security, comprising: receiving from at least one DAA (Data Acquisition Agents) raw data collected from at least one user's OSPs (Online Service Providers) and from at least one user's device, wherein said raw data relative to activities of a user in online accounts; building a combined profile of a user from the data received from said user's OSPs, wherein said profile holds two kinds of data, one specific for each OSP and the second a cross OSPs profile data, thus said combined profile represents the identity and usage characteristic of said user in online accounts; analyzing said data for threats by identifying deviation from normal usage characteristic of said user; and if said analysis indicates that the data is inconsistent with a stored profile of said user, generating a threat alert to said user's device; receiving feedback from said user regarding said threat alert; and improving said threat analysis using said user's feedback.\n",
            "Similarity Score: 0.5621\n",
            "\n",
            "\n",
            "Patent ID: 10606928\n",
            "PubMed Claim: 1. A method, comprising: receiving a first electronic document including a plurality of regions; identifying, by a processor, the plurality of regions in the first electronic document; and processing the first electronic document using a template to generate a second electronic document by tagging at least a subset of the plurality of regions of the first electronic document with information indicating a logical order of the plurality of the regions based on the template, the tagging information conforming to at least one accessibility standard and allowing an accessibility product to present the subset of the plurality of regions through a computing device according to the logical order without user specification of the logical order of presentation., 2. The method of claim 1 , wherein the template includes a set of tagging rules corresponding to a type of the first document., 3. The method of claim 2 , wherein the template defines the plurality of regions in association with the set of tagging rules., 4. The method of claim 3 , further comprising automatically detecting the plurality of regions., 5. The method of claim 4 , wherein the automatically detected plurality of regions are saved in the template., 6. The method of claim 5 , wherein the plurality of regions are automatically detected by determining a plurality of text fragments associated with at least one of the plurality of regions and determining a gap between the plurality of text fragments., 7. The method of claim 6 , wherein the plurality of text fragments have a reading order., 8. A non-transitory computer-readable storage medium storing instructions thereon, the instructions when executed by a processor cause the processor to: receive a first electronic document including a plurality of regions; identify, by a processor, the plurality of regions in the first electronic document; and process the first electronic document using a template to generate a second electronic document by tagging at least a subset of the plurality of regions of the first electronic document with information indicating a logical order of the plurality of the regions based on the template, the tagging information conforming to at least one accessibility standard and allowing an accessibility to product to present the subset of the plurality of regions through a computing device according to the logical order without user specification of the logical order of presentation., 9. The computer-readable storage medium of claim 8 , wherein the template includes a set of tagging rules corresponding to a type of the first document., 10. The computer-readable storage medium of claim 9 , wherein the template defines the plurality of regions in association with the set of tagging rules., 11. The computer-readable storage medium of claim 10 , wherein the instructions cause the processor to automatically detect the plurality of regions., 12. The computer-readable storage medium of claim 11 , wherein the automatically detected plurality of regions are saved in the template., 13. The computer-readable storage medium of claim 12 , wherein the plurality of regions are automatically detected by determining a plurality of text fragments associated with at least one of the plurality of regions and determining a gap between the plurality of text fragments., 14. The computer-readable storage medium of claim 13 , wherein the plurality of text fragments have a reading order., 15. A system for converting documents, comprising: a processor; and a computer readable medium, comprising instructions executable on the processor for: receiving a first electronic document including a plurality of regions; identifying, by a processor, the plurality of regions in the first electronic document; and processing the first electronic document using a template to generate a second electronic document by tagging at least a subset of the plurality of regions of the first electronic document with information indicating a logical order of the plurality of the regions based on the template, the tagging information conforming to at least one accessibility standard and allowing an accessibility to product to present the subset of the plurality of regions through a computing device according to the logical order without user specification of the logical order of presentation., 16. The system of claim 15 , wherein the template includes a set of tagging rules corresponding to a type of the first document., 17. The system of claim 16 , wherein the template defines the plurality of regions in association with the set of tagging rules., 18. The system of claim 17 , wherein the instructions are executable on the processor for automatically detecting the plurality of regions., 19. The system of claim 18 , wherein the automatically detected plurality of regions are saved in the template., 20. The system of claim 19 , wherein the plurality of regions are automatically detected by determining a plurality of text fragments associated with at least one of the plurality of regions and determining a gap between the plurality of text fragments., 21. The system of claim 20 , wherein the plurality of text fragments have a reading order.\n",
            "Similarity Score: 0.5621\n",
            "\n",
            "\n",
            "Patent ID: 10606852\n",
            "PubMed Claim: 1. A method, comprising: receiving, by a columnar database management system from a client device over a network, a data mining request, the columnar database management system comprising stored columns of data, data mining operations, and a database engine, the data mining request containing a description of requested calculations and information about data items to be processed; parsing, by the database engine, the description of the requested calculations, the parsing identifying a data mining operation of the data mining operations; generating, by the database engine, a data mining processing plan for processing the data items specified by the data mining request, the generating comprising: identifying, based on the data mining operation identified from the parsing or an internal table or data structure of the columnar database management system, any other data mining operation necessary to complete processing of the data mining request; acquiring any resource needed for processing the data items indicated by the data mining request; performing a pre-allocation procedure on any resource thus acquired; and performing orchestration tasks, the orchestration tasks including a coordination procedure, the coordination procedure including determining an order of execution for different parts of identified data mining operations that are to be applied to the stored columns of data; wherein the data mining processing plan thus generated by the database engine comprises the data items and the identified mining operations to be used, the order of execution in which the identified mining operations are to be executed, the resources to be used during execution, and a coordination of the identified data mining operations and the resources to be used during execution; executing, by the database engine, the data mining processing plan, the executing producing data mining results; and responsive to the data mining request, returning the data mining results for presentation on the client device., 2. The method according to claim 1 , wherein the orchestration tasks further comprise at least one of a lock control procedure, a concurrency control procedure, an integrity control procedure, a queue management procedure, a parallelization procedure, or a synchronization procedure., 3. The method according to claim 1 , wherein the coordination procedure further comprises determining an execution duration of a particular data mining operation or a step thereof and utilizing the execution duration thus determined in generation of the data mining processing plan., 4. The method according to claim 1 , wherein the data mining operations comprise at least one of a cross tabulation process, a Venn diagram generation, profile finding processes, decision tree algorithms, association rule algorithms, clustering algorithms, time series algorithms, neural network algorithms, support vector machine related algorithms, or Bayesian network related algorithms., 5. The method according to claim 1 , further comprising: authenticating the data mining request, the authenticating performed by the database engine prior to the parsing, the authenticating comprising determining whether authentication information included in the data mining request is valid against information for authenticated clients stored by the database engine., 6. The method according to claim 1 , wherein the data mining processing plan comprises executable code available as software modules in the columnar database management system., 7. The method according to claim 1 , wherein the data mining request is received by the columnar database management system from the client device indirectly via a frontend application of a data mining system within which the columnar database management system operates, the frontend application receiving the data mining results from the columnar database management system for transmission to the client device., 8. A columnar database management system, comprising: a processor; a non-transitory computer-readable medium; stored columns of data embodied on the non-transitory computer-readable medium; data mining operations embodied on the non-transitory computer-readable medium; and stored instructions embodied on the non-transitory computer-readable medium and translatable by the processor to implement a database engine for processing a data mining request received from a client device over a network, the data mining request containing a description of requested calculations and information about data items to be processed, the processing by the database engine comprising: parsing the description of the requested calculations, the parsing identifying a data mining operation of the data mining operations; generating a data mining processing plan for processing the data items specified by the data mining request, the generating comprising: identifying, based on the data mining operation identified from the parsing or an internal table or data structure of the columnar database management system, any other data mining operation necessary to complete processing of the data mining request; acquiring any resource needed for processing the data items indicated by the data mining request; performing a pre-allocation procedure on any resource thus acquired; and performing orchestration tasks, the orchestration tasks including a coordination procedure, the coordination procedure including determining an order of execution for different parts of identified data mining operations that are to be applied to the stored columns of data; wherein the data mining processing plan thus generated by the database engine comprises the data items and the identified mining operations to be used, the order of execution in which the identified mining operations are to be executed, the resources to be used during execution, and a coordination of the identified data mining operations and the resources to be used during execution; executing the data mining processing plan, the executing producing data mining results; and responsive to the data mining request, returning the data mining results for presentation on the client device., 9. The columnar database management system of claim 8 , wherein the orchestration tasks further comprise at least one of a lock control procedure, a concurrency control procedure, an integrity control procedure, a queue management procedure, a parallelization procedure, or a synchronization procedure., 10. The columnar database management system of claim 8 , wherein the coordination procedure further comprises determining an execution duration of a particular data mining operation or a step thereof and utilizing the execution duration thus determined in generation of the data mining processing plan., 11. The columnar database management system of claim 8 , wherein the data mining operations comprise at least one of a cross tabulation process, a Venn diagram generation, profile finding processes, decision tree algorithms, association rule algorithms, clustering algorithms, time series algorithms, neural network algorithms, support vector machine related algorithms, or Bayesian network related algorithms., 12. The columnar database management system of claim 8 , wherein the processing by the database engine further comprises authenticating the data mining request, the authenticating performed prior to the parsing, the authenticating comprising determining whether authentication information included in the data mining request is valid against information for authenticated clients stored by the database engine., 13. The columnar database management system of claim 8 , wherein the data mining processing plan comprises executable code available as software modules in the columnar database management system., 14. The columnar database management system of claim 8 , wherein the data mining request is received by the columnar database management system from the client device indirectly via a frontend application of a data mining system within which the columnar database management system operates, the frontend application receiving the data mining results from the columnar database management system for transmission to the client device., 15. A computer program product comprising a non-transitory computer-readable medium storing instructions translatable by a processor of a columnar database management system for: receiving a data mining request received from a client device over a network, the columnar database management system comprising stored columns of data and data mining operations, the data mining request containing a description of requested calculations and information about data items to be processed; parsing the description of the requested calculations, the parsing identifying a data mining operation of the data mining operations; generating a data mining processing plan for processing the data items specified by the data mining request, the generating comprising: identifying, based on the data mining operation identified from the parsing or an internal table or data structure of the columnar database management system, any other data mining operation necessary to complete processing of the data mining request; acquiring any resource needed for processing the data items indicated by the data mining request; performing a pre-allocation procedure on any resource thus acquired; and performing orchestration tasks, the orchestration tasks including a coordination procedure, the coordination procedure including determining an order of execution for different parts of identified data mining operations that are to be applied to the stored columns of data; wherein the data mining processing plan thus generated by the database engine comprises the data items and the identified mining operations to be used, the order of execution in which the identified mining operations are to be executed, the resources to be used during execution, and a coordination of the identified data mining operations and the resources to be used during execution; executing the data mining processing plan, the executing producing data mining results; and responsive to the data mining request, returning the data mining results for presentation on the client device., 16. The computer program product of claim 15 , wherein the orchestration tasks further comprise at least one of a lock control procedure, a concurrency control procedure, an integrity control procedure, a queue management procedure, a parallelization procedure, or a synchronization procedure., 17. The computer program product of claim 15 , wherein the coordination procedure further comprises determining an execution duration of a particular data mining operation or a step thereof and utilizing the execution duration thus determined in generation of the data mining processing plan., 18. The computer program product of claim 15 , wherein the data mining operations comprise at least one of a cross tabulation process, a Venn diagram generation, profile finding processes, decision tree algorithms, association rule algorithms, clustering algorithms, time series algorithms, neural network algorithms, support vector machine related algorithms, or Bayesian network related algorithms., 19. The computer program product of claim 15 , wherein the instructions are further translatable by the processor for authenticating the data mining request, the authenticating performed prior to the parsing, the authenticating comprising determining whether authentication information included in the data mining request is valid against information for authenticated clients stored by the database engine., 20. The computer program product of claim 15 , wherein the data mining processing plan comprises executable code available as software modules in the columnar database management system.\n",
            "Similarity Score: 0.5615\n",
            "\n",
            "\n",
            "Patent ID: 10606841\n",
            "PubMed Claim: 1. A computing device for data compression token generation, the computing device comprising: a hardware processor; and one or more memory devices having stored therein a plurality of instructions that, when executed by the hardware processor, cause the computing device to establish: a plurality of search agents to search for a plurality of matches and to generate a plurality of weight values, wherein each search agent is associated with a different index, and wherein each search agent is to: search, in parallel, a history of an input stream for a corresponding match of the plurality of matches, wherein the corresponding match comprises a substring of the history that matches the input stream starting at a position that is based on the index associated with the search agent, and wherein the corresponding match is associated with a length and a distance; and generate, in parallel, a corresponding weight value of the plurality of weight values, wherein each weight value is associated with a corresponding match of the plurality of matches, and wherein each weight value is indicative of the length associated with the corresponding match and an encoded length associated with the corresponding match, wherein the encoded length is indicative of a number of bits to encode the corresponding match, wherein to generate the corresponding weight value comprises to: generate a raw score associated with the corresponding match based on the length associated with the corresponding match or the encoded length associated with the corresponding match, wherein to generate the raw score comprises to generate a frequency count weight as a function of a first frequency count of the length associated with the corresponding match and a second frequency count of the distance associated with the corresponding match; normalize the raw score to generate a percentile weight based on a maximum of a plurality of raw scores, wherein each raw score of the plurality of raw scores is associated with a match of the plurality of matches; and generate the corresponding weight value as a function of the percentile weight; and a decision engine to select a selected match from the plurality of matches as a function of the plurality of weight values., 2. The computing device of claim 1 , wherein to generate the corresponding weight value comprises to determine whether the distance associated with the corresponding match is included in a move-to-front stack; replace the distance associated with the corresponding match with a symbol from the move-to-front stack in response to a determination that the distance associated with the corresponding match is included in the move-to-front stack; and move the distance associated with the corresponding match to a front of the move-to front stack in response to a determination of whether the distance associated with the corresponding match is included in the move-to-front stack., 3. The computing device of claim 1 , wherein to generate the raw score comprises to generate a length weight as a function of the length associated with the corresponding match and the index associated with the search agent., 4. The computing device of claim 1 , wherein to generate the raw score comprises to generate an extra bit weight as a function of a number of extra bits corresponding to the distance associated with the corresponding match and a predetermined maximum number of extra bits., 5. The computing device of claim 1 , wherein to generate the corresponding weight value comprises to: generate a plurality of raw scores associated with the corresponding match based on the length associated with the corresponding match and the encoded length associated with the corresponding match; normalize each of the plurality of raw scores to generate a plurality of percentile weights, wherein each percentile weight is associated with a corresponding raw score; and generate the corresponding weight value as a function of the plurality of percentile weights., 6. The computing device of claim 5 , wherein to generate the corresponding weight value further comprises to: determine whether the corresponding match is adjacent to another match of the plurality of matches; and generate the corresponding weight value as a function of an adjacency bonus in response to a determination that the corresponding match is adjacent to another match, wherein the adjacency bonus comprises a plurality of percentile weights associated with the other match., 7. The computing device of claim 5 , wherein to generate the corresponding weight value as a function of the plurality of percentile weights comprises to adjust a relative importance of each percentile weight of the plurality of percentile weights., 8. The computing device of claim 7 , wherein to adjust the relative importance of each percentile weight of the plurality of percentile weights comprises to: multiply each percentile weight of the plurality of percentile weights by a corresponding constant to generate a corresponding product; and sum the plurality of products to generate the corresponding weight value., 9. The computing device of claim 7 , wherein to adjust the relative importance of each percentile weight comprises to adjust the relative importance of each percentile weight based on a data type of the input data stream., 10. A method for data compression token generation, the method comprising: searching in parallel, by a computing device, a history of an input stream for a plurality of matches, wherein each match comprises a substring of the history that matches the input stream starting at a position based on a corresponding index, and wherein each match is associated with a length and a distance; generating in parallel, by the computing device, a plurality of weight values, wherein each weight value is associated with a corresponding match of the plurality of matches, and wherein each weight value is indicative of the length associated with the corresponding match and an encoded length associated with the corresponding match, wherein the encoded length is indicative of a number of bits to encode the corresponding match, wherein generating in parallel the plurality of weight values comprises generating a first weight value associated with a first match of the plurality of matches, and wherein generating the first weight value comprises: generating a raw score associated with the first match based on the length associated with the first match or the encoded length associated with the first match, wherein generating the raw score comprises generating a frequency count weight as a function of a first frequency count of the first length and a second frequency count of the first distance; normalizing the raw score to generate a percentile weight based on a maximum of a plurality of raw scores, wherein each raw score of the plurality of raw scores is associated with a corresponding match of the plurality of matches; and generating the first weight value as a function of the percentile weight; and selecting, by the computing device, a selected match from the plurality of matches as a function of the plurality of weight values., 11. The method of claim 10 , wherein generating in parallel the plurality of weight values comprises generating a first weight value associated with a first match of the plurality of matches, and wherein generating the first weight value comprises: determining whether a first distance of the first match is included in a move-to-front stack; replacing the first distance with a corresponding symbol from the move-to-front stack in response to determining that the first distance of the first match is included in the move-to-front stack; and moving the first distance to a front of the move-to front stack in response to determining whether the first distance of the first match is included in the move-to-front stack., 12. The method of claim 10 , wherein generating the raw score comprises generating an extra bit weight as a function of a number of extra bits corresponding to the first distance and a predetermined maximum number of extra bits., 13. The method of claim 10 , wherein generating in parallel the plurality of weight values comprises generating a first weight value associated with a first match of the plurality of matches, and wherein generating the first weight value comprises: generating a plurality of raw scores associated with the first match based on the length associated with the first match and the encoded length associated with the first match; normalizing each of the plurality of raw scores to generate a plurality of percentile weights, wherein each percentile weight is associated with a corresponding raw score; and generating the first weight value as a function of the plurality of percentile weights., 14. The method of claim 13 , wherein generating the first weight value further comprises: determining whether the first match is adjacent to another match of the plurality of matches; and generating the first weight value as a function of an adjacency bonus in response to determining that the first match is adjacent to another match, wherein the adjacency bonus comprises a plurality of percentile weights associated with the other match., 15. One or more computer-readable storage media comprising a plurality of instructions that in response to being executed cause a computing device to: search in parallel a history of an input stream for a plurality of matches, wherein each match comprises a substring of the history that matches the input stream starting at a position based on a corresponding index, and wherein each match is associated with a length and a distance; generate in parallel a plurality of weight values, wherein each weight value is associated with a corresponding match of the plurality of matches, and wherein each weight value is indicative of the length associated with the corresponding match and an encoded length associated with the corresponding match, wherein the encoded length is indicative of a number of bits to encode the corresponding match; wherein to generate in parallel the plurality of weight values comprises to generate a first weight value associated with a first match of the plurality of matches, and wherein to generate the first weight value comprises to: generate a raw score associated with the first match based on the length associated with the first match or the encoded length associated with the first match, wherein to generate the raw score comprises to generate a frequency count weight as a function of a first frequency count of the first length and a second frequency count of the first distance; normalize the raw score to generate a percentile weight based on a maximum of a plurality of raw scores, wherein each raw score of the plurality of raw scores is associated with a corresponding match of the plurality of matches; and generate the first weight value as a function of the percentile weight; and select a selected match from the plurality of matches as a function of the plurality of weight values., 16. The one or more computer-readable storage media of claim 15 , wherein to generate in parallel the plurality of weight values comprises to generate a first weight value associated with a first match of the plurality of matches, and wherein to generate the first weight value comprises to: determine whether a first distance of the first match is included in a move-to-front stack; replace the first distance with a corresponding symbol from the move-to-front stack in response to determining that the first distance of the first match is included in the move-to-front stack; and move the first distance to a front of the move-to front stack in response to determining whether the first distance of the first match is included in the move-to-front stack., 17. The one or more computer-readable storage media of claim 15 , wherein to generate the raw score comprises to generate an extra bit weight as a function of a number of extra bits corresponding to the first distance and a predetermined maximum number of extra bits., 18. The one or more computer-readable storage media of claim 15 , wherein to generate in parallel the plurality of weight values comprises to generate a first weight value associated with a first match of the plurality of matches, and wherein generating the first weight value comprises to: generate a plurality of raw scores associated with the first match based on the length associated with the first match and the encoded length associated with the first match; normalize each of the plurality of raw scores to generate a plurality of percentile weights, wherein each percentile weight is associated with a corresponding raw score; and generate the first weight value as a function of the plurality of percentile weights., 19. The one or more computer-readable storage media of claim 18 , wherein to generate the first weight value further comprises to: determine whether the first match is adjacent to another match of the plurality of matches; and generate the first weight value as a function of an adjacency bonus in response to determining that the first match is adjacent to another match, wherein the adjacency bonus comprises a plurality of percentile weights associated with the other match.\n",
            "Similarity Score: 0.5614\n",
            "\n",
            "\n",
            "Patent ID: 10606787\n",
            "PubMed Claim: 1. A system comprising: a processor; and a rank of state machine engines, wherein the state machine engines of the rank are coupled together by an inter-rank bus, and wherein the rank of state machine engines is configurable to be one logical group, and wherein the rank of state machine engines is also configurable to be multiple logical groups., 2. The system of claim 1 , wherein the processor is configured to assign a number to each state machine engine of the rank., 3. The system of claim 1 , wherein the rank of state machine engines comprises a module including the rank., 4. The system of claim 3 , wherein the processor is configured to assign the number during initialization of the module., 5. The system of claim 1 , wherein the processor is configured to provide data to a particular state machine engine of the rank to configure the particular state machine engine as a master device., 6. The system of claim 5 , wherein the master device is configured to coordinate synchronization of the state machine engines of the rank., 7. The system of claim 1 , wherein the processor is configured to provide data to each state machine engine of the rank to indicate a total number of state machine engines that are part of the rank., 8. The system of claim 1 , wherein the processor is configured to provide data to each state machine engine of the rank to indicate a logical group to which the respective state machine engine belongs., 9. The system of claim 1 , wherein the processor is configured to provide data to each state machine engine of the rank to indicate a number of logical groups that are part of the rank., 10. The system of claim 1 , wherein the inter-rank bus enables each state machine engine of the rank to analyze all bytes of data collectively received for analysis by the state machine engines of the rank when the rank is configured as one logical group., 11. The system of claim 10 , wherein each of the state machine engines of the rank is configured to process an entire data stream received for analysis by the rank., 12. The system of claim 1 , wherein the inter-rank bus enables each state machine engine of the rank to receive an assigned portion of a data stream to be analyzed when the rank is configured as multiple logical groups., 13. The system of claim 12 , wherein the system implements a data-slicing scheme to assign the portions of the data stream to the state machine engines., 14. The system of claim 12 , wherein the processor is configured to sequentially provide data intended for each logical group of the multiple logical groups and wherein the state machine engines of the rank store the data in an offset manner., 15. The system of claim 1 , wherein the state machine engines of the rank are coupled to data lines of the processor., 16. The system of claim 1 , wherein the inter-rank bus is configured to allow data to be exchanged between the state machine engines of the rank., 17. A system comprising: a processor; and a plurality of state machine engines, wherein the plurality of state machine engines is configurable to be one logical group., 18. The system of claim 17 , wherein each of the plurality of state machine engines is configured to analyze a same portion of a data stream., 19. The system of claim 18 , wherein the processor is configured to provide the data stream to each of the plurality of state machine engines., 20. The system of claim 18 , wherein each state machine engine includes a data buffer to store the portion of data stream., 21. The system of claim 17 , wherein the plurality of state machine engines comprises eight state machine engines configured to be one logical group., 22. The system of claim 17 , wherein the plurality of state machine engines is configurable to be multiple logical groups., 23. A system comprising: a processor; and a plurality of state machine engines, wherein the plurality of state machine engines is configurable to be multiple logical groups., 24. The system of claim 23 , wherein a first number of the plurality of state machine engines is part of a first logical group, a second number of the plurality of state machine engines is part of a second logical group, and wherein the first and second logical groups are configured to analyze different portions of a data stream., 25. The system of claim 23 , wherein the plurality of state machine engines comprises a first state machine engine and a second state machine engine, wherein the first state machine engine is part of a first logical group, the second state machine engine is part of a second logical group, and at least one of the first logical group and the second logical group comprises a plurality of state machine engines., 26. The system of claim 25 , wherein the first logical group comprises a greater number of state machine engines than the second logical group.\n",
            "Similarity Score: 0.5611\n",
            "\n",
            "\n",
            "Patent ID: 10606743\n",
            "PubMed Claim: 1. An apparatus, comprising: an array of non-volatile memory cells including a plurality of sections each with a plurality of rows; and a controller configured to: move data stored in a first portion of the array in a first particular order based on a first wear leveling algorithm, wherein the first particular order includes moving data from a first row of a first section of the array to a second row of the first section of the array via a first sensing component stripe, wherein the first sensing component stripe is only coupled to rows of the first section of the array; and move data stored in a second portion of the array in a second particular order different than the first particular order based on a second wear leveling algorithm different from the first wear leveling algorithm and move data from a second section of the array to the first row of the first section of the array, via the first sensing component stripe and a second sensing component stripe, to create an open row in the second section of the array for wear leveling., 2. The apparatus of claim 1 , wherein the data stored in the second portion of the array is moved from the second section to the first section prior to the data stored in the first portion of the array being moved again., 3. The apparatus of claim 1 , wherein a first number of sense amplifiers in the first sensing component stripe are activated when moving the data stored in the first portion of the array from the first row to the second row., 4. The apparatus of claim 1 , wherein a first number of sense amplifiers in the first sensing component stripe and a second number of sense amplifiers in the second sensing component stripe are activated when moving the data stored in the second portion of the array from the second section to the first section., 5. The apparatus of claim 1 , wherein the controller is configured to move data stored in a third portion of the array from a third section to the second section in response to data from a particular number of portions of memory cells in the second section being moved within the second section., 6. The apparatus of claim 1 , wherein the controller includes a counter to count a number of times data stored in a plurality of portions of the array is moved between rows within a particular section., 7. The apparatus of claim 1 , wherein the first portion of the array includes a portion of the first row., 8. The apparatus of claim 1 , wherein the first portion of the array includes the first row., 9. The apparatus of claim 1 , wherein the array of non-volatile memory cells is a 3D array., 10. An apparatus, comprising: an array of non-volatile memory cells including a plurality of sections each with a plurality of rows; and a controller configured to: move data stored in a first portion of the array in a first particular order based on a first wear leveling algorithm, wherein the first particular order includes moving the data from a first row of a first section of the array to a second row of the first section of the array via a first sensing component stripe, wherein the first sensing component stripe is only coupled to rows of the first section of the array; and move data stored in a second portion of the array in a second particular order different than the first particular order based on a second wear leveling algorithm different from the first wear leveling algorithm and move data from a second section of the array to the first section of the array, via the first sensing component stripe and a second sensing component stripe, to create an open row in the second section for wear leveling in response to data from each row in the first section being moved within the first section, wherein the second sensing component stripe is only coupled to rows of the second section of the array., 11. The apparatus of claim 10 , wherein the controller is configured to move the data stored in the first portion of the array from the first row to the second row by firing the first row of memory cells., 12. The apparatus of claim 10 , wherein the controller is configured to move the data stored in the first portion of the array from the first row to the second row by sensing and latching the data stored in the first portion in one of a first number of sense amplifiers in the first sensing component stripe., 13. The apparatus of claim 10 , wherein the controller is configured to move the data stored in the first portion of the array from the first row to the second row by firing the second row of memory cells., 14. The apparatus of claim 10 , wherein the controller is configured to move the data stored in the first portion of the array from the first row to the second row by moving the data stored in the first portion of the array from a first number of sense amplifiers in the first sensing component stripe to the second row., 15. An apparatus, comprising: an array of non-volatile memory cells including a plurality of sections each with a plurality of rows; and a controller configured to: move data stored in a first section of the array among a plurality of rows in the first section in a first particular order based on a first wear leveling algorithm via a first sensing component stripe, wherein the first sensing component stripe is only coupled to rows in the first section of the array; move a portion of data stored in a particular row of a second section of the array to the first section of the array, via the first sensing component stripe and a second sensing component stripe, to create an open row in the second section of the array for wear leveling; and move data stored in the second section of the array among a plurality of rows in the second section of the array in a second particular order different than the first particular order based on a second wear leveling algorithm different from the first wear leveling algorithm via the second sensing component stripe, wherein the second sensing component stripe is only coupled to rows in the second section of the array., 16. The apparatus of claim 15 , wherein the controller is configured to move the data stored in the first section of the array of non-volatile memory cells by firing a row of memory cells in the first section., 17. The apparatus of claim 15 , wherein the controller is configured to move the data stored in the first section of the array by sensing and latching the data stored in the first section of the array in a first number of sense amplifiers in the first sensing component stripe., 18. The apparatus of claim 15 , wherein the controller is configured to perform an error correction operation on the portion of data stored in the particular row of the second section of the array when the portion of data stored in the particular row of the second section of the array is moved from the second section to the first section of the array., 19. The apparatus of claim 15 , wherein the controller is configured to move the portion of data stored in the particular row of the second section of the array of non-volatile memory cells by sensing and latching the portion of data stored in the particular row of the second section of the array of non-volatile memory cells in a second number of sense amplifiers in the second sensing component stripe., 20. The apparatus of claim 15 , wherein the controller is configured to move the portion of data stored in the particular row of the second section of the array of non-volatile memory cells by firing a different row of memory cells in the second section of the array of non-volatile memory cells., 21. A method, comprising: moving data stored in a first portion of an array of non-volatile memory cells in a first particular order based on a first wear leveling algorithm, wherein the first particular order includes moving the data from a first row of a first section of the array of non-volatile memory cells to a second row of the first section of the array of non-volatile memory cells via a first sensing component stripe, wherein the first sensing component stripe is only coupled to rows of the first section of the array of non-volatile memory cells; and moving data stored in a second portion of the array of non-volatile memory cells in a second particular order different than the first particular order based on a second wear leveling algorithm different from the first wear leveling algorithm and moving data from a second section of the array of non-volatile memory cells to the first section of the array of non-volatile memory cells, via the first sensing component stripe and a second sensing component stripe, to create an open row in the second section of the array of non-volatile memory cells for wear leveling in response to data from a particular number of portions of memory cells in the first section of the array of non-volatile memory cells being moved within the first section of the array of non-volatile memory cells, wherein the second sensing component stripe is only coupled to rows of the second section of the array of non-volatile memory cells., 22. The method of claim 21 , further comprising moving data stored in a third portion of the array of non-volatile memory cells from a third row of the second section to a fourth row of the second section., 23. The method of claim 21 , further comprising moving the data stored in the second portion of the array from the second section to the first section prior to the data stored in the first portion of the array of non-volatile memory cells being moved again., 24. The method of claim 21 , further comprising activating a first number of sense amplifiers in the first sensing component stripe when moving the data stored in the first portion of the array of non-volatile memory cells from the first row to the second row., 25. The method of claim 21 , further comprising activating a first number of sense amplifiers in the first sensing component stripe and a second number of sense amplifiers in the second sensing component stripe when moving the data stored in the second portion of the array of non-volatile memory cells from the second section to the first section., 26. The method of claim 21 , further comprising moving data stored in a third portion of the array from a third section to the second section in response to data from a particular number of portions of non-volatile memory cells in the second section being moved within the second section., 27. The method of claim 21 , further comprising counting data stored in a plurality of portions of the array of non-volatile memory cells moved between a plurality of rows within a particular section via a counter., 28. A method, comprising: moving data stored in a first section of an array between a plurality of rows in the first section in a first particular order based on a first wear leveling algorithm via a first sensing component stripe, wherein the first sensing component stripe is only coupled to rows in the first section of the array; moving a portion of data stored in a second section of the array to the first section of the array, via the first sensing component stripe and a second sensing component stripe, to create an open row in the second section of the array for wear leveling; and moving data stored in the second section of the array in a second particular order different than the first particular order based on a second wear leveling algorithm different from the first wear leveling algorithm via the second sensing component stripe, wherein the second sensing component stripe is only coupled to rows in the second section of the array., 29. The method of claim 28 , further comprising firing a row of memory cells in the second section to move the portion of data stored in the second section of the array of non-volatile memory cells., 30. The method of claim 28 , further comprising sensing and latching the portion of data stored in the second section of the array of non-volatile memory cells in a first number of sense amplifiers in the first sensing component stripe to move the portion of data., 31. The method of claim 28 , further comprising performing an error correction operation on the data when moving the data between the plurality of rows.\n",
            "Similarity Score: 0.5600\n",
            "\n",
            "\n",
            "Patent ID: 10606816\n",
            "PubMed Claim: 1. A computer-implemented method of sorting data records comprising: generating a plurality of data structures, each of which is associated with a different corresponding record field used to sort the data records, and inserting values of the record fields into the corresponding data structures, the values of the record fields being received in a plurality of streams, each of the plurality of streams corresponding to a different respective record field and including a sequence of chunks, each of the chunks including values of a record field corresponding to the stream including the chunk; inserting values of the record fields into corresponding data structures, the values being inserted such that the values are in an order in the corresponding data structures, the inserting comprising: for each respective value of each chunk of each stream of the plurality of streams, performing: receiving a respective value and an instruction for a respective entry of a respective stream, updating the data structure for the respective stream according to the respective value and the instruction, and generating an instruction for a corresponding entry of a next stream; and emitting a top predetermined number of the sorted data records, the emitting including reading out the inserted values stored in the plurality of data structures, wherein: each of the data structures comprises one or more ordered parts; each inserted value is inserted into a corresponding ordered part of the corresponding data structure, the corresponding ordered part further including a count of occurrences of the value; and each ordered part of a data structure corresponding to a record field having a sort priority immediately below another record field corresponds to a distinct value inserted into an ordered part of the data structure corresponding to the another record field., 2. The computer-implemented method of claim 1 , wherein the generating an instruction is for inserting a value of another field of the same record into an ordered part of a partitioned data structure corresponding to the another field., 3. The computer-implemented method of claim 2 , wherein inserting a value of a record field into the corresponding data structure is an O(log(m)+log(n)) operation, where n is a number of ordered parts of the data structure, and m is a number of elements in the ordered part of the data structure the value is inserted into., 4. The computer-implemented method of claim 1 , further comprising determining a predetermined quantity of the sorted data records., 5. The computer-implemented method of claim 4 , further including: compressing the data records indicated by the data structure based on the count of occurrences of the field values of the corresponding record fields., 6. The computer-implemented method of claim 1 , wherein the data records are compressed, and inserting the values of the record fields further comprises: decompressing selected fields of the data records., 7. The computer-implemented method of claim 1 , wherein the data records include streaming column data from a database table.\n",
            "Similarity Score: 0.5591\n",
            "\n",
            "\n",
            "Patent ID: 10606857\n",
            "PubMed Claim: 1. A method, comprising: populating, by a data intake and query system, an index of a metrics store with a plurality of metrics, each metric including a measure value; receiving, by the data intake and query system, a specified condition related to the plurality of metrics; cataloging, by the data intake and query system, metadata related to the specified condition in an in-memory metrics catalog; receiving, by the data intake and query system, a search query including search criteria; evaluating, by the data intake and query system, the search query by applying the search criteria to the metadata of the metrics catalog to obtain results that satisfy the search criteria; and causing display, on a display device, of the results or data indicative of the results., 2. The method of claim 1 , further comprising: calling, by the data intake and query system, an application programming interface (API) to retrieve metrics data from the metrics store, the metrics data being cataloged in the in-memory metrics catalog., 3. The method of claim 1 , wherein the plurality of metrics are received by the data intake and query system over a computer network from a plurality of remote computer systems., 4. The method of claim 1 , wherein the query is input by a user via a user interface rendered on the display device, and wherein the results or the data indicative of the results is rendered on the user interface., 5. The method of claim 1 , wherein the metrics store is not an in-memory metrics store., 6. The method of claim 1 , wherein the metrics store resides in non-volatile memory, and wherein the results are obtained by retrieving metrics data only from the metrics catalog., 7. The method of claim 1 , wherein the metrics store resides in non-volatile memory, and wherein the results are obtained by retrieving metrics data in the metrics store., 8. The method of claim 1 , wherein at least some of the metadata is user specified metadata., 9. The method of claim 1 , wherein the metadata includes user specified metadata indicative of at least one condition causing the metrics catalog to automatically retrieve metrics data from the metrics store., 10. The method of claim 1 , wherein the metadata includes user specified metadata indicative of a threshold of a measure value, a range of a measure value, or preferred measure value for a metric., 11. The method of claim 1 , wherein the metadata defines a condition related to a metric in the metrics store, and the occurrence of the condition causes the metrics catalog to display an alert on the display device., 12. The method of claim 1 , wherein the search query is input by a user and expressed in a pipelined search language., 13. The method of claim 1 , wherein the index includes a plurality of dimensions, and wherein each of the plurality of dimensions is either a required dimension or an optional dimension, each metric includes a value for each required dimension, and only some of the plurality of metrics include values for some optional dimensions., 14. The method of claim 1 , wherein the index includes a plurality of dimensions, and the plurality of dimensions includes a user specified dimension., 15. The method of claim 1 , wherein each metric has only one measure value, and the measure value is a floating point value., 16. The method of claim 1 , wherein the plurality of metrics are received by the data intake and query system over a computer network from a plurality of remote computer systems, and where each metric is semi-structured data or structured data., 17. The method of claim 1 , wherein the measure value is a utilization of a processor, a temperature of an electronic component, or a voltage reading of an electronic component., 18. The method of claim 1 , wherein the search criteria has a scope including metrics data and non-metrics data, and wherein the results include metrics data and non-metrics data., 19. The method of claim 1 , wherein the metadata includes user specified metadata causing a metric to appear deleted or edited from the metric store., 20. The method of claim 1 , wherein the metadata includes user specified metadata causing a metric to appear with a unit value different from a unit value of the metric in the metric store., 21. The method of claim 1 , wherein the metadata includes user specified metadata indicative of a relationship between two or more metrics of the metrics store., 22. The method of claim 1 , wherein the plurality of metrics are received by the data intake and query system over a computer network from a plurality of remote computer systems., 23. The method of claim 1 , wherein the query is input by a user via a user interface rendered on the display device, and wherein the results or the data indicative of the results is rendered on the user interface., 24. The method of claim 1 , wherein the metrics store is not an in-memory metrics store., 25. The method of claim 1 , wherein the results are obtained by retrieving metrics data only from the metrics catalog., 26. A method, comprising: storing, by a data intake and query system, a plurality of metrics in an index of a metrics store residing in non-volatile memory, the index including a plurality of dimensions and a measure for each metric; receiving, by the data intake and query system, a specified condition related to the plurality of metrics stored in the index of the metrics store; cataloging, by the data intake and query system, metadata related to the specified condition in a metrics catalog residing in volatile memory, wherein some of the metadata is user specified and some of the metadata is derived from the plurality of metrics stored in the metrics store; receiving, by the data intake and query system, a search query including search criteria; evaluating, by the data intake and query system, the search query by applying the search criteria to the metadata of the metrics catalog to obtain results without accessing the plurality of metrics of the metrics store; and displaying, on a display device, the results or data indicative of the results., 27. The method of claim 26 , further comprising: calling, by the data intake and query system, an application programming interface (API) to retrieve metrics data from the metrics store, the metrics data being cataloged in the metrics catalog., 28. The method of claim 26 , wherein the results are obtained by retrieving metrics data from the metrics store., 29. The method of claim 26 , wherein at least some of the metadata is user specified metadata., 30. A data intake and query system, comprising: a processor; and memory containing instructions that, when executed by the electronic device, cause the data intake and query system to: populate an index of a metrics store with a plurality of metrics, each metric including a measure value; receive a specified condition related to the plurality of metrics of the index of the metrics store; catalog metadata related to the specified condition in an in-memory metrics catalog; receive a search query including search criteria; evaluate the search query by applying the search criteria to the metadata of the metrics catalog to obtain results that satisfy the search criteria; and cause the results or data indicative of the results to be displayed on a display device.\n",
            "Similarity Score: 0.5588\n",
            "\n",
            "\n",
            "Patent ID: 10606853\n",
            "PubMed Claim: 1. A method for identifying prospective new clients based upon review of a plurality of current clients, comprising: receiving, from a user of a transactional platform via a computing device, a request for prospective client identification; identifying, by processing circuitry, a plurality of clients associated with the user; identifying, by the processing circuitry for each organization of the plurality of organizations, a plurality of key terms relevant to the respective organization, wherein identifying the plurality of key terms comprises identifying a web site of the respective organization, performing a web scraping operation of the web site to obtain raw data, and identifying, within the raw data, at least a subset of the plurality of key terms by isolating frequently used terms; automatically performing, by the processing circuitry a plurality of Internet searches, each search using different groupings of the plurality of key terms relevant to the plurality of organizations, the plurality of Internet searches resulting in a plurality of web sites; automatically deriving, by the processing circuitry from at least a portion of the plurality of web sites, prospect information for a plurality of prospect organizations, wherein, for each prospect organization, the prospect information comprises a prospect organization name; and causing presentation of the prospect information to a user of a computing device., 2. The method of claim 1 , wherein identifying the plurality of clients comprises accessing, from a user account of the user on the transactional platform, at least a portion of the plurality of current clients of the user., 3. The method of claim 1 , wherein identifying the plurality of clients comprises receiving, from the user via the computing device, identification of at least one desired new client, wherein the identification comprises at least one of an organization name and an organization web site., 4. The method of claim 1 , wherein identifying the plurality of key terms comprises: identifying, within the plurality of key terms, a subset of redundant key terms; and removing redundancies from the subset of redundant key terms., 5. The method of claim 1 , further comprising, after performing the plurality of Internet searches, discarding, by the processing circuitry, a subset of the plurality of web sites based on parsing URL content of the subset of the plurality of web sites., 6. The method of claim 1 , wherein deriving prospect information comprises querying a financial or business research web site to obtain at least one of an address, an industry, a size, and a revenue., 7. The method of claim 1 , further comprising, prior to performing the Internet searches, classifying, by the processing circuitry, the plurality of clients by at least one of size, geographic region, maturity, and industry, wherein performing the plurality of Internet searches comprises performing, for each classification of the plurality of clients, a plurality of classification-targeted Internet searches., 8. The method of claim 7 , wherein identifying the key terms comprises at least one of promoting key terms prevalent to a particular classification and demoting key terms prevalent across classifications., 9. The method of claim 7 , further comprising, prior to presenting the prospect information, automatically classifying, by the processing circuitry, the plurality of prospects by the at least one of the size, the geographic region, the maturity, and the industry., 10. The method of claim 1 , further comprising, prior to presenting the prospect information, automatically removing, by the processing circuitry, redundancies in the plurality of plurality of prospect organizations., 11. The method of claim 10 , wherein automatically removing the redundancies comprises applying a fuzzy name matching technique to identify variances in prospect name within the plurality of prospect organizations., 12. The method of claim 1 , further comprising, prior to presenting the prospect information, automatically cross-referencing, by the processing circuitry, each of the plurality of prospect organizations with a plurality of existing clients within the transactional platform., 13. The method of claim 1 , further comprising, prior to presenting the prospect information, automatically cross-referencing, by the processing circuitry, the plurality of prospect organizations against the plurality of clients to confirm the plurality of key terms identified the plurality of clients., 14. A system of software engines for identifying prospective new clients based upon review of a plurality of current clients, the system of software engines being stored as sets of instructions on at least one processor, the system comprising: an attribute generation engine for determining a plurality of attributes of each of a plurality of current clients of a user of a transactional platform, and categorizing the plurality of current clients by the plurality of attributes; a web scraping engine for identifying, for each of the plurality of current clients, a client web site, and obtaining raw data from each client web site; a key term generation engine for generating, from the raw data from each client web site, a plurality of key terms; a prospect generation engine for identifying a plurality of web sites through conducting Internet search queries using groups of the plurality of key terms, and identifying, from the plurality of web sites, a plurality of prospective clients; a prospect classification engine for determining a plurality of attributes of each of the plurality of prospective clients, categorizing the plurality of prospective clients by the plurality of attributes, and discarding one or more prospects of the plurality of prospective clients based on determining each of the one or more prospects lacks attributes desired by the user; and a graphical user interface engine for presenting the plurality of prospective clients to a user at a computing device., 15. The system of claim 14 , further comprising a client identification engine for confirming the plurality of key terms, when applied by the prospect generation engine, identified each of the plurality of current clients as search results., 16. The system of claim 14 , further comprising a client matching engine for cross-referencing the plurality of prospective clients with registered clients of the transactional platform., 17. The system of claim 14 , further comprising a term refining engine for: receiving, responsive to the plurality of web sites, a set of positive match indications and a set of negative match indications; and refining at least one of the plurality of key terms and weightings used in combining the key terms in constructing search queries., 18. The system of claim 17 , wherein the term refining engine coordinates with a machine learning model for identifying key terms related to potential prospective clients.\n",
            "Similarity Score: 0.5575\n",
            "\n",
            "\n",
            "Patent ID: 10606775\n",
            "PubMed Claim: 1. An apparatus, comprising: a computing tile comprising a processing device and a memory resource, wherein the computing tile is configured to: receive a command to initiate an operation to reduce a size of a block of data from a first size to a second size; responsive to receipt of the command, receive a block of data comprising a plurality of columns of data from a memory device coupled to the apparatus; and responsive to receipt of the block of data, perform an operation on the block of data to extract predetermined data from the block of data by removing at least one column of data from among the plurality of columns of data to reduce a size of the block of data from a first size to a second size., 2. The apparatus of claim 1 , wherein the computing tile is configured to perform the operation on the block of data responsive to receipt of the block of data in the absence of an intervening command., 3. The apparatus of claim 1 , wherein the computing tile is further configured to receive an interrupt message as part of the command to initiate the operation., 4. The apparatus of claim 1 , wherein the computing tile is further configured to cause the reduced size block of data to be transferred to circuitry external to the computing tile., 5. The apparatus of claim 1 , wherein the computing tile further comprises a direct media access (DMA) buffer to receive a subsequent block of data during performance of the operation on the block of data, and wherein the computing tile is configured to perform a subsequent operation on the subsequent block of data to extract predetermined data from the subsequent block of data to reduce a size of the subsequent block of data from a first size to a second size in the absence of receipt of an intervening command to initiate the subsequent operation., 6. The apparatus of claim 5 , wherein the computing tile is configured to cause the reduced size subsequent block of data to be transferred to circuitry external to the computing tile in the absence of receipt of an intervening command by the computing tile., 7. The apparatus of claim 1 , wherein the processing device comprises a reduced instruction set computing device., 8. An apparatus, comprising: a memory resource coupled to the processing device and inbound buffering circuitry; and a processing device coupled to queuing circuitry and outbound buffering circuitry, wherein the processing resource is configured to: receive, via the queuing circuitry, a command to initiate an operation to reduce respective sizes of blocks of data by selectively removing at least one column of data from the blocks of data; cause a first block of data comprising a plurality of columns of data to be loaded into the memory resource from the inbound buffering circuitry; cause the memory resource to perform the operation on the first block of data; cause a second block of data to be loaded into the inbound buffering circuitry; cause the second block of data to be loaded into the memory resource from the inbound buffering circuitry; and responsive to a determination that the operation on the first block of data is complete, cause the memory resource to perform the operation on the second block of data., 9. The apparatus of claim 8 , wherein the processing device is further configured to cause the second block of data to be loaded into the inbound buffering circuitry, loaded into the memory resource, and cause the memory resource to perform the operation on the second block of data in the absence of an additional command separate from the command to initiate the operation., 10. The apparatus of claim 8 , wherein, as part of the operation, the memory resource is configured to: store the first block of data in a first partition of the memory resource; transfer a relevant portion of the first block of data to a second partition of the memory resource; and transfer the data stored in the second partition to the outbound buffering circuitry., 11. The apparatus of claim 8 , wherein the command to initiate the operation includes an interrupt message., 12. The apparatus of claim 8 , wherein the first block of data or the second block of data includes data corresponding to a database, and wherein the operation comprises a filtering operation to extract particular columns of data from the first block of data or the second block of data., 13. The apparatus of claim 8 , wherein the processing device is configured to cause, subsequent to performance of the operation, at least one of a first resultant block of data and a second resultant block of data to be: transferred to the outbound buffering circuitry; and transferred from the outbound buffering circuitry to circuitry external to the apparatus., 14. The apparatus of claim 13 , wherein the processing device is configured to cause the at least one of the first resultant block of data and the second resultant block of data to be: transferred to the outbound buffering circuitry; and transferred from the outbound buffering circuitry to circuitry external to the apparatus in the absence of an additional command separate from the command to initiate the operation., 15. A system, comprising: a plurality of computing tiles each comprising a respective memory resource and a respective reduced instruction set computing (RISC) device, wherein computing tiles among the plurality of computing tiles are configured to: receive respective streams of data comprising a plurality of blocks of data comprising respective columns of data; and perform operations on the blocks of data to remove at least one column of data from the plurality of blocks of data to extract requested portions of the blocks of data by transferring portions of the blocks of data between partitions of the respective memory resources., 16. The system of claim 15 , further comprising a communication subsystem coupled to the plurality of computing tiles, wherein the communication subsystem is configured to provide communications pathways between the plurality of computing tiles to allow a first computing tile among the plurality of computing tiles to access an address space associated with a second computing tile among the plurality of computing tiles., 17. The system of claim 15 , further comprising a controller coupled to the computing tiles, wherein the controller is configured to allocate particular computing tiles among the plurality of computing tiles to perform the operations on the blocks of data., 18. The system of claim 15 , wherein the computing tiles are configured to initiate the operations on the blocks of data in response to receipt of an initiation command, and wherein the computing tiles are configured to receive the respective streams of data and perform the operations on the blocks of data in the absence of a command subsequent to the initiation command., 19. The system of claim 15 , wherein the computing tiles are configured to transfer the blocks of data that include the extracted requested portions of data to circuitry external to the computing tiles in response to completion of the operation to extract the requested data., 20. The system of claim 15 , wherein the computing tiles further comprise respective direct media access (DMA) buffering components configured to: buffer subsequent blocks of data received as part of the respective streams of data while the operations are performed on preceding blocks of data; and cause the subsequent blocks of data to be transferred to the respective memory resources in response to completion of the operations on the preceding blocks of data., 21. A method, comprising: receiving, by a processing device, a command to initiate performance of an operation involving blocks of data comprising respective columns of data stored in a memory device coupled to the processing device; receiving, responsive to the initiation command, a first block of data from the memory device; performing, responsive to receipt of the block of data, a first operation to remove at least one column of data from the respective columns of data corresponding to the first block of data to extract data from the first block of data received from the memory device; receiving a second block of data from the memory device at the processing device while the processing device is performing the first operation; performing, responsive to completion of the first operation and before receiving an additional initiation command, a second operation to remove at least one column of data from the respective columns of data corresponding to the second block of data to extract data from the second block of data received by the processing device., 22. The method of claim 21 , further comprising buffering, by buffer circuitry coupled to the processing device, the second block of data prior to performance of the second operation such that the second block of data is available to processing device to perform the second operation upon completion of the first operation., 23. The method of claim 21 , further comprising: requesting, by the processing device, information stored in an address space of a processing device different than the processing device; transferring the requested information from the processing device different than the processing device to the processing device., 24. The method of claim 21 , wherein performing the first operation and the second operation includes performing the first operation and the second operation within a memory resource coupled to the processing device., 25. The method of claim 21 , further comprising transferring the data extracted from the first block of data to circuitry external to the processing device in response to completion of the operation to extract data from the first block of data., 26. The method of claim 21 , wherein performing the first operation to extract data from the first block of data further comprises: storing the first block of data in a first partition of a memory resource coupled to the processing device; and selectively transferring a portion of data associated with the first block of data to a second partition of the memory device, wherein the portion of data includes the data to be extracted from the block of data., 27. The method of claim 21 , further comprising: generating a logical record corresponding to at least one of the data extracted from the first block of data and the second block of data; and transferring the logical record to circuitry external to the processing device.\n",
            "Similarity Score: 0.5565\n",
            "\n",
            "\n",
            "Patent ID: 10606815\n",
            "PubMed Claim: 1. A computer-implemented method for creating one or more indexes for information retrieval, the method comprising: reading a document having embedded hinting information into a computer memory, the hinting information including one or more tags, wherein the document includes text; identifying, using the hinting information, a unique expression in the text of the document, wherein the hinting information is associated with the unique expression; creating a first set of indexes for the unique expression in the document using a first analysis method, wherein the first analysis method is an n-gram analysis, wherein a size of the n-gram analysis for a particular unique expression is based on a value found in the tag associated with the particular unique expression; creating a second set of indexes for one or more sequences of words in the document using a second analysis method, wherein the second analysis method is a morphological analysis, and wherein the one or more sequences of words include words in the text that are not in the unique expression; and storing the created first and second sets of indexes in the memory for use in information retrieval., 2. The method according to claim 1 , wherein creating the first and second sets of indexes comprises: creating one or more indexes of the second set of indexes using the second analysis method until the hinting information is found in the document; creating, in response to finding hinting information in the document, the first set of indexes for each sequence in the unique expression associated with the found hinting information using the first analysis method instead of the second analysis method; and executing, after the first set of indexes for each sequence is created, the second analysis method instead of the first analysis method to create one or more additional indexes of the second set of indexes., 3. The method according to claim 2 , wherein a switching between the first analysis method and the second analysis method is executed by a preprocessor., 4. The method according to claim 1 , the method further comprising: searching the document for hinting information, wherein: the creating the first set of indexes for the unique expression is performed in response to finding the hinting information, and the creating the second set of indexes for the one or more sequences of words is performed in response to not finding the hinting information., 5. The method according to claim 1 , wherein the hinting information is inserted before and after or only before each unique expression in the document., 6. The method according to claim 1 , wherein the unique expression is identified according to at least one of using an engine for inferring existence of a unique expression, in response to a unique expression being stored in a storage, using a software application, or manually., 7. The method according to claim 1 , wherein the unique expression is selected from a group consisting of a proper noun, an abbreviation, a coined word, a new word, and a word or phrase which is described in a language different from a base language used in the document., 8. The method according to claim 1 , wherein the one or more tags include at least one of a set of a start tag and an end tag, or a tag having information on the number of words or letters or on the number of bytes in a unique expression for which the first analysis method is used., 9. The method according to claim 1 , wherein the hinting information includes information on an attribute of the unique expression, and the first set of indexes for each sequence in the unique expression with which the hinting information is associated is created by executing the first analysis method using the attribute information., 10. The method according to claim 1 , wherein the reading of the document and the creation of the first and second sets of indexes from the document which is now read into memory are repeatedly carried out, and wherein the repetition is carried out according to at least one of a fixed interval, a set time, manually, in response to the document being updated, or in response to generation of a new document having hinting information., 11. The method according to claim 1 , wherein the first analysis method is a method for generating a contiguous sequence of items from the unique expression, and wherein the second analysis method is a method for dividing the text other than the unique expression into a plurality of meaningful units., 12. The method according to claim 1 , wherein the document having embedded hinting information corresponds to an original document, the method further comprising: retrieving the original document from a storage; identifying the unique expression in the original document; embedding the hinting information into the original document, wherein the one or more tags indicate a location of the unique expression in the original document; and storing the original document with the embedded one or more tags as the document having embedded hinting information in the storage., 13. The method according to claim 1 , wherein the document includes text in a first language and text in a second language, wherein the first language is a base language of the document, and wherein the unique expression is the text in the second language., 14. A computer-implemented method for creating one or more indexes for information retrieval, the method comprising: identifying, by a processor and using hinting information embedded in a document that includes text, a unique expression in the text of the document; creating, by the processor, a first set of indexes for the unique expression by performing an n-gram analysis on the unique expression, wherein a size of the n-gram analysis for the unique expression is based on a value found in a tag associated with the unique expression; creating, by the processor, a second set of indexes for one or more sequences of words in the document by performing a morphological analysis on each word in the text in the document other than the unique expression; and storing, by the processor, the first and second sets of indexes for use in information retrieval., 15. The method according to claim 14 , wherein the hinting information includes the tag, wherein the tag is located directly before the unique expression, and wherein the tag includes a first parameter and a second parameter, the first parameter indicating the number of words in the unique expression, and the second parameter indicating the number of words in each index of the first set of indexes., 16. A computer-implemented method for creating one or more indexes for information retrieval, the method comprising: reading a document into a computer memory, wherein the document includes text; analyzing, by a processor, the document to identify one or more tags embedded in the document, each tag being associated with a unique expression found in the text; determining, by the processor and based on the one or more tags, that an n-gram analysis is to be performed to create indexes for each unique expression in the text; creating, by the processor, a first set of indexes for each unique expression by performing the n-gram analysis on each unique expression in the text, wherein a size of the n-gram analysis for a particular unique expression is based on a value found in the tag associated with the particular unique expression; creating, by the processor, a second set of indexes for one or more sequences of words in the document by performing a morphological analysis on each word in the text in the document other than the unique expression; and storing, by the processor, the first and second sets of indexes in the computer memory.\n",
            "Similarity Score: 0.5565\n",
            "\n",
            "\n",
            "Patent ID: 10606760\n",
            "PubMed Claim: 1. A method of writing data to a memory system comprising: receiving, by a memory controller, a sequence of N consecutive logical block addresses (LBAs) and logical sector data for each of the LBAs, from a host; compressing, by the memory controller, the logical sector data; executing, by the memory controller, a first one of a plurality of hash functions on a first LBA among the sequence to generate a first virtual address; determining, by the memory controller, whether the first virtual address is occupied; setting a destination address to the first virtual address when it is determined that the virtual address is not occupied; setting the destination address to a second other virtual address generated from executing a second other one of the hash functions on the first LBA when it is determined that the first virtual address is occupied; storing, the compressed data in a first physical sector of a nonvolatile memory associated with the destination address; updating, by the memory controller, a mapping table to include to include a 1 st entry corresponding to the first LBA and an index of the hash function that generated the destination address, and 2 nd though Nth consecutive entries respectively corresponding to the 2 nd through Nth LBAs each including the index and an offset to the 1 st entry, and where N is at least two., 2. The method of claim 1 , wherein each hash function is configured to generate a different pseudo-random number when operated on a same LBA., 3. The method of claim 1 , further comprising the memory controller storing information in spare region of the first physical sector indicating offsets and lengths of compressed logical sector data for each of the LBAs., 4. The method of claim 1 , further comprising the memory controller updating the entries to indicate that logical sector data associated with each of the LBAs has been compressed., 5. A memory system comprising: a nonvolatile memory device comprising a plurality of physical sectors; a mapping table; and a memory controller including a plurality of hash functions, the memory controller configured to access the physical sectors using the mapping table and the hash functions, wherein the memory controller is configured to receive a sequence of N consecutive logical block addresses (LBAs) from a host and logical sector data for each of the LBAs, compress the logical sector data to generate compressed data, execute a first one of the hash functions on a first logical block address (LBA) among the sequence to generate a first virtual address, determine whether the first virtual address is occupied, set a destination address to the first virtual address when it is determined that the first virtual address is not occupied, set the destination address to a second other virtual address generated from executing a second other one of the hash functions on the first LBA when it is determined that the first virtual address is occupied, and store the compressed data in a first physical sector among the physical sectors that is associated with the destination address, wherein the memory controller updates the mapping table to include a 1 st entry corresponding to the first LBA and an index of the hash function that generated the destination address, and 2 nd though Nth consecutive entries respectively corresponding to the 2 nd through Nth LBAs each including the index and an offset to the 1 st entry, and where N is at least two., 6. The memory system of claim 5 , wherein each hash function is configured to generate a different pseudo-random number when operated on a same LBA., 7. The memory system of claim 5 , wherein the controller is configured to receive an input LBA and a read command from the host, access an entry of the mapping table associated with the input LBA to retrieve an index and an offset, subtract the retrieved offset from the input LBA to generate a result, operate one of the hash functions identified by the retrieved index on the result to generate a third virtual address, and output data of one of the physical sectors associated with the third virtual address to the host., 8. The memory system of claim 5 , wherein the nonvolatile memory is flash memory., 9. The memory system of claim 5 , wherein the controller stores information in a spare region of the first physical sector indicating offsets and lengths of compressed logical sector data for each of the LBAs., 10. The memory system of claim 5 , wherein the controller is configured to update the entries to indicate that logical sector data associated with each of the LBAs has been compressed., 11. The memory system of claim 5 , wherein the controller is configured to receive an input LBA, store logical sector data associated with the input LBA in the memory device without compression in one of the physical sectors when the input LBA is received without at least one additional LBA sequential to the input LBA, and update an entry of the mapping table corresponding to the input LBA to indicate the stored logical sector data is uncompressed., 12. The memory system of claim 5 , wherein the controller stores the compressed data in the first physical sector and a second physical sector among the physical sectors., 13. The memory system of claim 12 , wherein the compressed data includes compressed data for one logical sector that is split across the first and second physical sectors., 14. The memory system of claim 13 , wherein the controller updates the mapping table to indicate that the one logical sector is split., 15. The memory system of claim 5 , further comprising a buffer temporarily storing the sequence of logical block addresses (LBAs) and the corresponding logical sector data., 16. A method of reading data from a memory system comprising: receiving, by a memory controller, a first logical block address (LBA) and a read command from a host; accessing, by the memory controller, an entry of a mapping table associated with the first LBA to retrieve an index and an offset, in response to receipt of the read command; generating, by the memory controller, a second LBA by subtracting the offset from the first LBA; selecting, by the memory controller, a hash function from among a plurality of different hash functions using the index; executing, by the memory controller, the selected hash function on the second LBA to generate a virtual address; and retrieving data from a physical sector of a nonvolatile memory associated with the virtual address, wherein the different hash functions generate a different virtual address when executed on a same value., 17. The method of claim 16 , further comprising: uncompressing, by the memory controller, the retrieved data to generate uncompressed data when the entry indicates a compression has been performed; sending, by the controller, the uncompressed data associated with the LBA to the host when the entry indicates the compression; and sending, by the controller, the retrieved data to the host when the entry indicates no compression has been performed., 18. The method of claim 16 , wherein the retrieving of the data comprises: determining, by the memory controller, an offset and a size of the data in the physical sector from a spare region in the physical sector; and extracting, by the memory controller, data from the physical sector at the offset and having the size.\n",
            "Similarity Score: 0.5559\n",
            "\n",
            "\n",
            "Patent ID: 10606849\n",
            "PubMed Claim: 1. A method of assigning confidence scores to relationship entries in a knowledge graph, comprising: assigning, using a data processing system, respective initial confidence scores to relationship n-tuples in a knowledge graph (KG), wherein each of the relationship n-tuples designates at least a first entity, a second entity, and a relationship between the first and second entities or a single entity and a relationship between the single entity and one or more properties of the single entity; associating, using the data processing system, respective feature vectors with each of the relationship n-tuples, wherein the feature vectors are encoded with values representing a technology used to extract the first and second entities from data and a source that provided the data; generating, using the data processing system, a training set that includes at least a subset of the relationship n-tuples labeled with respective ground truth labels; learning, using the data processing system, respective initial weights for the feature vectors based on the training set; and generating, using the data processing system, respective subsequent confidence scores for each of the relationship n-tuples based on the initial weights for the feature vectors., 2. The method of claim 1 , wherein the method further comprises: extracting the relationship n-tuples from the data; and populating the KG with the extracted relationship n-tuples., 3. The method of claim 1 , wherein the features vectors have associated dynamic features and associated static features and the method further comprises: determining that one or more of the dynamic features associated with one or more of the feature vectors has changed; in response to determining that one or more of the dynamic features associated with one or more of the feature vectors has changed, learning respective new weights for the feature vectors; and generating respective new confidence scores for each of the relationship n-tuples based on the new weights for the feature vectors., 4. The method of claim 3 , wherein the dynamic features include one or more of a ��klout�� score and a ��click , 5. The method of claim 1 , wherein the method further comprises: determining that one or more new relationship n-tuples should be promoted to the training set; modifying the training set to include the new relationship n-tuples; learning respective new weights for the feature vectors based on the modified training set; and generating respective new confidence scores for each of the relationship n-tuples based on the new weights for the feature vectors., 6. The method of claim 5 , wherein the new relationship n-tuples are selected for promotion to the training set based on a confidence score and a robustness of the new relationship n-tuples., 7. The method of claim 6 , wherein the new relationship n-tuples that are automatically added to the training set are weighted differently than the new relationship n-tuples that are not automatically added to the training set., 8. A computer program product configured to assign confidence scores to relationship entries in a knowledge graph, the computer program product comprising: a computer-readable storage device; and computer-readable program code embodied on the computer-readable storage device, wherein the computer-readable program code, when executed by a data processing system, causes the data processing system to: assign respective initial confidence scores to relationship n-tuples in a knowledge graph (KG), wherein each of the relationship n-tuples designates at least a first entity, a second entity, and a relationship between the first and second entities or a single entity and a relationship between the single entity and one or more properties of the single entity; associate respective feature vectors with each of the relationship n-tuples, wherein the feature vectors are encoded with values representing a technology used to extract the first and second entities from data and a source that provided the data; generate a training set that includes at least a subset of the relationship n-tuples labeled with respective ground truth labels; learn respective initial weights for the feature vectors based on the training set; and generate respective subsequent confidence scores for each of the relationship n-tuples based on the initial weights for the feature vectors., 9. The computer program product of claim 8 , wherein the computer-readable program code, when executed by the data processing system, further causes the data processing system to: extract the relationship n-tuples from the data; and populate the KG with the extracted relationship n-tuples., 10. The computer program product of claim 8 , wherein the features vectors have associated dynamic features and associated static features and the computer-readable program code, when executed by the data processing system, further causes the data processing system to: determine that one or more of the dynamic features associated with one or more of the feature vectors has changed; in response to determining that one or more of the dynamic features associated with one or more of the feature vectors has changed, learn respective new weights for the feature vectors; and generate respective new confidence scores for each of the relationship n-tuples based on the new weights for the feature vectors., 11. The computer program product of claim 10 , wherein the dynamic features include one or more of a ��klout�� score and a ��click , 12. The computer program product of claim 8 , wherein the computer-readable program code, when executed by the data processing system, further causes the data processing system to: determine that one or more new relationship n-tuples should be promoted to the training set; modify the training set to include the new relationship n-tuples; learn respective new weights for the feature vectors based on the modified training set; and generate respective new confidence scores for each of the relationship n-tuples based on the new weights for the feature vectors., 13. The computer program product of claim 12 , wherein the new relationship n-tuples are selected for promotion to the training set based on a confidence score and a robustness of the new relationship n-tuples., 14. The computer program product of claim 13 , wherein the new relationship n-tuples that are automatically added to the training set are weighted differently than the new relationship n-tuples that are not automatically added to the training set., 15. A data processing system, comprising: a cache memory; and a processor coupled to the cache memory, wherein the processor is configured to: assign respective initial confidence scores to relationship n-tuples in a knowledge graph (KG), wherein each of the relationship n-tuples designates at least a first entity, a second entity, and a relationship between the first and second entities or a single entity and a relationship between the single entity and one or more properties of the single entity; associate respective feature vectors with each of the relationship n-tuples, wherein the feature vectors are encoded with values representing a technology used to extract the first and second entities from data and a source that provided the data; generate a training set that includes at least a subset of the relationship n-tuples labeled with respective ground truth labels; learn respective initial weights for the feature vectors based on the training set; and generate respective subsequent confidence scores for each of the relationship n-tuples based on the initial weights for the feature vectors., 16. The data processing system of claim 15 , wherein the processor is further configured to: extract the relationship n-tuples from the data; and populate the KG with the extracted relationship n-tuples., 17. The data processing system of claim 15 , wherein the features vectors have associated dynamic features and associated static features and the processor is further configured to: determine that one or more of the dynamic features associated with one or more of the feature vectors has changed; in response to determining that one or more of the dynamic features associated with one or more of the feature vectors has changed, learn respective new weights for the feature vectors; and generate respective new confidence scores for each of the relationship n-tuples based on the new weights for the feature vectors., 18. The data processing system of claim 17 , wherein the dynamic features include one or more of a ��klout�� score and a ��click , 19. The data processing system of claim 15 , wherein the processor is further configured to: determine that one or more new relationship n-tuples should be promoted to the training set; modify the training set to include the new relationship n-tuples; learn respective new weights for the feature vectors based on the modified training set; and generate respective new confidence scores for each of the relationship n-tuples based on the new weights for the feature vectors., 20. The data processing system of claim 19 , wherein the new relationship n-tuples are selected for promotion to the training set based on a confidence score and a robustness of the new relationship n-tuples, and wherein the new relationship n-tuples that are automatically added to the training set are weighted differently than the new relationship n-tuples that are not automatically added to the training set.\n",
            "Similarity Score: 0.5527\n",
            "\n",
            "\n",
            "Patent ID: 10606960\n",
            "PubMed Claim: 1. A method comprising: receiving, by a networked system, a first language construct transmitted from a device of a first entity that is directed to a second entity; identifying, by the networked system, a construct identifier corresponding to the first language construct; determining, by the networked system, a language preference of the second entity, the language preference corresponding to a language identifier of a second language; retrieving, by the networked system, a second language construct from a translated construct table by locating a row in the translated construct table that contains the construct identifier, the language identifier corresponding to the language preference of the second entity, and the second language construct, the second language construct being a translation of the first language construct into the second language corresponding to the language preference; using the second language construct to update information associated with the first entity; and transmitting the updated information to a device of the second entity., 2. The method of claim 1 , wherein the determining the language preference of the second entity comprises accessing stored user information of the second entity and identifying the language preference from the stored user information., 3. The method of claim 1 , wherein: the second entity is a website associated with the networked system; and the using the second language construct to update information associated with the first entity comprises using the second language construct to generate or update a listing for the first entity., 4. The method of claim 1 , wherein: the second entity is a website associated with the networked system; and the using the second language construct to update information associated with the first entity comprises using the second language construct to update user information for the first entity with the website., 5. The method of claim 1 , wherein identifying the construct identifier corresponding to the first language construct comprises: accessing a construct table, the construct table comprising a construct identifier field to store a unique identifier for each stored language construct and a construct field to store each language construct; locating the first language construct in the construct table; and retrieving, from the construct table, the construct identifier corresponding to the first language construct., 6. The method of claim 1 , wherein the using the second language construct to update information associated with the first entity comprises using the second language construct to generate a translated communication that is transmitted to the device of the second entity., 7. The method of claim 1 , wherein the translated construct table comprises a plurality of rows for a same first language construct, each of the plurality of rows for the same first language construct having a different language identifier and a different second language construct., 8. A hardware storage device storing instructions which, when executed by at least one hardware processor of a machine, cause the machine to perform operations comprising: receiving a first language construct transmitted from a device of a first entity that is directed to a second entity; identifying a construct identifier corresponding to the first language construct; determining a language preference of the second entity, the language preference corresponding to a language identifier of a second language; retrieving a second language construct from a translated construct table by locating a row in the translated construct table that contains the construct identifier, the language identifier corresponding to the language preference of the second entity, and the second language construct, the second language construct being a translation of the first language construct into the second language corresponding to the language preference; using the second language construct to update information associated with the first entity; and transmitting the updated information to a device of the second entity., 9. The hardware storage device of claim 8 , wherein the determining the language preference of the second entity comprises accessing stored user information of the second entity and identifying the language preference from the stored user information., 10. The hardware storage device of claim 8 , wherein: the second entity is a website; and the using the second language construct to update information associated with the first entity comprises using the second language construct to generate a listing for the first entity., 11. The hardware storage device of claim 8 , wherein: the second entity is a website; and the using the second language construct to update information associated with the first entity comprises using the second language construct to update user information for the first entity with the website., 12. The hardware storage device of claim 8 , wherein: the second entity is a website; and the using the second language construct to update information associated with the first entity comprises using the second language construct to update a listing for the first entity., 13. The hardware storage device of claim 8 , wherein the using the second language construct to update information associated with the first entity comprises using the second language construct to generate a translated communication that is transmitted to the device of the second entity., 14. The hardware storage device of claim 8 , wherein the operations further comprise: searching a user table for the second entity; and identifying a language identifier for the second entity from the user table, the language identifier corresponding to the language preference stored in the user table for the second entity., 15. A system comprising: one or more hardware processors; and a hardware storage device comprising instructions that when executed by the one or more hardware processors, cause the one or more hardware processors to perform operations comprising: receiving a first language construct transmitted from a device of a first entity that is directed to a second entity; identifying a construct identifier corresponding to the first language construct; determining a language preference of the second entity, the language preference corresponding to a language identifier of a second language; retrieving a second language construct from a translated construct table by locating a row in the translated construct table that contains the construct identifier, the language identifier corresponding to the language preference of the second entity, and the second language construct, the second language construct being a translation of the first language construct into the second language corresponding to the language preference; using the second language construct to update information associated with the first entity; and transmitting the updated information to a device of the second entity., 16. The system of claim 15 , wherein the determining the language preference of the second entity comprises accessing stored user information of the second entity and identifying the language preference from the stored user information., 17. The system of claim 15 , wherein: the second entity is a website; and the using the second language construct to update information associated with the first entity comprises using the second language construct to generate or update a listing for the first entity., 18. The system of claim 15 , wherein: the second entity is a website; and the using the second language construct to update information associated with the first entity comprises using the second language construct to update user information for the first entity with the web site., 19. The system of claim 15 , wherein the using the second language construct to update information associated with the first entity comprises using the second language construct to generate a translated communication that is transmitted to the device of the second entity., 20. The method of claim 1 , wherein the second entity is the networked system and the device of the second entity is a server of the networked system.\n",
            "Similarity Score: 0.5512\n",
            "\n",
            "\n",
            "Patent ID: 10607004\n",
            "PubMed Claim: 1. A computer-implemented method to apply pattern engineering with metadata-driven unit operations to improve an efficiency of analysis of log files having different file formats, the computer-implemented method comprising: determining, by executing an instruction with a processor, a first file format of a log file from the different file formats, the log file to be converted to a vector output file; generating, by executing an instruction with the processor, a first sequence of processing tasks based on the first file format, the first sequence including a first metadata tag corresponding to a conversion task to convert the first file format to a string format, the log file including pattern occurrence data; generating, by executing an instruction with the processor, a second metadata tag within the first sequence of processing tasks, the second metadata tag associated with a second processing task to identify respective features from the pattern occurrence data by comparing the string to a pattern corresponding to malware; generating, by executing an instruction with the processor, a third metadata tag within the first sequence of processing tasks, the third metadata tag associated with a third processing task to create the vector output file of the respective features from the pattern occurrence data identified by the second metadata tag; and executing, by executing an instruction with the processor, the first sequence of the first metadata tag, the second metadata tag, and the third metadata tag to create the vector output file associated with the first file format., 2. The computer-implemented method as defined in claim 1 , wherein the first metadata tag includes parsing operations of the log file for at least one of a text file format, a comma separated value (CSV) file format, a JavaScript Object Notation (JSON) file format, or a binary file format., 3. The computer-implemented method as defined in claim 1 , further including building a dictionary of feature nomenclature associated with the respective features from the pattern occurrence data., 4. The computer-implemented method as defined in claim 3 , further including generating search substrings of the feature nomenclature., 5. The computer-implemented method as defined in claim 4 , wherein the second metadata tag identifies at least one of the search substrings as feature occurrence instances., 6. The computer-implemented method as defined in claim 1 , further including executing a second sequence of the first metadata tag, a fourth metadata tag, and a fifth metadata tag to create a second vector output file associated with the first file format., 7. The computer-implemented method as defined in claim 6 , wherein the second metadata tag is to invoke a dictionary to identify feature occurrence instances, and the fourth metadata tag is to invoke regular expressions to identify feature occurrence instances., 8. An apparatus to apply pattern engineering with metadata-driven metadata tags to improve an efficiency of analysis of log files having different file formats, the apparatus comprising: a log file retriever to: retrieve a log file in a first log file format, the log file including pattern occurrence data; and determine a first file format of the log file from the different file formats, the log file to be converted to a vector output file; a file to string operation builder to generate a first metadata tag of a first sequence of processing tasks that is based on the first file format, the first metadata tag corresponding to a conversion task to convert the first file format to a string format; an extraction operation builder to generate a second metadata tag within the first sequence of processing tasks, the second metadata tag associated with a second processing task to identify respective features from the pattern occurrence data by comparing the string to a pattern corresponding to malware; a feature save operation builder to generate a third metadata tag within the first sequence of processing tasks, the third metadata tag associated with a third processing task to save the vector output file; and an operation flow builder to: generate the first sequence of processing tasks, the first sequence including the first metadata tag, the second metadata tag, and the third metadata tag to create the vector output file of the respective features from the pattern occurrence data identified by the second metadata tag; and execute the first sequence of the first metadata tag, the second metadata tag, and the third metadata tag to create the vector output file associated with the first file format., 9. The apparatus as defined in claim 8 , wherein the file to string operation builder is to generate parsing operations of the log file for at least one of a text file format, a comma separated value (CSV) file format, a JavaScript Object Notation (JSON) file format, or a binary file format., 10. The apparatus as defined in claim 8 , further including a dictionary editor to build a dictionary of feature nomenclature associated with the respective features from the pattern occurrence data., 11. The apparatus as defined in claim 8 , further including a dictionary editor to facilitate extraction of feature instances based on at least one of dictionary matching or regular expression strings., 12. The apparatus as defined in claim 8 , further including a dictionary editor to normalize one or more search substrings to identify feature nomenclature based on a dictionary association., 13. The apparatus as defined in claim 8 , further including a hashing operation builder to hash the respective features to a unique integer value., 14. The apparatus as defined in claim 8 , further including a formatting operation builder to format the vector output file based on a Library for Support Vector Machines (LIBSVM) classification format., 15. A tangible computer readable storage medium comprising computer readable instructions to improve an efficiency of analysis of log files having different file formats, the instructions which, when executed, cause a processor to at least: determine a first file format of a log file from the different file formats, the log file to be converted to a vector output file; generate a first sequence of processing tasks based on the first file format, the first sequence including a first metadata tag corresponding to a conversion task to convert the first file format to a string format, the log file including pattern occurrence data; generate a second metadata tag within the first sequence of processing tasks, the second metadata tag associated with a second processing task to identify respective features from the pattern occurrence data by comparing the string to a pattern corresponding to malware; generate a third metadata tag within the first sequence of processing tasks, the third metadata tag associated with a third processing task to create the vector output file of the respective features from the pattern occurrence data identified by the second metadata tag; and execute the first sequence of the first metadata tag, the second metadata tag, and the third metadata tag to create the vector output file associated with the first file format., 16. The tangible computer readable storage medium of claim 15 , wherein the instructions, when executed, cause the processor to generate parsing operations of the log file for at least one of a text file format, a comma separated value (CSV) file format, a JavaScript Object Notation (JSON) file format, or a binary file format., 17. The tangible computer readable storage medium of claim 15 , wherein the instructions, when executed, cause the processor to build a dictionary of feature nomenclature associated with the respective features from the pattern occurrence data., 18. The tangible computer readable storage medium of claim 17 , wherein the instructions, when executed, cause the processor to generate search substrings of the feature nomenclature., 19. The tangible computer readable storage medium of claim 18 , wherein the instructions, when executed, cause the processor to identify, by executing the second processing task associated with the second metadata tag, the search substrings as feature occurrence instances., 20. The tangible computer readable storage medium of claim 15 , wherein the instructions, when executed, cause the processor to execute a second sequence of the first metadata tag, a fourth metadata tag, and a fifth metadata tag to create a second vector output file associated with the first file format.\n",
            "Similarity Score: 0.5501\n",
            "\n",
            "\n",
            "Patent ID: 10606845\n",
            "PubMed Claim: 1. A method, comprising: detecting, by a device comprising a processor, leading events of an application based on historical ranking information, wherein the leading events are the time segments during which the application remains in at least a predefined high ranking in an application leaderboard, and a standard for at least the predefined high ranking is that a ranking of the application in the application leaderboard is not greater than a ranking threshold K*, and the detecting the leading events of the application comprises: identifying start times of the leading events and adjacent end times of the leading events that are adjacent to the start times, wherein the leading events are separately formed by connecting ranking points during a leading even, and based on a result of searching for rankings of the application at time points represented in the historical ranking information, identifying time segments between the start times and the adjacent end times as corresponding to the leading events, wherein the historical ranking information comprises a ranking index corresponding to a discrete date index, and wherein each element in the ranking index corresponds to a discrete time point in the discrete date index, and represents a ranking of the application when the application is at the discrete time point; in response to a time interval of two adjacent leading events of the adjacent leading events being determined to be less than an interval threshold, combining adjacent leading events of the leading events to form leading sessions of the application, wherein the adjacent leading events comprise at least two consecutive time segments of the time segments; and sending the leading session of the application to at least one of at least one device of an application developer, an operator of an application store or an application user., 2. The method of claim 1 , further comprising: setting the ranking threshold K*., 3. The method of claim 1 , wherein a value of the ranking threshold K* is in a range of integers between 1 and 500., 4. The method of claim 1 , further comprising: setting the interval threshold., 5. The method of claim 1 , wherein a value of the interval threshold is in a range of 2 to 10 times of an update cycle of the application leaderboard., 6. The method of claim 1 , wherein if a first ranking of the application at a first time point in the historical ranking information is not greater than the ranking threshold K*, identifying the first time point as a start time; and if a second ranking of the application at a last time point in the historical ranking information is not greater than the ranking threshold K*, identifying the last time point as an adjacent end time of the adjacent end times., 7. The method of claim 1 , wherein the combining the adjacent leading events of the leading events to form the leading sessions of the application comprises: searching, in an order of the adjacent leading events, for a detected leading event starting from an initial time point of the historical ranking information in; and when a time interval between a current leading event and a previous leading event is less than an interval threshold, combining the current leading event and the previous leading event in a same leading session until the searching for the detected leading event is completed., 8. The method of claim 7 , wherein the combining the adjacent leading events of the leading events to form the leading sessions of the application further comprises: when the time interval between the current leading event and the previous leading event is not less than the interval threshold, and another time interval between the current leading event and a next leading event is not less than the interval threshold, detecting the detected leading event as a leading session of the leading sessions., 9. The method of claim 1 , wherein the time segments are first time segments, and wherein the historical ranking information comprises information about ratings on the application by users of the application in second time segments in the history., 10. The method of claim 1 , further comprising: obtaining the historical ranking information of the application in an application leaderboard., 11. The method of claim 10 , wherein the obtaining the historical ranking information comprises at least one of obtaining the historical ranking information from a device of an operator of an application store or extracting the historical ranking information from data received from the application store., 12. The method of claim 1 , further comprising: when a first ranking at a current time point is not greater than a ranking threshold K* and a second ranking of the rankings at a previous time point is greater than the ranking threshold K*, identifying the current time point as a start time of the leading event of the start times of the leading events; and when a first ranking at a current time point is greater than the ranking threshold K* and a second ranking of the rankings at a previous time point is not greater than the ranking threshold K*, identifying the previous time point as an adjacent end time of the adjacent end times., 13. A system, comprising: a memory that stores executable units; and a processor, coupled to the memory, that executes the executable units to perform operations of the system, the executable units comprising: a leading event detection unit configured to detect leading events of an application based on historical ranking information, wherein the leading events are the time segments during which the application remains in at least a predefined high ranking in an application leaderboard, and a standard for at least the predefined high ranking is that a ranking of the application in the application leaderboard is not greater than a ranking threshold K*, and the leading event detection unit comprises: a start time identification module configured to identify start times of the leading events, an end time identification module configured to identify adjacent end times of the leading events, which are adjacent to the start times, wherein the leading events are separately formed by connecting ranking points during a leading event, and a leading event identification module configured to, based on a result of searching for rankings of the application at time points represented in the historical ranking information, identify time segments between the start times and the adjacent end times as the leading events, wherein the historical ranking information comprises a ranking index corresponding to a discrete date index, and wherein each element in the ranking index corresponds to a discrete time point in the discrete date index, and represents a ranking of the application when the application is at the discrete time point; a leading session detection unit configured to, in response to a time interval of two adjacent leading events of the adjacent leading events being determined to be less than an interval threshold, combine adjacent leading events of the leading events to form a leading session of the application, wherein the adjacent leading events comprise at least two consecutive time segments of the time segments; and a leading session sending unit configured to send the leading session of the application to at least one of at least one device of an application developer, an operator of an application store or an application user., 14. The system of claim 13 , wherein the executable units further comprise a ranking threshold setting unit configured to set the ranking threshold K*., 15. The system of claim 13 , wherein a standard for combining the adjacent leading events in a same leading session is that a time interval of the adjacent leading events is less than an interval threshold., 16. The system of claim 15 , wherein the executable units further comprise an interval threshold setting unit configured to set the interval threshold., 17. The system of claim 13 , wherein the start time identification module is further configured to identify a first time point as a start time of the start times if a first ranking of the application at the first time point in the historical ranking information is not greater than a ranking threshold; and the end time identification module is further configured to identify a last time point as an adjacent end time of the adjacent end times if a last ranking of the application at the last time point in the historical ranking information is not greater than the ranking threshold., 18. The system of claim 13 , wherein the leading session detection unit is further configured to: search, in time order, for the leading events starting from an initial time point of the historical ranking information; and when a time interval between a current leading event and a previous leading event is less than an interval threshold, combine the adjacent leading events in a same leading session until the search for the leading events is completed., 19. The system of claim 18 , wherein the leading session detection unit is configured to detect a leading event of the leading events as the leading session when a first time interval between the leading event and the previous leading event is not less than the interval threshold, and a second time interval between the leading event and a next leading event is not less than the interval threshold., 20. The system of claim 13 , wherein the executable units further comprise a historical ranking information obtaining unit configured to obtain the historical ranking information of the application in an application leaderboard., 21. The system of claim 20 , wherein the historical ranking information obtaining unit is configured to at least one of obtain the historical ranking information from a device of an operator of an application store or extract the historical ranking information from data published by the application store., 22. The system of claim 13 , wherein when a first ranking at a current time point is not greater than the ranking threshold K* and a second ranking of the rankings at a previous time point is greater than a ranking threshold K*, the start time identification module is further configured to identify the current time point as a start time of the leading event of the start times of the leading events; and when a first ranking at a current time point is greater than the ranking threshold K* and a second ranking of the rankings at a previous time point is not greater than the ranking threshold K*, the end time identification module is further configured to identify the previous time point as an adjacent end time of the adjacent end times., 23. The system of claim 13 , wherein a value of the interval threshold is in a range of 2 to 10 times of an update cycle of the application leaderboard., 24. A non-transitory computer readable storage device, comprising at least one executable instruction, which, in response to execution, causes a system comprising a processor to perform operations, comprising: detecting leading events of an application based on historical ranking information, wherein the leading events are the time segments during which the application remains in at least a predefined high ranking in an application leaderboard, and a standard for at least the predefined high ranking is that a ranking of the application in the application leaderboard is not greater than a ranking threshold K*, and the detecting the leading events of the application comprises: identifying start times of the leading events and adjacent end times of the leading events, wherein the adjacent end times are adjacent to the start times, wherein the leading events are separately formed by connecting ranking points during a leading event, and based on a result of searching for rankings of the application at time points represented in the historical ranking information, identifying time segments between the start times and the adjacent end times as the leading events, wherein the historical ranking information comprises a ranking index corresponding to a discrete date index, and wherein each element in the ranking index corresponds to a discrete time point in the discrete date index, and represents a ranking of the application when the application is at the discrete time point; combining adjacent leading events of the leading events to form leading sessions of the application, wherein the adjacent leading events comprise at least two consecutive time segments of the time segments, and sending the leading session of the application to at least one of at least one device of an application developer, an operator of an application store or an application user., 25. The non-transitory computer readable storage device of claim 24 , wherein the operations further comprise: setting the ranking threshold K*., 26. The non-transitory computer readable storage device of claim 25 , wherein a value of the ranking threshold K* is in a range of integers between 1 and 500., 27. The non-transitory computer readable storage device of claim 24 , wherein the operations further comprise: in response to a time interval of two adjacent leading events of the adjacent leading events being determined to be less than an interval threshold, combining the two adjacent leading events in a same leading session., 28. The non-transitory computer readable storage device of claim 24 , wherein the operations further comprise: setting the interval threshold., 29. The non-transitory computer readable storage device of claim 24 , wherein a value of the interval threshold is in a range of 2 to 10 times of an update cycle of the application leaderboard., 30. The non-transitory computer readable storage device of claim 24 , wherein the time segments are first time segments, and wherein the historical ranking information comprises information about ratings on the application by users of the application in second time segments in the history., 31. The non-transitory computer readable storage device of claim 24 , wherein the operations further comprise: obtaining the historical ranking information of the application in an application leaderboard., 32. The non-transitory computer readable storage device of claim 31 , wherein the obtaining the historical ranking information comprises at least one of obtaining the historical ranking information from a device of an operator of an application store or extracting the historical ranking information from data received from the application store.\n",
            "Similarity Score: 0.5481\n",
            "\n",
            "\n",
            "Patent ID: 10606983\n",
            "PubMed Claim: 1. A system, comprising: a central database having a hierarchical access control based on a category of user, the category of user being selected from the group consisting of member/enrollee, provider, management, coder, and auditor, the central database storing medical records for each of a plurality of patients in a patient population, and structured to filter out all incoming updates to the central databases except those corresponding to one of the plurality of individuals; a computer running a plurality of applications, including a program for creating an individual profile, wherein the individual profile for each of the plurality of patients is stored in the central database; and a server for providing a remote computer with access to the central database via a web-based application, the web-based application performing operations comprising: generating a plurality of graphical user interfaces dynamically created by the program for viewing information from the central database and providing users with a capability to derive information at a specified level; wherein a first graphical user interface of the plurality of graphical user interfaces displays a dashboard for displaying information on the patient population with review capabilities as to services provided to patients within the patient population, wherein the dashboard includes a navigation menu with a plurality of navigation elements, the plurality of navigation elements including Summary, Review by Plan, Review By Primary Care Physician (PCP), Review by Category, Evaluations, Prevalence, Record Upload, and Reports Library, wherein, under Review by Plan, a plurality of reports by PCP are selectable; wherein a second graphical user interface of the plurality of graphical user interfaces displays information providing Risk Adjusted Factor (RAF) comparative analysis by plan for the Current Year (CY) active or termed members to provide users an overall RAF score for the same membership between two years; wherein a third graphical user interface of the plurality of graphical user interfaces displays a member summary page; wherein a fourth graphical user interface of the plurality of graphical user interfaces displays information on claims, medication refills, provider, designated specialty of said provider, and date of services rendered; wherein a fifth graphical user interface of the plurality of graphical user interfaces displays a screen for displaying diagnostic information for a specific patient from among the plurality of patients, the diagnostic information including one or more diagnostic codes and a diagnosis description corresponding to each of the one or more diagnostic codes. wherein the operations further comprise: displaying, on the screen, one or more data entry fields by which an additional diagnostic code may be added to the medical records stored for the specific patient in the central database; applying a plurality of code edits to prevent the addition of inappropriate diagnostic codes using the web-based application; and, for each additional diagnostic code added using the web-based application, tracking a page number of the medical records stored for the specific patient in the central database; wherein a sixth graphical user interface of the plurality of graphical user interfaces displays information on objective quality measures as represented in a Centers for Medicare and Medicaid Services (CMS) star ratings program format; wherein a seventh graphical user interface of the plurality of graphical user displays information of a monthly trend report tracking historical compliance scores for each objective quality measure; and wherein an eighth graphical user interface of the plurality of graphical user interfaces displays information specific to a patient of the patient population regarding specific quality measures that have been met or not met, and providing for supplemental data or exclusions that may apply to said patient for the specific quality measure., 2. The system of claim 1 , wherein the diagnostic information further includes a hierarchical condition category (HCC) corresponding to each of the one or more diagnostic codes., 3. The system of claim 1 , wherein the operations further comprise displaying, on the screen, a comment input tool by which a user of the web-based application may add comments to the medical records stored for the specific patient in the central database., 4. The system of claim 3 , wherein the comment input tool includes a plurality of selectable prewritten comments., 5. The system of claim 4 , wherein the comment input tool further includes a text field for adding a comment other than the selectable prewritten comments.\n",
            "Similarity Score: 0.5480\n",
            "\n",
            "\n",
            "Patent ID: 10606996\n",
            "PubMed Claim: 1. A method of authenticating a biometric input, comprising: receiving image capture information from a first processing stream; generating a first image and authentication information with a second processing stream based at least part on the image capture information received from the first processing stream; providing the first image and the authentication information to a third processing stream; concurrently performing a first pattern matching process based on the first image with the second processing stream and a second pattern feature extraction process with the third processing stream, wherein the second pattern feature extraction process is based on the first image and the authentication information provided by the second processing stream; providing a first set of match parameters based on the first pattern matching process to the third processing stream; determining a second set of match parameters based on a second pattern matching process performed with the third processing stream; generating a match score based on the first set of match parameters and the second set of match parameters; and authenticating the biometric input based on the match score., 2. The method of claim 1 wherein the second processing stream is executed on at least one application processor., 3. The method of claim 2 wherein the third processing stream is executed on a secure processor., 4. The method of claim 3 wherein a processing capability of the at least one application processor is greater than a processing capability of the secure processor., 5. The method of claim 1 wherein the first processing stream is executed on an application-specific integrated circuit., 6. The method of claim 1 wherein the authentication information comprises a reduced feature descriptor and location information., 7. The method of claim 1 wherein generating the match score comprises generating the match score with the third processing stream., 8. The method of claim 1 wherein at least a portion of the second pattern matching process occurs concurrently with performing a first liveness detection process with the second processing stream., 9. The method of claim 8 further comprising: performing a second liveness detection process with the third processing stream; and authenticating the biometric input based at least in part on the first liveness detection process and the second liveness detection process., 10. The method of claim 1 wherein the biometric input is a fingerprint., 11. A system for authenticating a biometric input, comprising: a biometric sensor configured to obtain the biometric input a first processor executing a first processing stream configured to generate image information based on the biometric input; a second processor executing a second processing stream configured to: receive the image information from the first processing stream; generate authentication information based on the image information; generate a first set of match parameters based on the image information; a third processor executing a third processing stream configured to: receive the image information from the second processing stream; receive the authentication information and the first set of match parameters from the second processing stream; generate a second set of match parameters based on the image information and the authentication information; and authenticate the biometric input based on the first set of match parameters and the second set of match parameters, wherein at least a portion of the second processing stream and the third processing stream occur concurrently., 12. The system of claim 11 wherein the image information received by the third processing stream from the second processing stream is the image information generated by the first processing stream., 13. The system of claim 11 wherein the second processing stream is configured to generate an image based on the image information received from the first processing stream, and the image information received by the third processing stream from the second processing stream is the image generated by the second processing stream., 14. The system of claim 11 wherein the second processing stream is configured to perform a first liveness detection process based on the image information and the third processing stream is configured to perform a second liveness detection process based on the image information., 15. The system of claim 14 wherein at least a portion of the first liveness detection process is executed concurrently with an execution of the second liveness detection process., 16. The system of claim 14 wherein the third processing stream is configured to authenticate the biometric input based at least in part on the first liveness detection process and the second liveness detection process., 17. The system of claim 11 wherein the first processor is at least one application-specific integrated circuit., 18. The system of claim 11 wherein the second processor is at least one application processor., 19. The system of claim 11 wherein the third processor is at least one secure processor., 20. The system of claim 11 wherein a processing capability of the second processor is greater than a processing capability of the third processor., 21. The system of claim 11 wherein the authentication information comprises a reduced feature descriptor and location information., 22. The system of claim 11 wherein the biometric input is an iris image., 23. A computer program product, comprising: a first non-transitory computer-readable storage medium comprising code for a first processing stream including code for generating image information based on a biometric input; a second non-transitory computer-readable storage medium comprising code for a second processing stream including: code for receiving the image information from the first processing stream; code for generating authentication information based on the image information; conde for generating a first set of match parameters based on the image information; a third non-transitory computer-readable storage medium comprising code for a third processing stream including: code for receiving the image information from the second processing stream; code for receiving the authentication information and the first set of match parameters from the second processing stream; code for generating a second set of match parameters based on the image information and the authentication information; and code for authenticating the biometric input based on the first set of match parameters and the second set of match parameters, wherein at least a portion of the second processing stream and the third processing stream occur concurrently., 24. The computer program product of claim 23 wherein the code for receiving the image information from the second processing stream includes code for receiving the image information generated by the first processing stream., 25. The computer program product of claim 23 wherein the code for the second processing stream includes code for generating an image based on the image information received from the first processing stream, and the code for receiving the image information from the second processing stream include code for receiving the image generated by the second processing stream., 26. The computer program product of claim 23 wherein the code for the second processing stream includes code for performing a first liveness detection process based on the image information, and the code for the third processing stream includes code for performing a second liveness detection process based on the image information., 27. The computer program product of claim 26 wherein at least a portion of the code for performing the first liveness detection process is executed concurrently with the code for performing the second liveness detection process., 28. The computer program product of claim 26 wherein the code for the third processing stream includes code for authenticating the biometric input based at least in part on the code for the first liveness detection process and the code for the second liveness detection process., 29. The computer program product of claim 23 wherein the code for the first processing stream includes code for generating the image information based on a fingerprint input., 30. An apparatus for authenticating a biometric input, comprising: means for receiving image capture information from a first processing stream; means for generating a first image and authentication information with a second processing stream based at least part on the image capture information received from the first processing stream; means for providing the first image and the authentication information to a third processing stream; means for concurrently performing a first pattern matching process based on the first image with the second processing stream and a second pattern feature extraction process with the third processing stream, wherein the second pattern feature extraction process is based on the first image and the authentication information provided by the second processing stream; means for providing a first set of match parameters based on the first pattern matching process to the third processing stream; means for determining a second set of match parameters based on a second pattern matching process performed with the third processing stream; means for generating a match score based on the first set of match parameters and the second set of match parameters; and means for authenticating the biometric input based on the match score.\n",
            "Similarity Score: 0.5479\n",
            "\n",
            "\n",
            "Patent ID: 10606977\n",
            "PubMed Claim: 1. A method for verifying a design of an electronic circuit, the method comprising: simulating the design; and displaying a directed graph representative of the simulated design, wherein the directed graph is a navigable and graphical view of cause-effect data from a symbolic simulation, wherein the directed graph comprising a plurality of shapes each having a different color, wherein at least one of the shapes is associated with a plurality of variables of the design, wherein a direction of at least one of the paths of the directed graph is defined by a temporal relationship between at least first and second variables of the design., 2. The method of claim 1 wherein the direction of the at least one path of the graph is further defined by a testbench applied to simulate the design., 3. The method of claim 1 wherein the directed graph includes a plurality of paths each showing a propagating direction associated with at least one variable through the path., 4. The method of claim 3 wherein the plurality of paths are displayed concurrently with associated portions of the design or a testbench applied to simulate the design., 5. The method of claim 1 further comprising: displaying at least a subset of the plurality of variables that transition at substantially a same time along a horizontal or vertical direction., 6. The method of claim 1 further comprising annotating the directed graph with values of the plurality of variables resulting from the simulation., 7. The method of claim 6 further comprising: specifying a target coverage; and displaying values of the plurality of variables required to achieve the specified target coverage., 8. A computer system configured to: Simulate, via a processor, a circuit design; and display a directed graph representative of the simulated design, wherein the directed graph is a navigable and graphical view of cause-effect data from a symbolic simulation, wherein the directed graph comprising a plurality of shapes each having a different color, wherein at least one of the shapes is associated with a plurality of variables of the design, wherein a direction of at least one of the paths of the directed graph is defined by a temporal relationship between at least first and second plurality of variables., 9. The computer system of claim 8 wherein the direction of the at least one path of the graph is further defined by a testbench applied to simulate the design., 10. The computer system of claim 8 wherein the directed graph includes a plurality of paths each showing a propagating direction associated with at least one variable through the path., 11. The computer system of claim 10 wherein computer system is further configured to display the plurality of paths concurrently with associated portions of the design or a testbench applied to simulate the design., 12. The computer system of claim 8 wherein computer system is further configured to display at least a subset of the plurality of variables that transition at substantially a same time a long a horizontal or vertical direction., 13. The computer system of claim 8 wherein the computer system is further configured to annotate the directed graph with values of the plurality of variables resulting from the simulation., 14. The computer system of claim 13 where in the computer system is further configured to: specify a target coverage; and display values of the plurality of variables required to achieve the specified target coverage., 15. A method for navigating a large data set during a symbolic simulation to determine a reason for unreachability comprising: performing, via a processor, a symbolic simulation of the large data set to generate a plurality of symbol values; generating a directed graph to show how the symbol values flowed during the symbolic simulation, wherein the directed graph is navigable and graphical view of cause-effect data from a symbolic simulation, wherein the symbol values colored and shaped for various analysis wherein at least one of the shapes is associated with a plurality of variables, wherein a direction of at least one of the paths of the directed graph is defined by a temporal relationship between at least first and second variables.\n",
            "Similarity Score: 0.5468\n",
            "\n",
            "\n",
            "Patent ID: 10606782\n",
            "PubMed Claim: 1. A method of aligning received bad data indicators (BDIs) with received data on a cross-chip link, the method comprising: receiving, by a transaction layer from the cross-chip link, a control flit of a frame, the control flit comprising incoming data flit information for a plurality of incoming data flits; adding the incoming data flit information to a control structure in the transaction layer; receiving, from the cross-chip link, the plurality of incoming data flits in the frame; directing each of the plurality of incoming data flits to virtual channel queues based on the incoming data flit information at a first read pointer in the control structure; after receiving all of the plurality of incoming data flits of the frame, receiving a bookend flit for the frame, the bookend flit comprising a plurality of BDIs for the plurality of data flits in the frame; and associating, by the transaction layer, each of the BDIs with the plurality of data flits based on the incoming data flit information at a second read pointer in the control structure., 2. The method of claim 1 , further comprising: providing, from the transaction layer, the plurality of data flits and BDIs for the plurality of data flits to a host processing unit., 3. The method of claim 2 , wherein associating each of the BDIs with the plurality of data flits based on the incoming data flit information at the second read pointer in the control structure comprises: processing, by a state machine, each BDI based on a clock cycle of the host processing unit., 4. The method of claim 1 , wherein directing each of the plurality of incoming data flits to virtual channel queues based on the incoming data flit information at the first read pointer in the control structure comprises, for each incoming data flit: retrieving, from the control structure at the first read pointer, a virtual channel identifier; selecting a virtual channel queue based on the virtual channel identifier; and storing the incoming data flit in an entry in the selected virtual channel queue., 5. The method of claim 1 , wherein associating each of the BDIs with the plurality of data flits based on the incoming data flit information at the second read pointer in the control structure comprises, for each BDI: retrieving, from the control structure at the second read pointer, a virtual channel identifier; selecting a BDI array based on the virtual channel identifier; and storing the BDI in an entry in the selected BDI array., 6. The method of claim 1 , wherein directing each of the plurality of incoming data flits to virtual channel queues based on the incoming data flit information at the first read pointer in the control structure comprises: storing each of the plurality of incoming data flits in the virtual channel queues based on a location of a write pointer into the virtual channel queues., 7. The method of claim 1 , wherein the incoming data flit information comprises a virtual channel identifier and a length of each of the plurality of incoming data flits.\n",
            "Similarity Score: 0.5457\n",
            "\n",
            "\n",
            "Patent ID: 10606797\n",
            "PubMed Claim: 1. A method of implementing a token-controlled process within an integrated circuit, the method comprising: at a primary data buffer of an integrated circuit, collecting input data from one or more input data sources; implementing a data processing pipeline, wherein the data processing pipeline is defined by at least: one or more matrix multiply accelerators; one or more local data buffers; implementing by the integrated circuit one or more flow scoreboard modules, wherein implementing the one or more flow scoreboard modules includes: (i) implementing a token-count table that tracks one or more tokens within the integrated circuit; (ii) implementing a program control table that monitors one or more program execution conditions based on the one or more tokens; generating state data for each of the one or more of the local data buffer and each of the one or more matrix multiply accelerators, wherein the state data indicates a level of utilization of each of the one or more of the local data buffer and each of the one or more matrix multiply accelerators; generating by the integrated circuit one or more tokens based on the state data for each of the one or more local data buffers and each of the one or more matrix multiply accelerators; tracking the one or more tokens generated by the integrated circuit; and (a) updating an internal state of the token count table based on the tracking or (b) updating an internal state of the program control table based on the tracking; and automatically propagating one or more portions of the input data from the primary data buffer along the data processing pipeline based on the implementation of the token count table and the implementation of the program control table., 2. The method according to claim 1 , further comprising: automatically executing one or more programs or one or more applications at one or more of the one or more matrix multiply accelerators of the data processing pipeline based on a state of the program control table., 3. The method according to claim 1 , wherein the token count table: is indexed according to a plurality of distinct token identifiers; includes an entry for each of the plurality of distinct token identifiers that stores a running count of a number of one distinct token having one of the plurality of distinct token identifiers; and each entry stores software-programmable configuration bits that set a respective counter trigger condition., 4. The method according to claim 3 , wherein the token count table is configured with at least one pointer that points to an entry in the program control table when a counter trigger condition is satisfied based on a count value for a distinct token within the token control table., 5. The method according to claim 1 , wherein the program control table: is indexed according to a plurality of distinct program identifiers of a plurality of distinct programs; each entry of the program table includes a counter that stores a counter value for one or more distinct tokens associated with one or more distinct token identifiers; and each entry of the program table stores a software-programmable configuration bits that set a program execution condition based on the counter value for the one or more distinct tokens., 6. The method according to claim 1 , wherein when an update to a token count of the token count table results in a token counter condition transitioning from not satisfied to satisfied, a corresponding entry in the program control table is accessed and a count of a counter value of the program control table is incremented or decremented., 7. The method according to claim 6 , wherein when an update to the program table entry counter value causes the program trigger condition to transition from not satisfied to satisfied, a notification interface is updated to reflect the transition., 8. The method according to claim 1 , further comprising: identifying a state of the at least one local data buffer; generating one or more tokens based on the identified state; and triggering a notification to an upstream component or a downstream component within the data processing pipeline of the integrated circuit based on the one or more tokens., 9. The method according to claim 8 , further comprising: in response to the notification, automatically loading one or more portions of the input data to the at least one local data buffer, or automatically loading the one or more portions of the input data from the at least one local data buffer into one of the one or more matrix multiply accelerators., 10. The method according to claim 1 , wherein the integrated circuit comprises: a plurality of computing tiles, wherein each of the plurality of computing tiles includes: a matrix multiply accelerator of the one or more matrix multiply accelerators, a computing processing circuit; and a flow scoreboard module of the one or more flow scoreboard modules; a local data buffer of the one or more local data buffers, wherein the plurality of computing tiles together define an intelligence processing array; a network on chip system comprising: a plurality of network-on-chip routers establishing a communication network between each of the plurality of computing tiles, wherein each network-on-chip router is in operable communication connection with at least one of the plurality of computing tiles and a distinct network-on-chip router of the plurality of network-on-chip routers; and the main buffer that is arranged remotely from each of the plurality of computing tiles, wherein the main buffer stores raw input data and/or data received from an upstream process or upstream device., 11. A method of implementing a token-controlled process within an integrated circuit, the method comprising: at a primary data buffer of an integrated circuit, collecting input data from one or more input data sources; implementing a data processing pipeline, wherein the data processing pipeline is defined by at least: one or more matrix multiply accelerators; one or more local data buffers; implementing by the integrated circuit one or more flow scoreboard modules, wherein implementing the one or more flow scoreboard modules includes: (i) implementing a token-count table that tracks one or more tokens within the integrated circuit; (ii) implementing a program control table that monitors one or more program execution conditions based on the one or more tokens; automatically propagating one or more portions of the input data from the primary data buffer along the data processing pipeline based on the implementation of the token count table and the implementation of the program control table, wherein: when an update to a token count of the token count table results in a token counter condition transitioning from not satisfied to satisfied, a corresponding entry in the program control table is accessed and a count of a counter value of the program control table is incremented or decremented, and when an update to the program table entry counter value causes the program trigger condition to transition from not satisfied to satisfied, a notification interface is updated to reflect the transition., 12. A method of implementing a token-controlled process within an integrated circuit, the method comprising: at a primary data buffer of an integrated circuit, collecting input data from one or more input data sources; implementing a data processing pipeline, wherein the data processing pipeline is defined by at least: one or more matrix multiply accelerators; one or more local data buffers; implementing by the integrated circuit one or more flow scoreboard modules, wherein implementing the one or more flow scoreboard modules includes: (i) implementing a token-count table that tracks one or more tokens within the integrated circuit; (ii) implementing a program control table that monitors one or more program execution conditions based on the one or more tokens; identifying a state of the at least one local data buffer; generating one or more tokens based on the identified state; triggering a notification to an upstream component or a downstream component within the data processing pipeline of the integrated circuit based on the one or more tokens; in response to the notification: (a) automatically loading one or more portions of the input data to the at least one local data buffer, or (b) automatically loading the one or more portions of the input data from the at least one local data buffer into one of the one or more matrix multiply accelerators; automatically propagating one or more portions of the input data from the primary data buffer along the data processing pipeline based on the implementation of the token count table and the implementation of the program control table.\n",
            "Similarity Score: 0.5455\n",
            "\n",
            "\n",
            "Patent ID: 10606738\n",
            "PubMed Claim: 1. A method, comprising: receiving results from a network of nodes, by a submission node, the results created after execution of a test package by the network of nodes to perform a test associated with an application; and updating a blockchain with the results, by the submission node., 2. The method of claim 1 , further comprising: creating, by the submission node, a contract comprising test information used to perform the test; including the contract and a request in the test package, by the submission node; and providing the test package to the network of nodes, by the submission node., 3. The method of claim 2 , wherein the contract comprises one or more of a reward for performing the test, a number of test cycles, an amount of central processing unit utilization, an amount of memory utilization, and an amount of time., 4. The method of claim 1 , wherein the test package comprises an image container., 5. The method of claim 1 , wherein the submission node comprises a distributed peer proxy node server configured to distribute the test package to the network of nodes, and the network of nodes comprises a plurality of distributed peer proxy node client devices., 6. The method of claim 1 , further comprising: comparing the received results to known results associated with the application, by the submission node; and creating an alert, by the submission node, when the results are different from the known results., 7. The method of claim 1 , further comprising: broadcasting the results, by the submission node, to one or more client devices in the network., 8. An apparatus, comprising: a receiver configured to receive results from a network of nodes, the results created after execution of a test package by the network of nodes to perform a test associated with an application; and a processor configured to update a blockchain with the results., 9. The apparatus of claim 8 , wherein the processor is further configured to: create a contract comprising test information used to perform the test; include the contract and a request in the test package; and provide the test package to the network of nodes., 10. The apparatus of claim 9 , wherein the contract comprises one or more of a reward for performing the test, a number of test cycles, an amount of central processing unit utilization, an amount of memory utilization, and an amount of time., 11. The apparatus of claim 8 , wherein the test package comprises an image container., 12. The apparatus of claim 8 , wherein the apparatus comprises a distributed peer proxy node server configured to distribute the test package to the network of nodes, and the network of nodes comprises a plurality of distributed peer proxy node client devices., 13. The apparatus of claim 8 , wherein the processor is further configured to: compare the received results to known results associated with the application; and create an alert when the results are different from the known results., 14. The apparatus of claim 8 , further comprising: a transmitter configured to broadcast the results to one or more client devices in the network., 15. A non-transitory computer readable storage medium storing instructions that, when executed, cause a processor to perform: receiving results from a network of nodes, the results created after execution of a test package by the network of nodes to perform a test associated with an application; and updating a blockchain with the results., 16. The non-transitory computer readable storage medium of claim 15 , wherein the instructions are further configured to cause the processor to perform: creating a contract comprising test information used to perform the test; including the contract and a request in the test package; and providing the test package to the network of nodes., 17. The non-transitory computer readable storage medium of claim 16 , wherein the contract comprises one or more of a reward for performing the test, a number of test cycles, an amount of central processing unit utilization, an amount of memory utilization, and an amount of time., 18. The non-transitory computer readable storage medium of claim 15 , wherein the test package comprises an image container., 19. The non-transitory computer readable storage medium of claim 15 , wherein the test package is distributed by a distributed peer proxy node server, and the network of nodes comprises a plurality of distributed peer proxy node client devices., 20. The non-transitory computer readable storage medium of claim 15 , wherein the instructions are further configured to cause the processor to perform at least one of: comparing the received results to known results associated with the application; creating an alert when the results are different from the known results; and broadcasting the results to one or more client devices in the network.\n",
            "Similarity Score: 0.5450\n",
            "\n",
            "\n",
            "Patent ID: 10606904\n",
            "PubMed Claim: 1. A method for automatically providing contextual information for a key and/or value in an electronic document displayed to a user by a computing device, the method comprising: a. displaying to a user by a computing device an electronic document; b. selecting by the user through an input device of the computing device, a key and/or value in the electronic document; c. determining, by a processor, an entity for the key and/or value in the electronic document pre-identified within the document and/or by natural language processing techniques, analyzing text patterns, presentation semantics, titles, and/or captions; d. identifying a category for the entity; e. performing a search operation by a search engine processor for electronic document(s) comprising of the category and at least one of the key or value; f. identifying, by the search engine processor, entities within the electronic document(s) found by the search engine belonging to the identified category; g. altering the electronic document displayed to the user by the computing device by incorporating within the electronic document the identified entities from the electronic document(s) found by the search engine; and h. displaying the altered electronic document to the user by the computing device., 2. The method as in claim 1 , wherein the category is present in a title in the document(s) found by the search engine., 3. The method as in claim 2 , wherein the identified entities in the document(s) found by the search engine are in a table., 4. The method as in claim 3 , wherein a column header of the table comprises of the key., 5. The method as in claim 2 , wherein the identified entities in the document(s) found by the search engine are in a list., 6. The method as in claim 5 , wherein a title of the list comprises of the key and/or value., 7. The method as in claim 1 , wherein the key is implicit., 8. The method as in claim 1 , wherein the identified entities are returned to the user in table or list form., 9. The method as in claim 1 , wherein the category for the entities is a parent category., 10. The method as in claim 1 , wherein the category for the entities is a subcategory., 11. The method as in claim 1 , wherein the key and/or value in the electronic document is highlighted.\n",
            "Similarity Score: 0.5431\n",
            "\n",
            "\n",
            "Patent ID: 10607005\n",
            "PubMed Claim: 1. A computer-implemented method for labeling automatically generated reports, at least a portion of the method being performed by a computing device comprising at least one processor, the method comprising: identifying: a set of incident reports that describe incidents that each involve at least one computing system and that comprise automatically collected information about the incidents; and a manually analyzed subset of the set of incident reports that further comprise manually generated information about the incidents in addition to automatically collected information about the incidents; assigning at least one label from a set of labels to at least one incident report in the manually analyzed subset of the set of incident reports, wherein the set of labels was generated based on applying a machine learning model to the manually generated information; deriving, from the automatically collected information, a set of features that describe the set of incident reports wherein each feature in the set of features discriminates between differing types of incident reports; plotting each incident report in the set of incident reports on a graph based on at least one value for the incident report of at least one feature in the set of features; in response to determining that the labeled incident report and the incident report comprise similar features from the set of features by determining that the labeled incident report and the incident report are plotted within a predetermined distance of each other in the graph, propagating at least one label assigned to a labeled incident report in the manually analyzed subset of the set of incident reports to an incident report that is not in the manually analyzed subset; and performing an action related to the label on the incident report that is not in the manually analyzed subset in response to propagating the label to the incident report., 2. The computer-implemented method of claim 1 , wherein performing the action comprises forwarding the incident report to an analyst for manual analysis., 3. The computer-implemented method of claim 1 , wherein performing the action comprises propagating at least one manually added note from the labeled incident report to the incident report., 4. The computer-implemented method of claim 1 , wherein the incidents comprise security incidents and the set of incident reports comprises incident reports generated by security applications., 5. The computer-implemented method of claim 1 , wherein assigning the at least one label from a set of labels to the at least one incident report in the manually analyzed subset of the set of incident reports based on applying the machine learning model to the manually generated information comprises analyzing the manually generated information using a natural language processing technique., 6. The computer-implemented method of claim 1 , wherein deriving, from the automatically collected information, the set of features that describe the set of incident reports comprises: deriving an original set of features from the set of incident reports; and refining, using a machine learning model, the original set of features into a reduced set of features that comprises a subset of the original set features that differentiates between incident reports of different types more effectively than a subset of the original features not in the reduced set of features., 7. The computer-implemented method of claim 1 , wherein assigning the at least one label from a set of labels to the at least one incident report in the manually analyzed subset of the set of incident reports comprises: labeling the at least one incident report in the manually analyzed subset as severe; and labeling at least one additional incident report in the manually analyzed subset as not severe., 8. The computer-implemented method of claim 7 , wherein performing the action comprises at least one of: forwarding the incident report labeled as severe to an analyst for manual analysis in response to labeling the incident report as severe; and avoiding forwarding the additional incident report labeled as not severe to an analyst for manual analysis in response to labeling the additional incident report as not severe., 9. A system for labeling automatically generated reports, the system comprising: an identification module, stored in memory, that identifies: a set of incident reports that describe incidents that each involve at least one computing system and that comprise automatically collected information about the incidents; and a manually analyzed subset of the set of incident reports that further comprise manually generated information about the incidents in addition to automatically collected information about the incidents; an assignment module, stored in memory, that assigns at least one label from a set of labels to at least one incident report in the manually analyzed subset of the set of incident reports, wherein the set of labels was generated based on applying a machine learning model to the manually generated information; a deriving module, stored in memory, that derives, from the automatically collected information, a set of features that describe the set of incident reports, wherein each feature in the set of features discriminates between differing types of incident reports; a propagation module, stored in memory, that propagates at least one label assigned to a labeled incident report in the manually analyzed subset of the set of incident reports to an incident report that is not in the manually analyzed subset and that comprises similar features from the set of features with the labeled incident report by: plotting each incident report in the set of incident reports on a graph based on at least one value for the incident report of at least one feature in the set of features; and propagating the at least one label from the labeled incident report to the incident report in response to determining that the labeled incident report and the incident report are plotted within a predetermined distance of each other in the graph; a performing module, stored in memory, that performs an action related to the label on the incident report that is not in the manually analyzed subset in response to propagating the label to the incident report; and at least one physical processor configured to execute the identification module, the assignment module, the deriving module, the propagation module, and the performing module., 10. The system of claim 9 , wherein the performing module performs the action by forwarding the incident report to an analyst for manual analysis., 11. The system of claim 9 , wherein the performing module performs the action by propagating at least one manually added note from the labeled incident report to the incident report., 12. The system of claim 9 , wherein the incidents comprise security incidents and the set of incident reports comprises incident reports generated by security applications., 13. The system of claim 9 , wherein the assignment module assigns the at least one label from a set of labels to the at least one incident report in the manually analyzed subset of the set of incident reports based on applying the machine learning model to the manually generated information by analyzing the manually generated information using a natural language processing technique., 14. The system of claim 9 , wherein the deriving module derives, from the automatically collected information, the set of features that describe the set of incident reports by: deriving an original set of features from the set of incident reports; and refining, using a machine learning model, the original set of features into a reduced set of features that comprises a subset of the original set features that differentiates between incident reports of different types more effectively than a subset of the original features not in the reduced set of features., 15. The system of claim 9 , wherein the assignment module assigns the at least one label from a set of labels to the at least one incident report in the manually analyzed subset of the set of incident reports by: labeling the at least one incident report in the manually analyzed subset as severe; and labeling at least one additional incident report in the manually analyzed subset as not severe., 16. The system of claim 15 , wherein the performing module performs the action by at least one of: forwarding the incident report labeled as severe to an analyst for manual analysis in response to labeling the incident report as severe; and avoiding forwarding the additional incident report labeled as not severe to an analyst for manual analysis in response to labeling the additional incident report as not severe., 17. A non-transitory computer-readable medium comprising one or more computer-readable instructions that, when executed by at least one processor of a computing device, cause the computing device to: identify: a set of incident reports that describe incidents that each involve at least one computing system and that comprise automatically collected information about the incidents; and a manually analyzed subset of the set of incident reports that further comprise manually generated information about the incidents in addition to automatically collected information about the incidents; assign at least one label from a set of labels to at least one incident report in the manually analyzed subset of the set of incident reports, wherein the set of labels was generated based on applying a machine learning model to the manually generated information; derive, from the automatically collected information, a set of features that describe the set of incident reports wherein each feature in the set of features discriminates between differing types of incident reports; plot each incident report in the set of incident reports on a graph based on at least one value for the incident report of at least one feature in the set of features; in response to determining that the labeled incident report and the incident report comprise similar features from the set of features by determining that the labeled incident report and the incident report are plotted within a predetermined distance of each other in the graph, propagate at least one label assigned to a labeled incident report in the manually analyzed subset of the set of incident reports to an incident report that is not in the manually analyzed subset and that comprises similar features from the set of features with the labeled incident report; and perform an action related to the label on the incident report that is not in the manually analyzed subset in response to propagating the label to the incident report., 18. The non-transitory computer-readable medium of claim 17 , wherein the one or more computer-readable instructions cause the computing device to perform the action by forwarding the incident report to an analyst for manual analysis., 19. The non-transitory computer-readable medium of claim 17 , wherein performing the action comprises propagating at least one manually added note from the labeled incident report to the incident report., 20. The non-transitory computer-readable medium of claim 17 , wherein the incidents comprise security incidents and the set of incident reports comprises incident reports generated by security applications.\n",
            "Similarity Score: 0.5419\n",
            "\n",
            "\n",
            "Patent ID: 10606843\n",
            "PubMed Claim: 1. A method comprising: receiving, by at least one computing device, a data driven application engineering (DDAE) specification; determining, by the at least one computing device, a metamodel that defines relationships between tokens, lines, and statements found in the DDAE specification, wherein each of the tokens includes a foreign key indicating a relationship with one of the statements; defining, by the at least one computing device, a plurality of connector patterns based on the received DDAE specification and the metamodel, wherein the connector patterns modularize a plurality of condition tests as comparisons and gates; and generating, using a compiler executing on the at least one computing device, a plurality of irreducible modules in a perl programming language based on the plurality of connector patterns, wherein the plurality of irreducible modules perform the calculation according to the plurality of condition tests to produce an output variable., 2. The method of claim 1 , wherein the connector patterns define a set of modules that can be created and combined in any application., 3. The method of claim 1 , wherein the irreducible modules are independent of each other and a data flow associated with the irreducible module is identified by the output variable., 4. The method of claim 3 , wherein the output variable is identified by a primary key value and is related to other variables by foreign key references., 5. The method of claim 1 , wherein the irreducible modules are associated with a parallel computing application., 6. The method of claim 5 , wherein the irreducible modules are hardware or software infrastructure agnostic., 7. The method of claim 1 , wherein the generating the plurality of irreducible modules includes generating a two dimensional matrix, wherein each entry within the two dimensional matrix is associated with a token within a particular line sequence that is within a statement., 8. The method of claim 1 , wherein the plurality of irreducible modules includes a gate connector., 9. The method of claim 8 , wherein the gate connector comprises at least one of an AND gate, an OR gate, a NAND gate, and NOR gate and connects two independent variables with a dependent variable., 10. The method of claim 1 , wherein the irreducible models are generated in the perl programming language using a SQL query., 11. The method of claim 10 , wherein the DDAE specification is received via a graphical user interface., 12. The method of claim 1 , wherein the DDAE specification defines a calculation and comprises the plurality of condition tests that are required for assigning a correct value to the output variable., 13. The method of claim 1 , wherein the irreducible modules further includes a calculation connector and a comparison connector, the calculation connector includes at least one of a numeric function, a string function, and an aggregate function defined in the DDAE specification, and the comparison connector includes a comparison of two independent variables and outputs TRUE if values of the two independent variables comply with the comparison in accordance with the condition tests., 14. The method of claim 13 , wherein the calculation connector connects two or three independent variables with a dependent variable by combining the two or three independent variables to assign a value to the dependent variable., 15. The method of claim 13 , wherein the comparison connector compares the two independent variables and then assigns a value to a dependent variable., 16. The method of claim 1 , further comprising generating at least one irreducible model in a Java programming language., 17. The method of claim 1 , wherein the foreign key further indicates a relationship between a line entity, one of the statements, and the metamodel.\n",
            "Similarity Score: 0.5415\n",
            "\n",
            "\n",
            "Patent ID: 10606874\n",
            "PubMed Claim: 1. A method implemented in a computer infrastructure comprising a combination of hardware and software, the method comprising: generating a ranked result set based on a search query; generating an adjusted ranked result set based on a skill rating of a search user; determining an efficiency of the search by click through selection data which includes a time it takes for the search user to click through the adjusted ranked result set before selecting a result document contained in the adjusted ranked result to generate a modified skill rating of the searcher in view of the amount of documents clicked on by the search user prior to achieving the result document, wherein the more documents clicked on by the search user the less of an increase in the skill rating of the search user; monitoring a review of the adjusted ranked result set by the search user, wherein the monitoring comprises monitoring time spent reviewing the adjusted ranked result set; and storing the modified skill rating of the searcher based on the determined efficiency., 2. The method of claim 1 , wherein the monitoring further comprises monitoring at least one of: a number of documents reviewed in the adjusted ranked result set; and a rank of the result document contained in the adjusted ranked result set., 3. The method of claim 2 , further comprising adjusting the skill rating of the search user based on the monitoring., 4. The method of claim 1 , further comprising: providing the result document to a recipient; and receiving feedback associated with the result document from the recipient., 5. The method of claim 4 , further comprising adjusting the skill rating of the search user based on at least one of the monitoring and the feedback., 6. The method of claim 4 , further comprising determining a lack of documentation in a domain or category based on the feedback., 7. The method of claim 1 , wherein the adjusting the ranked result set based on the skill rating of the search user comprises: identifying at least one document that is in both the ranked result set and a similar search performed by another search user having a higher skill rating than the search user; and changing a ranking of the at least one document in the ranked result set based on the identifying., 8. The method of claim 1 , wherein the adjusting the ranked result set based on the skill rating of the search user comprises: identifying at least one document that has been tagged by another search user having a higher skill rating than the search user; and changing a ranking of the at least one document in the ranked result set based on the identifying., 9. The method of claim 8 , wherein the identifying the at least one document comprises determining that the at least one document is contained in a same domain or category as the search query from the search user., 10. The method of claim 1 , further comprising providing a hint or educational information to the search user based on a similar search performed by another search user having a higher skill rating than the search user., 11. The method of claim 10 , wherein the ranked result set includes a ranking having a value that describes a percentage of relevance against 100 percent that a particular document is in the ranked result set., 12. The method of claim 11 , further comprising generating a set of documents from a skill set of the search user., 13. The method of claim 12 , wherein the skill set of the search user is based on the skill rating of the user., 14. The method of claim 13 , further comprising augmenting the skill result set of documents based on a search category derived from input search parameters inputted by the search user into the search query., 15. The method of claim 14 , further comprising accounting an order in which the search user clicked on the documents, thereby increasing a ranking of the clicked on documents for a subsequent similar search query performed by a lower skilled search user., 16. The method of claim 15 , further comprising identifying a language of the search user to employ a linguistic dictionary for adjusting terms within the search query., 17. The method of claim 16 , further comprising: receiving feedback associated with the result document from a recipient which was provided with the result document; adjusting the skill rating of the search user based on the monitoring and the feedback; and determining a lack of documentation in a domain or category based on the feedback., 18. A system implemented in hardware and comprising a computer infrastructure configured to: receive a search query from a search user; enter terms within the search query to alter a preferred document type to employ a tier arrangement to return documents requiring a type of skill from the search user; generate a ranked result set of documents in view of the type of skill by searching a document repository against the search query, wherein the ranked result set includes a ranking having a value that describes a percentage of relevance against 100 percent that a particular document is in the ranked result set; generate an adjusted ranked result set of documents based on a skill rating of the search user; monitor a review of the adjusted ranked result set of documents by the search user, wherein the monitoring comprises monitoring time spent reviewing the adjusted ranked result set; receive a selection of a result document contained in the adjusted ranked result set of documents; determine an efficiency of the search session by comparing a time of the search session to a threshold value; adjust the skill rating of the search user based on the efficiency; and store the adjusted skill rating of the searcher based on the efficiency., 19. The system of claim 18 , wherein the computer infrastructure is further operable to determine a lack of documentation in a domain or category based on feedback associated with the result document.\n",
            "Similarity Score: 0.5415\n",
            "\n",
            "\n",
            "Patent ID: 10606805\n",
            "PubMed Claim: 1. A system comprising: a non-transitory memory; and one or more hardware processors coupled to the non-transitory memory to execute instructions from the non-transitory memory to perform operations comprising: requesting an image from a registry provided via a network; receiving, from the registry, an address for the requested image; receiving from the registry a directory structure corresponding to the requested image at the address, the directory structure providing identifiers of one or more layers of the requested image and identifiers of one or more objects that are included within the one or more layers; traversing a local copy of the directory structure included in a persistent local mirror overlay file system (PLMO FS) to access a first object of the one or more objects from a local storage; traversing the local copy of the directory structure included in the PLMO FS to determine an input/output (I/O) miss corresponding to a second object of the one or more objects; responsive to determining the I/O miss, retrieving the second object from the registry and storing the second object to the local storage; and building a local copy of the requested image from the local storage, the local copy including the first object from the local storage and the retrieved second object., 2. The system of claim 1 , wherein the one or more layers are organized into a hierarchy., 3. The system of claim 1 , wherein each layer of the one or more layers is structured as an archived and/or a compressed file., 4. The system of claim 1 , wherein the directory structure received from the registry includes metadata describing amounts of the one or more objects stored in each layer of the one or more layers, modification times corresponding to the one or more objects, last access times corresponding to the one or more objects, hashes corresponding to the one or more objects, and sizes corresponding to the one or more objects., 5. The system of claim 1 , wherein the first and second objects are structured as archived and/or compressed files, and building the local copy of the requested image includes dearchiving and/or decompressing the archived and/or compressed files to extract their contents., 6. The system of claim 1 , further comprising updating the PLMO FS to indicate the presence of the second object in the local storage., 7. The system of claim 1 , further comprising matching a hash corresponding to the first object on the local storage with a hash retrieved from the registry., 8. A computer-implemented method comprising: requesting an image from a registry provided via a network; receiving, from the registry, an address for the requested image; receiving from the registry a directory structure corresponding to the requested image at the address, the directory structure providing identifiers of one or more layers of the requested image and identifiers of one or more objects that are included within the one or more layers; traversing a local copy of the directory structure included in a persistent local mirror overlay file system (PLMO FS) to access an object of the one or more objects from a local storage; determining an input/output (I/O) hit or miss corresponding to the traversed object of the one or more objects; responsive to determining the I/O miss, retrieving from the registry an I/O-missed object and storing the I/O-missed object to the local storage; and building a local copy of the requested image from the local storage, the local copy including an I/O-hit object and the retrieved I/O-missed object., 9. The method of claim 8 , wherein the one or more layers are organized into a hierarchy., 10. The method of claim 8 , wherein each layer of the one or more layers is structured an archived and/or a compressed file., 11. The method of claim 8 , wherein the directory structure received from the registry includes metadata describing amounts of the one or more objects stored in each layer of the one or more layers, modification times corresponding to the one or more objects, last access times corresponding to the one or more objects, hashes corresponding to the one or more objects, and sizes corresponding to the one or more objects., 12. The method of claim 8 , wherein the I/O-hit and I/O-missed objects are structured as archived and/or compressed files, and building the local copy of the requested image includes dearchiving and/or decompressing the archived and/or compressed files to extract their contents., 13. The method of claim 8 , further comprising updating the PLMO FS to indicate the presence of the I/O-missed object in the local storage., 14. The method of claim 8 , further comprising matching a hash corresponding to the traversed object with a hash retrieved from the registry., 15. A non-transitory machine-readable medium having stored thereon machine-readable instructions executable to cause at least one machine to perform operations comprising: requesting an image from a registry provided via a network; receiving, from the registry, an address for the requested image; receiving from the registry a directory structure corresponding to the requested image at the address, the directory structure providing identifiers of one or more layers of the requested image and identifiers of one or more objects that are included within the one or more layers; traversing a local copy of the directory structure included in a persistent local mirror overlay file system (PLMO FS) to access a first object of the one or more objects from a local storage; traversing the local copy of the directory structure included in the PLMO FS to determine an input/output (I/O) miss corresponding to a second object of the one or more objects; responsive to determining the I/O miss, retrieving the second object from the registry and storing the second object to the local storage; and building a local copy of the requested image from the local storage, the local copy including the first object from the local storage and the retrieved second object., 16. The non-transitory machine-readable medium of claim 15 , wherein the one or more layers are organized into a hierarchy., 17. The non-transitory machine-readable medium of claim 15 , wherein each layer of the one or more layers is structured as an archived and/or compressed file., 18. The non-transitory machine-readable medium of claim 15 , wherein the directory structure received from the registry includes metadata describing amounts of the one or more objects stored in each layer of the one or more layers, modification times corresponding to the one or more objects, last access times corresponding to the one or more objects, hashes corresponding to the one or more objects, and sizes corresponding to the one or more objects., 19. The non-transitory machine-readable medium of claim 15 , wherein the first and second objects are structured as archived and/or compressed files, and building the local copy of the requested image includes dearchiving and/or decompressing the archived and/or compressed files to extract their contents., 20. The non-transitory machine-readable medium of claim 15 , further comprising updating the PLMO FS to indicate the presence of the second object in the local storage.\n",
            "Similarity Score: 0.5415\n",
            "\n",
            "\n",
            "Patent ID: 10606889\n",
            "PubMed Claim: 1. A method, implemented by at least one computing device, comprising: receiving a query from a viewing user; searching, based on the query, a relational media database comprising a plurality of media presentations, wherein the relational media database, for a respective media presentation of the plurality of media presentations, comprises a subtitle track being a textual representation of a dialog within the respective media presentation, a frame from the respective media presentation associated with the subtitle track, program statistics based on analysis of the subtitle track, and a statistical index associated with a respective type of the program statistics, to yield search results; and transmitting the search results to a device associated with the viewing user, the search results comprising the frame and a prompt for ordering the respective media presentation associated with the frame., 2. The method of claim 1 , further comprising: retrieving, from a restricted access database, additional metadata associated with the subtitle track, wherein the relational media database is distinct from the restricted access database., 3. The method of claim 1 , further comprising receiving metadata that identifies a particular feature of the frame., 4. The method of claim 3 , wherein the metadata is further defined manually by another user different from the viewing user., 5. The method of claim 3 , wherein the metadata comprises a viewer rating on a scene-by-scene basis for the respective media presentation., 6. The method of claim 1 , further comprising: receiving a user query associated with a specific dialog within the respective media presentation; searching the relational media database for video presentations corresponding to the user query and presenting a list of results; receiving a user selection of a specific video presentation from the list of results; and transmitting a specific video presentation representative frame, a portion of a subtitle track associated with the specific video presentation, and a prompt for ordering the specific video presentation., 7. The method of claim 6 , further comprising presenting options for selecting a second metadata associated with the specific video presentation representative frame., 8. The method of claim 6 , further comprising presenting individual statistics for each video presentation in the list of results., 9. The method of claim 6 , wherein the list of results comprises a user approval rating for respective scenes associated with the list of results., 10. The method of claim 6 , further comprising: receiving a user query based on a dialog in a plurality of video presentations comprising the video presentation, the plurality of video presentations being included in a user personal library; and presenting, as a result of searching the plurality of video presentations, a list of video presentations comprising the program statistics., 11. A system comprising: a hardware processor; and a computer-readable storage medium having instructions stored which, when executed by the hardware processor, cause the hardware processor to perform operations comprising: receiving a query from a viewing user; searching, based on the query, a relational media database comprising a plurality of media presentations, wherein the relational media database, for a respective media presentation of the plurality of media presentations, comprises a subtitle track being a textual representation of a dialog within the respective media presentation, a frame from the respective media presentation associated with the subtitle track, program statistics based on analysis of the subtitle track, and a statistical index associated with a respective type of the program statistics, to yield search results; and transmitting the search results to a device associated with the viewing user, the search results comprising the frame and a prompt for ordering the respective media presentation associated with the frame., 12. The system of claim 11 , wherein the computer-readable storage medium stores additional instructions which, when executed by the hardware processor, cause the hardware processor to perform operations further comprising: retrieving, from a restricted access database, additional metadata associated with the subtitle track, wherein the relational media database is distinct from the restricted access database., 13. The system of claim 11 , wherein the computer-readable storage medium stores additional instructions which, when executed by the hardware processor, cause the hardware processor to perform operations further comprising: receiving metadata that identifies particular features of the frame., 14. The system of claim 13 , wherein the metadata is further defined manually by another user different from the viewing user., 15. The system of claim 13 , wherein the metadata comprises a viewer rating on a scene-by-scene basis for the respective media presentation., 16. The system of claim 11 , wherein the computer-readable storage medium stores additional instructions which, when executed by the hardware processor, cause the hardware processor to perform operations further comprising: receiving a user query associated with a specific dialog within the respective media presentation; searching the relational media database for video presentations corresponding to the user query and presenting a list of results; receiving a user selection of a specific video presentation from the list of results; and transmitting a specific video presentation representative frame, a portion of a subtitle track associated with the specific video presentation, and a prompt for ordering the specific video presentation., 17. The system of claim 16 , wherein the computer-readable storage medium stores additional instructions which, when executed by the hardware processor, cause the hardware processor to perform operations further comprising: presenting options for selecting a second metadata associated with the specific video presentation representative frame., 18. A computer-readable storage device having instructions stored which, when executed by a processor of a computing device, cause the processor of the computing device to perform operations comprising: receiving a query from a viewing user; searching, based on the query, a relational media database comprising a plurality of media presentations, wherein the relational media database, for a respective media presentation of the plurality of media presentations, comprises a subtitle track being a textual representation of a dialog within the respective media presentation, a frame from the respective media presentation associated with the subtitle track, program statistics based on analysis of the subtitle track, and a statistical index associated with a respective type of the program statistics, to yield search results; and transmitting the search results to a device associated with the viewing user, the search results comprising the frame and a prompt for ordering the respective media presentation associated with the frame.\n",
            "Similarity Score: 0.5411\n",
            "\n",
            "\n",
            "Patent ID: 10606949\n",
            "PubMed Claim: 1. An artificial intelligence based method for checking a text, the method comprising: lexing a first to-be-checked text and a second to-be-checked text respectively to obtain lexed words, determining word vectors of the lexed words to generate a first word vector sequence corresponding to the first text and a second word vector sequence corresponding to the second text; inputting the first word vector sequence and the second word vector sequence respectively into a pre-trained convolutional neural network containing at least one multi-scale convolutional layer, identifying vector sequences in a plurality of vector sequences outputted by a last multi-scale convolutional layer in the at least one multi-scale convolutional layer as eigenvector sequences, to obtain eigenvector sequence groups respectively corresponding to the texts, wherein the convolutional neural network is used for extracting characteristics of texts; combining eigenvector sequences in the obtained eigenvector sequence group corresponding to each text to generate a combined eigenvector sequence corresponding to each text; and analyzing the generated combined eigenvector sequences to determine whether the first text and the second text pass a similarity check., 2. The method for checking a text according to claim 1 , wherein the analyzing the generated combined eigenvector sequences to determine whether the first text and the second text pass a similarity check comprises: extracting, for each text, a maximum value in each dimension of the eigenvectors contained in a combined eigenvector sequence corresponding to each text, to generate a target eigenvector corresponding to the each text; and determining whether the first text and the second text pass the similarity check based on the generated target eigenvectors corresponding to the texts., 3. The method for checking a text according to claim 2 , wherein the determining whether the first text and the second text pass the similarity check based on the generated target eigenvectors corresponding to the texts comprises: inputting the generated target eigenvectors into a pre-trained similarity prediction model to obtain similarity prediction result of the first text and the second text, wherein the similarity prediction model is used for characterizing a corresponding relationship between target eigenvector sequences of a plurality of texts and similarity prediction results of the plurality of texts; and determining whether the first text and the second text pass the similarity check based on the obtained similarity prediction result., 4. The method for checking a text according to claim 3 , wherein the method further comprises training the similarity prediction model, comprising: extracting a preset training sample, wherein the training sample comprises a first training text, a second training text, and an identifier for indicating whether the first training text is similar to the second training text; analyzing the first training text and the second training text to generate target eigenvectors respectively corresponding to the first training sample and the second training sample; and obtaining the similarity prediction model by training using a machine learning method, using the target eigenvectors respectively corresponding to the first training sample and the second training sample as inputs, and using the identifier as an input., 5. The method for checking a text according to claim 2 , wherein the determining whether the first text and the second text pass the similarity check based on the generated target eigenvectors corresponding to the texts comprises: determining a similarity between a target eigenvector corresponding to the first text and a target eigenvector corresponding to the second text; determining the first text and the second text passing the similarity check in response to determining the similarity being greater than a preset similarity threshold; and determining the first text and the second text failing to pass the similarity check in response to determining the similarity being not greater than the similarity threshold., 6. The method for checking a text according to claim 1 , wherein a deep coherent layer and a pooling layer are arranged between adjacent multi-scale convolutional layers in the at least one multi-scale convolutional layer, the deep coherent layer is used for combining a plurality of vector sequences outputted by the multi-scale convolutional layer to generate a combined vector sequence consisting of a plurality of combined vectors, and the pooling layer is used for analyzing the combined vector sequence generated by the deep coherent layer in a preset window size and a preset window sliding step length to obtain a simplified combined vector sequence., 7. An artificial intelligence based apparatus for checking a text, the apparatus comprising: at least one processor; and a memory storing instructions, the instructions when executed by the at least one processor, cause the at least one processor to perform operations, the operations comprising: lexing a first to-be-checked text and a second to-be-checked text respectively to obtain lexed words, determining word vectors of the lexed words to generate a first word vector sequence corresponding to the first text and a second word vector sequence corresponding to the second text; inputting the first word vector sequence and the second word vector sequence respectively into a pre-trained convolutional neural network containing at least one multi-scale convolutional layer, identifying vector sequences in a plurality of vector sequences outputted by a last multi-scale convolutional layer in the at least one multi-scale convolutional layer as eigenvector sequences, to obtain eigenvector sequence groups respectively corresponding to the texts, wherein the convolutional neural network is used for extracting characteristics of texts; combining eigenvector sequences in the obtained eigenvector sequence group corresponding to each text to generate a combined eigenvector sequence corresponding to each text; and analyzing the generated combined eigenvector sequences to determine whether the first text and the second text pass a similarity check., 8. The apparatus for checking a text according to claim 7 , wherein the analyzing the generated combined eigenvector sequences to determine whether the first text and the second text pass a similarity check comprises: extracting, for each text, a maximum value in each dimension of the eigenvectors contained in a combined eigenvector sequence corresponding to the each text, to generate a target eigenvector corresponding to the each text; and determining whether the first text and the second text pass the similarity check based on the generated target eigenvectors corresponding to the texts., 9. The apparatus for checking a text according to claim 8 , wherein the determining whether the first text and the second text pass the similarity check based on the generated target eigenvectors corresponding to the texts comprises: inputting the generated target eigenvectors into a pre-trained similarity prediction model to obtain similarity prediction result of the first text and the second text, wherein the similarity prediction model is used for characterizing a corresponding relationship between target eigenvector sequences of a plurality of texts and similarity prediction results of the plurality of texts; and determining whether the first text and the second text pass the similarity check based on the obtained similarity prediction result., 10. The apparatus for checking a text according to claim 9 , wherein the operations further comprise training the similarity prediction model, comprising: extracting a preset training sample, wherein the training sample comprises a first training text, a second training text, and an identifier for indicating whether the first training text is similar to the second training text; analyzing the first training text and the second training text to generate target eigenvectors respectively corresponding to the first training sample and the second training sample; and obtaining the similarity prediction model by training using a machine learning method, using the target eigenvectors respectively corresponding to the first training sample and the second training sample as inputs, and using the identifier as an input., 11. The apparatus for checking a text according to claim 8 , wherein the determining whether the first text and the second text pass the similarity check based on the generated target eigenvectors corresponding to the texts comprises: determining a similarity between a target eigenvector corresponding to the first text and a target eigenvector corresponding to the second text; determining the first text and the second text passing the similarity check in response to determining the similarity being greater than a preset similarity threshold; and determining the first text and the second text failing to pass the similarity check in response to determining the similarity being not greater than the similarity threshold., 12. The apparatus for checking a text according to claim 7 , wherein a deep coherent layer and a pooling layer are arranged between adjacent multi-scale convolutional layers in the at least one multi-scale convolutional layer, the deep coherent layer is used for combining a plurality of vector sequences outputted by the multi-scale convolutional layer to generate a combined vector sequence consisting of a plurality of combined vectors, and the pooling layer is used for analyzing the combined vector sequence generated by the deep coherent layer in a preset window size and a preset window sliding step length to obtain a simplified combined vector sequence., 13. A non-transitory computer storage medium storing a computer program, the computer program when executed by one or more processors, causes the one or more processors to perform operations, the operations comprising: lexing a first to-be-checked text and a second to-be-checked text respectively to obtain lexed words, determining word vectors of the lexed words to generate a first word vector sequence corresponding to the first text and a second word vector sequence corresponding to the second text; inputting the first word vector sequence and the second word vector sequence respectively into a pre-trained convolutional neural network containing at least one multi-scale convolutional layer, identifying vector sequences in a plurality of vector sequences outputted by a last multi-scale convolutional layer in the at least one multi-scale convolutional layer as eigenvector sequences, to obtain eigenvector sequence groups respectively corresponding to the texts, wherein the convolutional neural network is used for extracting characteristics of texts; combining eigenvector sequences in the obtained eigenvector sequence group corresponding to each text to generate a combined eigenvector sequence corresponding to each text; and analyzing the generated combined eigenvector sequences to determine whether the first text and the second text pass a similarity check.\n",
            "Similarity Score: 0.5406\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_zI1hoLKVMW"
      },
      "source": [
        "# type(get_top_n_similar_patents_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB7Dqvbee7_G",
        "outputId": "2eca6557-fee2-4f76-e85c-0fe0071d9624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "get_top_n_similar_patents_df.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>top_claim_ids</th>\n",
              "      <th>cosine_similarity</th>\n",
              "      <th>claims</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10606917</td>\n",
              "      <td>0.6802</td>\n",
              "      <td>1. An alternating least square recommendation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10606970</td>\n",
              "      <td>0.6652</td>\n",
              "      <td>1. A computer-implemented method for statistic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10606918</td>\n",
              "      <td>0.6614</td>\n",
              "      <td>1. A convolution engine, comprising: an input ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10606971</td>\n",
              "      <td>0.6549</td>\n",
              "      <td>1. A system, comprising a processor to: receiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10606931</td>\n",
              "      <td>0.6529</td>\n",
              "      <td>1. A system, comprising: one or more storage d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   top_claim_ids  ...                                             claims\n",
              "0       10606917  ...  1. An alternating least square recommendation ...\n",
              "1       10606970  ...  1. A computer-implemented method for statistic...\n",
              "2       10606918  ...  1. A convolution engine, comprising: an input ...\n",
              "3       10606971  ...  1. A system, comprising a processor to: receiv...\n",
              "4       10606931  ...  1. A system, comprising: one or more storage d...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80AZOv0ae-1E"
      },
      "source": [
        "result = pd.concat([get_top_n_similar_patents_df, df], axis=1, join='inner')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4Ob0j_Xh3hG",
        "outputId": "dd0f7445-2ce2-485e-9a28-4e33735b1e0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "result.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>top_claim_ids</th>\n",
              "      <th>cosine_similarity</th>\n",
              "      <th>claims</th>\n",
              "      <th>patent_id</th>\n",
              "      <th>claim_number</th>\n",
              "      <th>sequence</th>\n",
              "      <th>dependent</th>\n",
              "      <th>exemplary</th>\n",
              "      <th>subclass</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10606917</td>\n",
              "      <td>0.6802</td>\n",
              "      <td>1. An alternating least square recommendation ...</td>\n",
              "      <td>10606734</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>6. A computer-program product for intelligent ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10606970</td>\n",
              "      <td>0.6652</td>\n",
              "      <td>1. A computer-implemented method for statistic...</td>\n",
              "      <td>10606736</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1. A computer-implemented method for creation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10606918</td>\n",
              "      <td>0.6614</td>\n",
              "      <td>1. A convolution engine, comprising: an input ...</td>\n",
              "      <td>10606737</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1. A method for testing a resource constrained...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10606971</td>\n",
              "      <td>0.6549</td>\n",
              "      <td>1. A system, comprising a processor to: receiv...</td>\n",
              "      <td>10606738</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1. A method, comprising: receiving results fro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10606931</td>\n",
              "      <td>0.6529</td>\n",
              "      <td>1. A system, comprising: one or more storage d...</td>\n",
              "      <td>10606739</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1. A device, comprising: a memory; and one or ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   top_claim_ids  ...                                               text\n",
              "0       10606917  ...  6. A computer-program product for intelligent ...\n",
              "1       10606970  ...  1. A computer-implemented method for creation ...\n",
              "2       10606918  ...  1. A method for testing a resource constrained...\n",
              "3       10606971  ...  1. A method, comprising: receiving results fro...\n",
              "4       10606931  ...  1. A device, comprising: a memory; and one or ...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flCL_SC1vavw",
        "outputId": "40b631a7-4cdb-4fed-e603-0daa1acf3660",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(result.count())"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "top_claim_ids        100\n",
            "cosine_similarity    100\n",
            "claims               100\n",
            "patent_id            100\n",
            "claim_number         100\n",
            "sequence             100\n",
            "dependent              0\n",
            "exemplary            100\n",
            "subclass             100\n",
            "text                 100\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjZl_jNvh8Kz"
      },
      "source": [
        "# import pandas as pd\n",
        "# import torch\n",
        "\n",
        "# # determine the supported device\n",
        "# def get_device():\n",
        "#     if torch.cuda.is_available():\n",
        "#         device = torch.device('cuda:0')\n",
        "#     else:\n",
        "#         device = torch.device('cpu') # don't have GPU \n",
        "#     return device\n",
        "\n",
        "# # convert a df to tensor to be used in pytorch\n",
        "# def df_to_tensor(df):\n",
        "#     device = get_device()\n",
        "#     return torch.from_numpy(df.values).float().to(device)\n",
        "\n",
        "# df_tensor = df_to_tensor(result[['cosine_similarity','claim_number','patent_id']])\n",
        "# # series_tensor = df_to_tensor(series)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6J_-r5oiQ3E"
      },
      "source": [
        "# df_tensor\n",
        "# sorted, indices = torch.sort(df_tensor, 0)\n",
        "# a = torch.topk(df_tensor, 2, dim = 0)\n",
        "# a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3lAp65HkU9s"
      },
      "source": [
        "k_similar_patents = result.nlargest(10, ['cosine_similarity'])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHnUv1IIqlN-",
        "outputId": "69b90090-465e-4dca-d075-aef30c02d3f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        }
      },
      "source": [
        "k_similar_patents"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>top_claim_ids</th>\n",
              "      <th>cosine_similarity</th>\n",
              "      <th>claims</th>\n",
              "      <th>patent_id</th>\n",
              "      <th>claim_number</th>\n",
              "      <th>sequence</th>\n",
              "      <th>dependent</th>\n",
              "      <th>exemplary</th>\n",
              "      <th>subclass</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10606917</td>\n",
              "      <td>0.6802</td>\n",
              "      <td>1. An alternating least square recommendation ...</td>\n",
              "      <td>10606734</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "      <td>6. A computer-program product for intelligent ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10606970</td>\n",
              "      <td>0.6652</td>\n",
              "      <td>1. A computer-implemented method for statistic...</td>\n",
              "      <td>10606736</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1. A computer-implemented method for creation ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10606918</td>\n",
              "      <td>0.6614</td>\n",
              "      <td>1. A convolution engine, comprising: an input ...</td>\n",
              "      <td>10606737</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1. A method for testing a resource constrained...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10606971</td>\n",
              "      <td>0.6549</td>\n",
              "      <td>1. A system, comprising a processor to: receiv...</td>\n",
              "      <td>10606738</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1. A method, comprising: receiving results fro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10606931</td>\n",
              "      <td>0.6529</td>\n",
              "      <td>1. A system, comprising: one or more storage d...</td>\n",
              "      <td>10606739</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1. A device, comprising: a memory; and one or ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10606981</td>\n",
              "      <td>0.6499</td>\n",
              "      <td>1. A computer-implemented method for space fra...</td>\n",
              "      <td>10606740</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1. A system comprising: a processor comprising...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10606909</td>\n",
              "      <td>0.6270</td>\n",
              "      <td>1. A computer-implemented method for optimizin...</td>\n",
              "      <td>10606741</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1. A process performed by a computing device f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10606856</td>\n",
              "      <td>0.6263</td>\n",
              "      <td>1. A method, comprising: ingesting, by a data ...</td>\n",
              "      <td>10606742</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1. A method for programming a motor drive havi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>10606749</td>\n",
              "      <td>0.6246</td>\n",
              "      <td>1. A non-transitory computer-readable storage ...</td>\n",
              "      <td>10606743</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1. An apparatus, comprising: an array of non-v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10606819</td>\n",
              "      <td>0.6236</td>\n",
              "      <td>1. A method of reducing a number of event reco...</td>\n",
              "      <td>10606744</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>1. A method for accessing a flash memory modul...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   top_claim_ids  ...                                               text\n",
              "0       10606917  ...  6. A computer-program product for intelligent ...\n",
              "1       10606970  ...  1. A computer-implemented method for creation ...\n",
              "2       10606918  ...  1. A method for testing a resource constrained...\n",
              "3       10606971  ...  1. A method, comprising: receiving results fro...\n",
              "4       10606931  ...  1. A device, comprising: a memory; and one or ...\n",
              "5       10606981  ...  1. A system comprising: a processor comprising...\n",
              "6       10606909  ...  1. A process performed by a computing device f...\n",
              "7       10606856  ...  1. A method for programming a motor drive havi...\n",
              "8       10606749  ...  1. An apparatus, comprising: an array of non-v...\n",
              "9       10606819  ...  1. A method for accessing a flash memory modul...\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "946WXJehrBwv",
        "outputId": "858edeaa-96af-4210-ddf7-4a79a1d63421",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "final_result = k_similar_patents.mode()\n",
        "print('Prediction for Subclass of New Patent is: ', final_result.iloc[0]['subclass'])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction for Subclass of New Patent is:  A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5NbR_4jTsV5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}