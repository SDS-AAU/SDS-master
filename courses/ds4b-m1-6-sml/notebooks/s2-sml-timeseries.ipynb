{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMV6crx300UQw4CReFtP61p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SDS-AAU/SDS-master/blob/master/courses/ds4b-m1-6-sml/notebooks/s2-sml-timeseries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import altair as alt\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "qaxy9GeKq51A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to timeseries\n",
        "\n",
        "What is a time series analysis and what are the benefits? A time series analysis focuses on a series of data points ordered in time. This is one of the most widely used data science analyses and is applied in a variety of industries. \n",
        "\n",
        "This approach can play a huge role in helping companies understand and forecast data patterns and other phenomena, and the results can drive better business decisions. For example:\n",
        "\n",
        "* If you’re a retailer, a time series analysis can help you forecast daily sales volumes to guide decisions around inventory and better timing for marketing efforts.\n",
        "* If you’re in the financial industry, a time series analysis can allow you to forecast stock prices for more effective investment decisions\n",
        "* If you’re an agricultural company, a time series analysis can be used for weather forecasting to guide planning decisions around planting and harvesting."
      ],
      "metadata": {
        "id": "96LlJvyeY7bR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basics\n",
        "\n",
        "- A **time-series** data is a series of data points or observations recorded at different or regular time intervals. In general, a time series is a sequence of data points taken at equally spaced time intervals.  The frequency of recorded data points may be hourly, daily, weekly, monthly, quarterly or annually.\n",
        "\n",
        "\n",
        "- **Time-Series Forecasting** is the process of using a statistical model to predict future values of a time-series based on past results.\n",
        "\n",
        "\n",
        "- A time series analysis encompasses statistical methods for analyzing time series data. These methods enable us to extract meaningful statistics, patterns and other characteristics of the data. Time series are visualized with the help of line charts. So, time series analysis involves understanding inherent aspects of the time series data so that we can create meaningful and accurate forecasts.\n",
        "\n",
        "\n",
        "- Applications of time series are used in statistics, finance or business applications. A very common example of time series data is the daily closing value of the stock index like NASDAQ or Dow Jones. Other common applications of time series are sales and demand forecasting, weather forecasting, econometrics, signal processing, pattern recognition and earthquake prediction.\n"
      ],
      "metadata": {
        "id": "VMxA_g5uyW_l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Components of a Time-Series\n",
        "\n",
        "\n",
        "- **Trend** - The trend shows a general direction of the time series data over a long period of time. A trend can be increasing(upward), decreasing(downward), or horizontal(stationary).\n",
        "\n",
        "\n",
        "- **Seasonality** - The seasonality component exhibits a trend that repeats with respect to timing, direction, and magnitude. Some examples include an increase in water consumption in summer due to hot weather conditions.\n",
        "\n",
        "\n",
        "- **Cyclical Component** - These are the trends with no set repetition over a particular period of time. A cycle refers to the period of ups and downs, booms and slums of a time series, mostly observed in business cycles. These cycles do not exhibit a seasonal variation but generally occur over a time period of 3 to 12 years depending on the nature of the time series.\n",
        "\n",
        "\n",
        "- **Irregular Variation** - These are the fluctuations in the time series data which become evident when trend and cyclical variations are removed. These variations are unpredictable, erratic, and may or may not be random.\n",
        "\n",
        "- **ETS Decomposition** - ETS Decomposition is used to separate different components of a time series. The term ETS stands for Error, Trend and Seasonality.\n",
        "\n",
        "![timeseries seassions](https://aaubs.github.io/ds-master/data/Images/m1_sml_time_series_seasson.png)"
      ],
      "metadata": {
        "id": "8pcluOVmyiq6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python Ecosystem\n",
        "\n",
        "Feature Engineering\n",
        "\n",
        "* [tsfresh](https://tsfresh.readthedocs.io/): “Time Series Feature Extraction Based on Scalable Hypothesis Tests.” Automatically calculates and extracts several time series features. \n",
        "* ...\n",
        "\n",
        "Time series prediction\n",
        "\n",
        "* [sktime](https://www.sktime.org/): This is an open-source python library exclusively designed for time series analysis. It provides an extension to the scikit-learn API for time-series solutions and contains all the required algorithms and tools that are needed for the effective resolution of time-series regression, prediction, and categorization issues.\n",
        "* [kats](https://facebookresearch.github.io/Kats/): Kats (Kits to Analyze Time Series) is an open-source Python library developed by researchers at Facebook. This library is easy to use and is helpful for time series problems. This is due to its very light weighted library of generic time series analysis which allows to set up the models quicker without spending so much time processing time series and calculations in different models.\n",
        "* ...\n"
      ],
      "metadata": {
        "id": "A1CGiliDVkye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data example"
      ],
      "metadata": {
        "id": "FjEWylxKqtoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vega_datasets import data"
      ],
      "metadata": {
        "id": "UvmkE1lqf7A4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Air Passengers"
      ],
      "metadata": {
        "id": "LpHB7z463-ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_passengers = pd.read_csv(\"https://raw.githubusercontent.com/aaubs/ds-master/main/data/air_passengers.csv\")"
      ],
      "metadata": {
        "id": "OBBUnayn4C6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_passengers.head()"
      ],
      "metadata": {
        "id": "s79yd6M74WjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_passengers.columns = ['date','n']"
      ],
      "metadata": {
        "id": "cJ7ShydN65A4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse date to datetime format\n",
        "df_passengers['date'] = pd.to_datetime(df_passengers['date'], format='%Y-%m')\n",
        "\n",
        "# Set the date as index \n",
        "df_passengers = df_passengers.set_index('date')"
      ],
      "metadata": {
        "id": "_51eZhJu5WNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_passengers.info()"
      ],
      "metadata": {
        "id": "BjC93awg4c9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_passengers.head()"
      ],
      "metadata": {
        "id": "7SNfW2ZBJm9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alt.Chart(data = df_passengers.reset_index()).mark_line().encode(\n",
        "    x='date:T',\n",
        "    y='n:Q'\n",
        ")"
      ],
      "metadata": {
        "id": "WJahmMUkKmjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Weather\n",
        "https://altair-viz.github.io/user_guide/times_and_dates.html"
      ],
      "metadata": {
        "id": "C1EURNMBew03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp = data.seattle_temps()\n",
        "df_temp.head()"
      ],
      "metadata": {
        "id": "itKbw_-wey3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp.info()"
      ],
      "metadata": {
        "id": "PzadgtUCumLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_temp[\"date\"] = pd.to_datetime(df_temp[\"date\"])"
      ],
      "metadata": {
        "id": "XTYV8jYEvaVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alt.Chart(df_temp[df_temp.date < '2010-01-15']).mark_line().encode(\n",
        "    x='date:T',\n",
        "    y='temp:Q'\n",
        ")"
      ],
      "metadata": {
        "id": "sDuOHeYJgovr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alt.Chart(df_temp[df_temp.date < '2010-01-15']).mark_rect().encode(\n",
        "    alt.X('hoursminutes(date):O', title='hour of day'),\n",
        "    alt.Y('monthdate(date):O', title='date'),\n",
        "    alt.Color('temp:Q', title='temperature (F)')\n",
        ")"
      ],
      "metadata": {
        "id": "TYH1umtBiEj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alt.Chart(df_temp.resample('M', on='date').mean().reset_index()).mark_line().encode(\n",
        "    x='date:T',\n",
        "    y='temp:Q'\n",
        ")"
      ],
      "metadata": {
        "id": "FKTAyDMKvzgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Energy Usage\n",
        "https://infovis.fh-potsdam.de/tutorials/infovis4time.html "
      ],
      "metadata": {
        "id": "SJti3-3u6N9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data downloaded from OPSD - see filter elements on this page: https://data.open-power-system-data.org/time_series/2019-06-05\n",
        "df_energy = pd.read_csv(\"https://data.open-power-system-data.org/index.php?package=time_series&version=2019-06-05&action=customDownload&resource=3&filter%5B_contentfilter_cet_cest_timestamp%5D%5Bfrom%5D=2015-01-01&filter%5B_contentfilter_cet_cest_timestamp%5D%5Bto%5D=2018-12-31&filter%5BRegion%5D%5B%5D=DE&filter%5BVariable%5D%5B%5D=load_actual_entsoe_transparency&filter%5BVariable%5D%5B%5D=solar_generation_actual&filter%5BVariable%5D%5B%5D=wind_generation_actual&downloadCSV=Download+CSV\",\n",
        "                   parse_dates=['utc_timestamp']) # parse timestamp column"
      ],
      "metadata": {
        "id": "osGyKFXO6ncE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_energy.head()"
      ],
      "metadata": {
        "id": "zD_EZDGL7kan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_energy = df_energy.drop(columns=[\"cet_cest_timestamp\"])\n",
        "df_energy.columns=[\"datetime\", \"load\", \"solar\", \"wind\"]\n",
        "df_energy[\"datetime\"] = df_energy[\"datetime\"].dt.tz_convert(\"Europe/Berlin\")\n",
        "df_energy = df_energy.set_index(\"datetime\")"
      ],
      "metadata": {
        "id": "7onLdCmY75nS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_energy.head()"
      ],
      "metadata": {
        "id": "mCz9wR4J8fF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_energy_day = df_energy.resample(\"D\").sum()\n",
        "df_energy_month = df_energy_day.resample(\"M\").mean()"
      ],
      "metadata": {
        "id": "PjIiNhV99X38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_energy_day.head()"
      ],
      "metadata": {
        "id": "XFwStoLT9c7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alt.Chart(df_energy_day.reset_index().melt(\"datetime\")).mark_circle().encode(\n",
        "    x='datetime',\n",
        "    y='value',\n",
        "    color='variable',\n",
        ").properties(width=800, height=400)"
      ],
      "metadata": {
        "id": "lyFYnPmI9sLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_day = alt.Chart(df_energy_day.reset_index().melt(\"datetime\")).mark_line(strokeWidth=1).encode(\n",
        "    x='datetime',\n",
        "    y='value',\n",
        "    color='variable',\n",
        ").properties(width=800, height=400)\n",
        "\n",
        "plot_day"
      ],
      "metadata": {
        "id": "_-4-qkwrDN2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_month = alt.Chart(df_energy_month.reset_index().melt(\"datetime\")).mark_line(opacity=0.75, interpolate=\"basis\").encode(\n",
        "    x='datetime',\n",
        "    y='value',\n",
        "    color='variable',\n",
        ").properties(width=800, height=400)\n",
        "\n",
        "plot_month"
      ],
      "metadata": {
        "id": "w92qnmqXCf4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_day + plot_month"
      ],
      "metadata": {
        "id": "I0s7L83VD0JG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bonus: Stocks"
      ],
      "metadata": {
        "id": "zpO1Ps1PepKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yfinance\n",
        "import yfinance as yf"
      ],
      "metadata": {
        "id": "Ri6A4fqKrBGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_stocks = yf.download(tickers='META', period='5y', interval='1d')"
      ],
      "metadata": {
        "id": "J5qqOZRb4L1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_stocks.head()"
      ],
      "metadata": {
        "id": "Ayrm_S5WLiEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_stocks.info()"
      ],
      "metadata": {
        "id": "kjYrQFmqMDxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alt.Chart(data = df_stocks.reset_index()).mark_line().encode(\n",
        "    x='Date:T',\n",
        "    y='Close:Q'\n",
        ")\n",
        "\n",
        "## Note: For the sake of consistency, I in this tutorial mostly use Altair for plotting.\n",
        "## However, the same plot could (in this case easier) also be produced with: \n",
        "# sns.lineplot(data=df_stocks, x=\"Date\", y=\"Close\")"
      ],
      "metadata": {
        "id": "HP603oTuLXUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Timeseries Decomposition\n",
        "\n"
      ],
      "metadata": {
        "id": "Y-omYp4IMNkq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basics\n",
        "\n",
        "- Any time series visualization may consist of the following components: **Base Level + Trend + Seasonality + Error**.\n",
        "\n",
        "\n",
        "\n",
        "- A **trend** is observed when there is an increasing or decreasing slope observed in the time series. \n",
        "- A **seasonality** is observed when there is a distinct repeated pattern observed between regular intervals due to seasonal factors. It could be because of the month of the year, the day of the month, weekdays or even time of the day.\n",
        "- Another important thing to consider is the **cyclic behaviour**. It happens when the rise and fall pattern in the series does not happen in fixed calendar-based intervals. We should not confuse 'cyclic' effect with 'seasonal' effect.\n",
        "\n",
        "\n",
        "However, It is not mandatory that all time series must have a trend and/or seasonality. A time series may not have a distinct trend but have a seasonality and vice-versa.\n",
        "\n",
        "- We may have different combinations of trends and seasonality. Depending on the nature of the trends and seasonality, a time series can be modeled as an additive or multiplicative time series. Each observation in the series can be expressed as either a sum or a product of the components.\n",
        "\n",
        "\n",
        "* **Additive time series:** Value = Base Level + Trend + Seasonality + Error\n",
        "* **Multiplicative Time Series:** Value = Base Level x Trend x Seasonality x Error"
      ],
      "metadata": {
        "id": "F4Mv4n3AYwq4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Application\n",
        "\n",
        "- Decomposition of a time series can be performed by considering the series as an additive or multiplicative combination of the base level, trend, seasonal index and the residual term.\n",
        "- The seasonal_decompose in statsmodels implements this conveniently."
      ],
      "metadata": {
        "id": "PjKRQWpRZRxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from dateutil.parser import parse"
      ],
      "metadata": {
        "id": "vE2usv4rZhjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate\n",
        "multiplicative_decomposition = seasonal_decompose(df_passengers['n'], model='multiplicative', period=30)\n",
        "additive_decomposition = seasonal_decompose(df_passengers['n'], model='additive', period=30)\n",
        "\n",
        "# Plot\n",
        "multiplicative_decomposition.plot().suptitle('Multiplicative Decomposition', fontsize=16)\n",
        "additive_decomposition.plot().suptitle('Additive Decomposition', fontsize=16)\n"
      ],
      "metadata": {
        "id": "ZtzUiS8MZU85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- If we look at the residuals of the additive decomposition closely, it has some pattern left over. \n",
        "- The multiplicative decomposition, looks quite random which is good. So ideally, multiplicative decomposition should be preferred for this particular series."
      ],
      "metadata": {
        "id": "iQ1-7sSVaXty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time Series Stationarity"
      ],
      "metadata": {
        "id": "wc0NlAoeiU7O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Stationarity** is a property of a time series. A stationary series is one where the values of the series is not a function of time. So, the values are independent of time.\n",
        "- Hence the statistical properties of the series like mean, variance and autocorrelation are constant over time. Autocorrelation of the series is nothing but the correlation of the series with its previous values.\n",
        "- A stationary time series is independent of seasonal effects as well.\n",
        "- We can covert any non-stationary time series into a stationary one by applying a suitable transformation. Mostly statistical forecasting methods are designed to work on a stationary time series. The first step in the forecasting process is typically to do some transformation to convert a non-stationary series to stationary.\n",
        "\n",
        "![Stationary and Non-Stationary Time Series](https://www.machinelearningplus.com/wp-content/uploads/2019/02/stationary-and-non-stationary-time-series-865x569.png?ezimgfmt=ng:webp/ngcb1)\n",
        "\n",
        "image source : https://www.machinelearningplus.com/wp-content/uploads/2019/02/stationary-and-non-stationary-time-series-865x569.png?ezimgfmt=ng:webp/ngcb1\n",
        "\n",
        "- We can apply some sort of transformation to make the time-series stationary. These transformation may include:\n",
        "  1. Differencing the Series (once or more)\n",
        "  2. Take the log of the series\n",
        "  3. Take the nth root of the series\n",
        "  4. Combination of the above\n",
        "- The most commonly used and convenient method to stationarize the series is by differencing the series at least once until it becomes approximately stationary.\n"
      ],
      "metadata": {
        "id": "0pCsD28XiXoG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test for stationarity?\n",
        "\n",
        "- The stationarity of a series can be checked by looking at the plot of the series.\n",
        "- Another method is to split the series into 2 or more contiguous parts and computing the summary statistics like the mean, variance and the autocorrelation. If the stats are quite different, then the series is not likely to be stationary.\n",
        "- There are several quantitative methods we can use to determine if a given series is stationary or not. This can be done using statistical tests called [Unit Root Tests](https://en.wikipedia.org/wiki/Unit_root). This test checks if a time series is non-stationary and possess a unit root. \n",
        "- There are multiple implementations of Unit Root tests like:\n",
        "  1. Augmented Dickey Fuller test (ADF Test)\n",
        "  2. Kwiatkowski-Phillips-Schmidt-Shin – KPSS test (trend stationary)\n",
        "  3. Philips Perron test (PP Test)\n",
        "\n",
        "\n",
        "The **Augmented Dickey Fuller test** or (ADF Test) is the most commonly used test to detect stationarity. Here, we assume that the null hypothesis is the time series possesses a unit root and is non-stationary. Then, we collect evidence to support or reject the null hypothesis. So, if we find that the p-value in ADF test is less than the significance level (0.05), we reject the null hypothesis."
      ],
      "metadata": {
        "id": "dnC_5TV0i6L3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.stattools import adfuller"
      ],
      "metadata": {
        "id": "zS303HCETgiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#perform augmented Dickey-Fuller test\n",
        "adfuller(df_passengers[\"n\"])"
      ],
      "metadata": {
        "id": "_d-VUO_iSzhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Counter example: White noise\n",
        "white_noise = np.random.normal(loc  =0, scale = 1, size = 500)\n",
        "plt.plot(white_noise)"
      ],
      "metadata": {
        "id": "SbK5UpLHWZ4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#perform augmented Dickey-Fuller test\n",
        "adfuller(white_noise)"
      ],
      "metadata": {
        "id": "8ZpjdpdLWevt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can substract the trend to get rid of it\n",
        "df_passengers['n_detrend'] = df_passengers['n'] - multiplicative_decomposition.trend\n",
        "plt.plot(df_passengers['n_detrend']) "
      ],
      "metadata": {
        "id": "j7iIIy5cXK8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can also do firsty differencing instead\n",
        "df_passengers['n_diff'] = df_passengers['n'].diff()\n",
        "plt.plot(df_passengers['n_diff'] ) "
      ],
      "metadata": {
        "id": "-prXJrhxYQEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autocorrelation and Partial Autocorrelation Functions\n",
        "\n",
        "- **Autocorrelation** is simply the correlation of a series with its own lags. If a series is significantly autocorrelated, that means, the previous values of the series (lags) may be helpful in predicting the current value.\n",
        "- **Partial Autocorrelation** also conveys similar information but it conveys the pure correlation of a series and its lag, excluding the correlation contributions from the intermediate lags."
      ],
      "metadata": {
        "id": "9vKUegu9YQRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.stattools import acf, pacf\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf"
      ],
      "metadata": {
        "id": "GxuQ4AsQZN7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Draw Plot\n",
        "fig, axes = plt.subplots(1,2,figsize=(16,3), dpi= 100)\n",
        "plot_acf(df_passengers['n'] .tolist(), lags=50, ax=axes[0])\n",
        "plot_pacf(df_passengers['n'].tolist(), lags=50, ax=axes[1])"
      ],
      "metadata": {
        "id": "Q7lmHp_cZP1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time-series Prediction (AKA forecasting)"
      ],
      "metadata": {
        "id": "rwn1gr9rj7eW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KATS\n",
        "\n",
        "Kats (Kits to Analyze Time Series) is a light-weight, easy-to-use, extenable, and generalizable framework to perform time series analysis in Python. Time series analysis is an essential component of data science and engineering work. Kats aims to provide a one-stop shop for techniques for univariate and multivariate time series including:\n",
        "\n",
        "1. Forecasting\n",
        "2. Anomaly and Change Point Detection\n",
        "3. Feature Extraction"
      ],
      "metadata": {
        "id": "EGbf-vcJQaGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install kats\n",
        "import kats\n",
        "from kats.consts import TimeSeriesData"
      ],
      "metadata": {
        "id": "cXcsYg5CchNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ts_passengers = df_passengers.reset_index().iloc[:, 0:2]\n",
        "ts_passengers.columns = [\"time\", \"value\"]\n",
        "ts_passengers = TimeSeriesData(ts_passengers)"
      ],
      "metadata": {
        "id": "sQSuJr1HcRIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (S) ARIMA\n",
        "\n",
        "Auto-Regressive Integrated Moving Average or ARIMA models look at autocorrelations or serial correlations in the data. In other words, ARIMA models look at differences between values in the time series. SARIMA builds upon the concept of ARIMA but extends it to model the seasonal elements in your data. \n",
        " \n",
        "SARIMA includes several parameters that can be tuned to achieve optimal performance. You can learn more about these parameters here. They are:\n",
        " \n",
        "Trend Elements:\n",
        "\n",
        "* p: Trend autoregression order.\n",
        "* d: Trend difference order.\n",
        "* q: Trend moving average order.\n",
        "\n",
        "Seasonal Elements:\n",
        "\n",
        "* P: Seasonal autoregressive order.\n",
        "* D: Seasonal difference order.\n",
        "* Q: Seasonal moving average order.\n",
        "* m: The number of time steps for a single seasonal period."
      ],
      "metadata": {
        "id": "5P1RBL3Zl0CB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from kats.models.sarima import SARIMAModel, SARIMAParams"
      ],
      "metadata": {
        "id": "LICeD9opfdvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create SARIMA param class\n",
        "params_arima = SARIMAParams(\n",
        "    p = 2, \n",
        "    d=1, \n",
        "    q=1, \n",
        "    trend = 'ct', \n",
        "    seasonal_order=(1,0,1,12)\n",
        "    )"
      ],
      "metadata": {
        "id": "KPIzpXYbfhB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initiate SARIMA model\n",
        "m_arima = SARIMAModel(data=ts_passengers, params=params_arima)"
      ],
      "metadata": {
        "id": "MUSeR57ffj9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit SARIMA model\n",
        "m_arima.fit()"
      ],
      "metadata": {
        "id": "_jVI9XyjfnOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate forecast values\n",
        "fcst_arima = m_arima.predict(\n",
        "    steps=30, \n",
        "    freq=\"MS\",\n",
        "    include_history=True\n",
        "    )"
      ],
      "metadata": {
        "id": "cANSF40dfnSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make plot to visualize\n",
        "m_arima.plot()"
      ],
      "metadata": {
        "id": "mg-uX1ylfr9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prophet\n",
        "\n",
        "* Prophet is an open-source library developed by Facebook and designed for automatic forecasting of univariate time series data.\n",
        "* It is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects. \n",
        "* It works best with time series that have strong seasonal effects and several seasons of historical data. \n",
        "* Prophet is robust to missing data and shifts in the trend, and typically handles outliers well."
      ],
      "metadata": {
        "id": "0m6Qe_w8gJwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the param and model classes for Prophet model\n",
        "from kats.models.prophet import ProphetModel, ProphetParams"
      ],
      "metadata": {
        "id": "GeesE7yugMYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a model param instance\n",
        "params_prophet = ProphetParams(seasonality_mode='multiplicative') # additive mode gives worse results"
      ],
      "metadata": {
        "id": "FEC-psengMkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a prophet model instance\n",
        "m_prophet = ProphetModel(ts_passengers, params_prophet)"
      ],
      "metadata": {
        "id": "43T0yczGgMtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit model simply by calling m.fit()\n",
        "m_prophet.fit()"
      ],
      "metadata": {
        "id": "yd2td9VkgMyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make prediction for next 30 month\n",
        "fcst_prophet = m_prophet.predict(steps=30, freq=\"MS\")"
      ],
      "metadata": {
        "id": "MAtxgtR5gM2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot to visualize\n",
        "m_prophet.plot()"
      ],
      "metadata": {
        "id": "WbbJC5gngU8Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}